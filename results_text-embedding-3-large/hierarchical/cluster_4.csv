title,abstract,class,cluster,publication,year,url,keywords,llm,human n,interaction,long-term?,conclusion,remark
Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task,"This study explores the neural and behavioral consequences of LLM-assisted essay writing. Participants were divided into three groups: LLM, Search Engine, and Brain-only (no tools). Each completed three sessions under the same condition. In a fourth session, LLM users were reassigned to Brain-only group (LLM-to-Brain), and Brain-only users were reassigned to LLM condition (Brain-to-LLM). A total of 54 participants took part in Sessions 1-3, with 18 completing session 4. We used electroencephalography (EEG) to assess cognitive load during essay writing, and analyzed essays using NLP, as well as scoring essays with the help from human teachers and an AI judge. Across groups, NERs, n-gram patterns, and topic ontology showed within-group homogeneity. EEG revealed significant differences in brain connectivity: Brain-only participants exhibited the strongest, most distributed networks; Search Engine users showed moderate engagement; and LLM users displayed the weakest connectivity. Cognitive activity scaled down in relation to external tool use. In session 4, LLM-to-Brain participants showed reduced alpha and beta connectivity, indicating under-engagement. Brain-to-LLM users exhibited higher memory recall and activation of occipito-parietal and prefrontal areas, similar to Search Engine users. Self-reported ownership of essays was the lowest in the LLM group and the highest in the Brain-only group. LLM users also struggled to accurately quote their own work. While LLMs offer immediate convenience, our findings highlight potential cognitive costs. Over four months, LLM users consistently underperformed at neural, linguistic, and behavioral levels. These results raise concerns about the long-term educational implications of LLM reliance and underscore the need for deeper inquiry into AI's role in learning.",2,4,arXiv,2025,https://arxiv.org/abs/2506.08872,Creativity,GPT-4o,54,Conversation,4 months,"1. Using LLMs like ChatGPT for essay writing significantly reduces cognitive engagement and brain connectivity compared to writing unaided ('Brain-only') or using a search engine . This reduced cognitive load correlates with more homogeneous essays, impaired memory recall (evidenced by poor quoting ability), and a diminished sense of ownership over the written work . 2. Prior LLM use appears to create a 'cognitive debt', hindering brain engagement even when the tool is removed, suggesting potential long-term negative impacts on learning and critical thinking skills .",Neuroscience experiments
Generative AI without guardrails can harm learning: Evidence from high school mathematics,"Generative AI is poised to revolutionize how humans work, and has already demonstrated promise in significantly improving human productivity. A key question is how generative AI affects learning—namely, how humans acquire new skills as they perform tasks. Learning is critical to long-term productivity, especially since generative AI is fallible and users must check its outputs. We study this question via a field experiment where we provide nearly a thousand high school math students with access to generative AI tutors. To understand the differential impact of tool design on learning, we deploy two generative AI tutors: one that mimics a standard ChatGPT interface (“GPT Base”) and one with prompts designed to safeguard learning (“GPT Tutor”). Consistent with prior work, our results show that having GPT-4 access while solving problems significantly improves performance (48% improvement in grades for GPT Base and 127% for GPT Tutor). However, we additionally find that when access is subsequently taken away, students actually perform worse than those who never had access (17% reduction in grades for GPT Base)—i.e., unfettered access to GPT-4 can harm educational outcomes. These negative learning effects are largely mitigated by the safeguards in GPT Tutor. Without guardrails, students attempt to use GPT-4 as a “crutch” during practice problem sessions, and subsequently perform worse on their own. Thus, decision-makers must be cautious about design choices underlying generative AI deployments to preserve skill learning and long-term productivity.",3,4,PNAS,2025,https://www.pnas.org/doi/10.1073/pnas.2422633122,Learning,GPT-4,About 1000,Conversation,F,"1. AI-assisted tools can improve immediate performance.

2. The short-term improvement cannot be sustained in the subsequent unassisted exam. The GPT Base group performed significantly worse, worse than the control group. The GPT Tutor group was on par with the control group.

3. Students did not even feel this was harmful. The GPT Base group did not think they learned less, and the GPT Tutor group believed they learned significantly better.",
"Beware of metacognitive laziness: Effects of generative artificial intelligence on learning motivation, processes, and performance","Abstract
With the continuous development of technological and educational innovation, learners nowadays can obtain a variety of supports from agents such as teachers, peers, education technologies, and recently, generative artificial intelligence such as ChatGPT. In particular, there has been a surge of academic interest in human‐AI collaboration and hybrid intelligence in learning. The concept of hybrid intelligence is still at a nascent stage, and how learners can benefit from a symbiotic relationship with various agents such as AI, human experts and intelligent learning systems is still unknown. The emerging concept of hybrid intelligence also lacks deep insights and understanding of the mechanisms and consequences of hybrid human‐AI learning based on strong empirical research. In order to address this gap, we conducted a randomised experimental study and compared learners' motivations, self‐regulated learning processes and learning performances on a writing task among different groups who had support from different agents, that is, ChatGPT (also referred to as the AI group), chat with a human expert, writing analytics tools, and no extra tool. A total of 117 university students were recruited, and their multi‐channel learning, performance and motivation data were collected and analysed. The results revealed that: (1) learners who received different learning support showed no difference in post‐task intrinsic motivation; (2) there were significant differences in the frequency and sequences of the self‐regulated learning processes among groups; (3) ChatGPT group outperformed in the essay score improvement but their knowledge gain and transfer were not significantly different. Our research found that in the absence of differences in motivation, learners with different supports still exhibited different self‐regulated learning processes, ultimately leading to differentiated performance. What is particularly noteworthy is that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger “metacognitive laziness”. In conclusion, understanding and leveraging the respective strengths and weaknesses of different agents in learning is critical in the field of future hybrid intelligence.
Practitioner notes
What is already known about this topic
Hybrid intelligence, combining human and machine intelligence, aims to augment human capabilities rather than replace them, creating opportunities for more effective lifelong learning and collaboration.
Generative AI, such as ChatGPT, has shown potential in enhancing learning by providing immediate feedback, overcoming language barriers and facilitating personalised educational experiences.
The effectiveness of AI in educational contexts varies, with some studies highlighting its benefits in improving academic performance and motivation, while others note limitations in its ability to replace human teachers entirely.
What this paper adds
We conducted a randomised experimental study in the lab setting and compared learners' motivations, self‐regulated learning processes and learning performances among different agent groups (AI, human expert and checklist tools).
We found that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger metacognitive ""laziness"", which can potentially hinder their ability to self‐regulate and engage deeply in learning.
We also found that ChatGPT can significantly improve short‐term task performance, but it may not boost intrinsic motivation and knowledge gain and transfer.
Implications for practice and/or policy
When using AI in learning, learners should focus on deepening their …",3,4,Britsh Journal of Educational Technology,2024,https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.13544,Learning,GPT-4,117,Conversation,F,"1. AI education does not improve people's learning interest.

2. AI triggers ""metacognitive laziness."" People rely on AI to offload tasks like evaluation and reflection, reducing their participation in key learning processes.

3. AI improves short-term performance but does not help long-term learning. AI education cannot achieve knowledge transfer, nor can it enhance the understanding of knowledge (knowledge gain).",
Whether and When Could Generative AI Improve College Student Learning Engagement?,"Generative AI (GenAI) technologies have been widely adopted by college students since the launch of ChatGPT in late 2022. While the debate about GenAI’s role in higher education continues, there is a lack of empirical evidence regarding whether and when these technologies can improve the learning experience for college students. This study utilizes data from a survey of 72,615 undergraduate students across 25 universities and colleges in China to explore the relationships between GenAI use and student learning engagement in different learning environments. The findings reveal that over sixty percent of Chinese college students use GenAI technologies in Academic Year 2023–2024, with academic use exceeding daily use. GenAI use in academic tasks is related to more cognitive and emotional engagement, though it may also reduce active learning activities and learning motivation. Furthermore, this study highlights that the role of GenAI varies across learning environments. The positive associations of GenAI and student engagement are most prominent for students in “high-challenge and high-support” learning contexts, while GenAI use is mostly negatively associated with student engagement in “low-challenge, high-support” courses. These findings suggest that while GenAI plays a valuable role in the learning process for college students, its effectiveness is fundamentally conditioned by the instructional design of human teachers.",3,4,Behavioral Sciences,2025,https://www.mdpi.com/2076-328X/15/8/1011,Education,No experiments. Deepseak GPT,"72,615",Conversation,F,"1. GenAI has a high adoption rate (over 60%) among Chinese college students, but satisfaction with its academic utility is limited 。

2. A positive association was found with higher cognitive engagement (higher-order thinking) and aspects of emotional engagement, such as academic self-efficacy and resilience 。

3. A negative association was found with behavioral engagement (e.g., note-taking, reviewing) and, notably, with learning interest and learning motivation 。

4. The effect of GenAI is highly dependent on the ""learning environment"" 。he positive associations of GenAI are most prominent in ""high-challenge and high-support"" learning contexts 。GenAI use is mostly negatively associated with student engagement in ""high-support, low-challenge"" courses. The effectiveness of GenAI is ""fundamentally conditioned by the instructional design of human teachers"".",
Trusting the Algorithm: Emotional Engagement with ChatGPT in Higher Education.,"This study examines emotional engagement with ChatGPT among 121 university students from diverse academic disciplines, focusing on the relationships between trust in the AI, the emotional framing of prompts, and the explicit use of ChatGPT for emotional support. Results reveal a paradox: higher trust correlates with increased emotional self-awareness (r=. 386) and perceived emotional intelligence (r=. 508), while deliberate emotional framing is linked to lower perceived AI emotional intelligence (r=–. 412) and reduced emotional benefits (r=–. 259). Students who use ChatGPT for emotional support report diminished emotional awareness (r=–. 190) and less favourable emotional outcomes (r=–. 270), indicating an “empathic expectation gap” where emotional intent exposes the system’s limitations. The findings highlight the need to integrate ChatGPT in digital pedagogy as a reflective tool rather than a substitute for human connection, with attention to ethical design, user education, and emotional literacy.",4,4,International Conference on Pedagogical Science and Digital Learning 2025,2025,https://doi.org/10.5281/ZENODO.17423731,Emotional Support Use,ChatGPT,121,Conversation,F,"Usage Patterns: While nearly half of students engage in emotional framing (M=1.45), only ~23% explicitly use ChatGPT for emotional support.

Basis of Trust: Trust is built on the AI being ""always available"" and ""non-judgmental,"" positioning it as a safe space for expression.

Emotional Outcomes: Students generally report neutral to moderately positive emotional results from these interactions (M=2.26).

Double-Edged Sword: While trust enables productive interaction, over-reliance on AI for regulation risks hindering personal emotional growth and diminishing human help-seeking behaviors.",
Exploring the Impact of Generative AI ChatGPT on Critical Thinking in Higher Education: Passive AI‑Directed Use or Human–AI Supported Collaboration?,"Generative AI is weaving into the fabric of many human aspects through its transformative power to mimic human-generated content. It is not a mere technology; it functions as a generative virtual assistant, raising concerns about its impact on cognition and critical thinking. This mixed-methods study investigates how GenAI ChatGPT affects critical thinking across cognitive presence (CP) phases. Forty students from a four-year university in the southwestern United States completed a survey; six provided their ChatGPT scripts, and two engaged in semi-structured interviews. Students’ self-reported survey responses suggested that GenAI ChatGPT improved triggering events (M = 3.60), exploration (M = 3.70), and integration (M = 3.60); however, responses remained neutral during the resolution stage. Two modes of interaction were revealed in the analysis of students’ ChatGPT scripts: passive, AI-directed use and collaborative, AI-supported interaction. A resolution gap was identified; nonetheless, the interview results revealed that when GenAI ChatGPT was utilized with guidance, all four stages of cognitive presence were completed, leading to enhanced critical thinking and a reconceptualization of ChatGPT as a more knowledgeable other. This research suggests that the effective use of GenAI in education depends on the quality of human–AI interaction. Future directions must orient toward an integration of GenAI in education that positions human and machine intelligence not as a substitution but as co-participation, opening new epistemic horizons while reconfiguring assessment practices to ensure that human oversight, critical inquiry, and reflective thinking remain at the center of learning.",3,4,Educ. Sci.,2025,https://www.mdpi.com/2227-7102/15/9/1198,Education,CHATGPT,40,Conversation,F,"1. LLMs, like ChatGPT, have the potential to support critical thinking in higher education if used collaboratively and with guidance. They can help students engage in true critical thinking, not just quick answers or cognitive offloading.

2. However, a major risk exists: passive use of AI can weaken, rather than enhance, deep learning and critical thinking. The effectiveness of LLMs depends heavily on how they are used, the educational design, and the human-AI collaboration framework.

3. To effectively use ChatGPT in education, institutions, educators, and course designers must carefully structure AI use — including when to use it, how to guide students, and ensure reflection and discussion — rather than simply opening access to ChatGPT.",
The Impact of ChatGPT on English as a Foreign Language Learners' Writing Skills – An Experimental Study at Georgian Universities,"This study explores the impact of ChatGPT on English as a Foreign Language (EFL) students' writing skills. The integration of advanced AI tools like ChatGPT has transformed educational experiences, offering significant potential to enhance writing competence through personalized feedback and interactive writing practice. Conducted in a Georgian higher education context, the study involved 33 B2-level students divided into experimental and control groups over six weeks. The experimental group used ChatGPT for writing assistance, while the control group received traditional instruction. Results showed that ChatGPT significantly improved students' writing performance, highlighting its efficacy as an educational tool. However, concerns about ethical use and over-reliance on AI were noted, emphasizing the need for a balanced integration of technology in language learning.",3,4,ESI,2025,https://eujournal.org/index.php/esj/article/view/19269?utm_source=chatgpt.com,Education,ChatGPT,33,Conversation,6 Weeks,"This study provides preliminary empirical evidence that, in EFL (English as a Foreign Language) writing training, ChatGPT significantly improves students' writing performance in a short-term (6-week) period compared to traditional methods, indicating a positive impact of LLMs (ChatGPT) on students' writing abilities and learning outcomes.",
