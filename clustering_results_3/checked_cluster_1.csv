title,abstract,Found_Cluster
Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task,"This study explores the neural and behavioral consequences of LLM-assisted essay writing. Participants were divided into three groups: LLM, Search Engine, and Brain-only (no tools). Each completed three sessions under the same condition. In a fourth session, LLM users were reassigned to Brain-only group (LLM-to-Brain), and Brain-only users were reassigned to LLM condition (Brain-to-LLM). A total of 54 participants took part in Sessions 1-3, with 18 completing session 4. We used electroencephalography (EEG) to assess cognitive load during essay writing, and analyzed essays using NLP, as well as scoring essays with the help from human teachers and an AI judge. Across groups, NERs, n-gram patterns, and topic ontology showed within-group homogeneity. EEG revealed significant differences in brain connectivity: Brain-only participants exhibited the strongest, most distributed networks; Search Engine users showed moderate engagement; and LLM users displayed the weakest connectivity. Cognitive activity scaled down in relation to external tool use. In session 4, LLM-to-Brain participants showed reduced alpha and beta connectivity, indicating under-engagement. Brain-to-LLM users exhibited higher memory recall and activation of occipito-parietal and prefrontal areas, similar to Search Engine users. Self-reported ownership of essays was the lowest in the LLM group and the highest in the Brain-only group. LLM users also struggled to accurately quote their own work. While LLMs offer immediate convenience, our findings highlight potential cognitive costs. Over four months, LLM users consistently underperformed at neural, linguistic, and behavioral levels. These results raise concerns about the long-term educational implications of LLM reliance and underscore the need for deeper inquiry into AI's role in learning.",2
Generative AI without guardrails can harm learning: Evidence from high school mathematics,"Generative AI is poised to revolutionize how humans work, and has already demonstrated promise in significantly improving human productivity. A key question is how generative AI affects learning〞namely, how humans acquire new skills as they perform tasks. Learning is critical to long-term productivity, especially since generative AI is fallible and users must check its outputs. We study this question via a field experiment where we provide nearly a thousand high school math students with access to generative AI tutors. To understand the differential impact of tool design on learning, we deploy two generative AI tutors: one that mimics a standard ChatGPT interface (※GPT Base§) and one with prompts designed to safeguard learning (※GPT Tutor§). Consistent with prior work, our results show that having GPT-4 access while solving problems significantly improves performance (48% improvement in grades for GPT Base and 127% for GPT Tutor). However, we additionally find that when access is subsequently taken away, students actually perform worse than those who never had access (17% reduction in grades for GPT Base)〞i.e., unfettered access to GPT-4 can harm educational outcomes. These negative learning effects are largely mitigated by the safeguards in GPT Tutor. Without guardrails, students attempt to use GPT-4 as a ※crutch§ during practice problem sessions, and subsequently perform worse on their own. Thus, decision-makers must be cautious about design choices underlying generative AI deployments to preserve skill learning and long-term productivity.",3
"Beware of metacognitive laziness: Effects of generative artificial intelligence on learning motivation, processes, and performance","Abstract
With the continuous development of technological and educational innovation, learners nowadays can obtain a variety of supports from agents such as teachers, peers, education technologies, and recently, generative artificial intelligence such as ChatGPT. In particular, there has been a surge of academic interest in human坼AI collaboration and hybrid intelligence in learning. The concept of hybrid intelligence is still at a nascent stage, and how learners can benefit from a symbiotic relationship with various agents such as AI, human experts and intelligent learning systems is still unknown. The emerging concept of hybrid intelligence also lacks deep insights and understanding of the mechanisms and consequences of hybrid human坼AI learning based on strong empirical research. In order to address this gap, we conducted a randomised experimental study and compared learners' motivations, self坼regulated learning processes and learning performances on a writing task among different groups who had support from different agents, that is, ChatGPT (also referred to as the AI group), chat with a human expert, writing analytics tools, and no extra tool. A total of 117 university students were recruited, and their multi坼channel learning, performance and motivation data were collected and analysed. The results revealed that: (1) learners who received different learning support showed no difference in post坼task intrinsic motivation; (2) there were significant differences in the frequency and sequences of the self坼regulated learning processes among groups; (3) ChatGPT group outperformed in the essay score improvement but their knowledge gain and transfer were not significantly different. Our research found that in the absence of differences in motivation, learners with different supports still exhibited different self坼regulated learning processes, ultimately leading to differentiated performance. What is particularly noteworthy is that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger ※metacognitive laziness§. In conclusion, understanding and leveraging the respective strengths and weaknesses of different agents in learning is critical in the field of future hybrid intelligence.
Practitioner notes
What is already known about this topic
Hybrid intelligence, combining human and machine intelligence, aims to augment human capabilities rather than replace them, creating opportunities for more effective lifelong learning and collaboration.
Generative AI, such as ChatGPT, has shown potential in enhancing learning by providing immediate feedback, overcoming language barriers and facilitating personalised educational experiences.
The effectiveness of AI in educational contexts varies, with some studies highlighting its benefits in improving academic performance and motivation, while others note limitations in its ability to replace human teachers entirely.
What this paper adds
We conducted a randomised experimental study in the lab setting and compared learners' motivations, self坼regulated learning processes and learning performances among different agent groups (AI, human expert and checklist tools).
We found that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger metacognitive ""laziness"", which can potentially hinder their ability to self坼regulate and engage deeply in learning.
We also found that ChatGPT can significantly improve short坼term task performance, but it may not boost intrinsic motivation and knowledge gain and transfer.
Implications for practice and/or policy
When using AI in learning, learners should focus on deepening their ＃",3
Whether and When Could Generative AI Improve College Student Learning Engagement?,"Generative AI (GenAI) technologies have been widely adopted by college students since the launch of ChatGPT in late 2022. While the debate about GenAI＊s role in higher education continues, there is a lack of empirical evidence regarding whether and when these technologies can improve the learning experience for college students. This study utilizes data from a survey of 72,615 undergraduate students across 25 universities and colleges in China to explore the relationships between GenAI use and student learning engagement in different learning environments. The findings reveal that over sixty percent of Chinese college students use GenAI technologies in Academic Year 2023每2024, with academic use exceeding daily use. GenAI use in academic tasks is related to more cognitive and emotional engagement, though it may also reduce active learning activities and learning motivation. Furthermore, this study highlights that the role of GenAI varies across learning environments. The positive associations of GenAI and student engagement are most prominent for students in ※high-challenge and high-support§ learning contexts, while GenAI use is mostly negatively associated with student engagement in ※low-challenge, high-support§ courses. These findings suggest that while GenAI plays a valuable role in the learning process for college students, its effectiveness is fundamentally conditioned by the instructional design of human teachers.",3
Trusting the Algorithm: Emotional Engagement with ChatGPT in Higher Education.,"This study examines emotional engagement with ChatGPT among 121 university students from diverse academic disciplines, focusing on the relationships between trust in the AI, the emotional framing of prompts, and the explicit use of ChatGPT for emotional support. Results reveal a paradox: higher trust correlates with increased emotional self-awareness (r=. 386) and perceived emotional intelligence (r=. 508), while deliberate emotional framing is linked to lower perceived AI emotional intelligence (r=每. 412) and reduced emotional benefits (r=每. 259). Students who use ChatGPT for emotional support report diminished emotional awareness (r=每. 190) and less favourable emotional outcomes (r=每. 270), indicating an ※empathic expectation gap§ where emotional intent exposes the system＊s limitations. The findings highlight the need to integrate ChatGPT in digital pedagogy as a reflective tool rather than a substitute for human connection, with attention to ethical design, user education, and emotional literacy.",4
Optimizing academic engagement and mental health through AI: an experimental study on LLM integration in higher education,"Background
In alignment with UNESCO's Sustainable Development Goal 4 (SDG4), which advocates for inclusive and equitable quality education, the integration of Artificial Intelligence tools〞particularly Large Language Models (LLMs)〞presents promising opportunities for transforming higher education. Despite this potential, empirical research remains scarce regarding the effects of LLM use on students' academic performance, mental well-being, and engagement, especially across different modes of implementation.
Objective
This experimental study investigated whether a guided, pedagogically grounded use of LLMs enhances students' academic writing quality, perceived mental health, and academic engagement more effectively than either unguided use or no exposure to LLMs. The study contributes to UNESCO's ""Futures of Education"" vision by exploring how structured AI use may foster more inclusive and empowering learning environments.
Method
A total of 246 undergraduate students were randomly assigned to one of three conditions: guided LLM use, unguided LLM use, or a control group with no LLM access. Participants completed a critical writing task and standardized instruments measuring academic engagement and mental well-being. Prior academic achievement was controlled for, and writing quality was assessed using Grammarly for Education.
Results
Students in the guided LLM condition achieved significantly higher scores in writing quality and academic engagement compared to the control group, with large and moderate effect sizes, respectively. Modest improvements in mental health indicators were also observed. By contrast, unguided use yielded moderate gains in writing quality but did not produce significant effects on engagement or well-being.
Conclusion
The findings highlight the critical role of intentional instructional design in the educational integration of AI tools. Structured guidance not only optimizes academic outcomes but also supports students' well-being and inclusion. This study offers empirical evidence to inform ongoing debates on how digital innovation can contribute to reducing educational disparities and advancing equitable learning in the post-pandemic era.",3
Impact of LLM Feedback on Learner Persistence in Programming,"Abstract
This study examines how Large Language Model (LLM) feedback generated for compiler errors impacts learners＊ persistence in programming tasks within a system for automated assessment of programming assignments. Persistence, the ability to maintain effort in the face of challenges, is crucial for academic success but can sometimes lead to unproductive"" wheel spinning"" when students struggle without progress. We investigated how additional LLM feedback based on the GPT-4 model, provided for compiler errors affects learners＊ persistence within a CS1 course. Specifically, we examined whether its impacts differ based on task difficulty, and if the effects persist after the feedback is removed. A randomized controlled trial involving 257 students across various programming tasks was conducted. Our findings reveal that LLM feedback improved some aspects of students＊ performance and persistence, such as increased scores, a higher likelihood of solving problems, and a lower tendency to demonstrate unproductive"" wheel spinning"" behavior. Notably, this positive impact was also observed in challenging tasks. However, its benefits did not sustain once the feedback was removed. The results highlight both the potential and limitations of LLM feedback, pointing out the need to promote long-term skill development and learning independent of immediate AI assistance.",3
Effects of LLM Use and NoteTaking on Reading Comprehension and Memory: A Randomised Experiment in Secondary Schools,"The rapid uptake of Generative AI, particularly large language models (LLMs), by students raises urgent questions about their effects on learning. We compared the impact of LLM use to that of traditional note-taking, or a combination of both, on secondary school students' reading comprehension and retention. We conducted a pre-registered, randomised controlled experiment with within-and between-participant design elements in schools. 405 students aged 14-15 studied two text passages and completed comprehension and retention tests three days later. Quantitative results demonstrated that both note-taking alone and combined with the LLM had significant positive effects on retention and comprehension compared to the LLM alone. Yet, most students preferred using the LLM over note-taking, and perceived it as more helpful. Qualitative results revealed that many students valued LLMs for making complex material more accessible and reducing cognitive load, while they appreciated note-taking for promoting deeper engagement and aiding memory. Additionally, we identified ""archetypes"" of prompting behaviour, offering insights into the different ways students interacted with the LLM. Overall, our findings suggest that, while note-taking promotes cognitive engagement and long-term comprehension and retention, LLMs may facilitate initial understanding and student interest. The study reveals the continued importance of traditional learning approaches, the benefits of combining AI use with traditional learning over using AI alone, and the AI skills that students need to maximise those benefits.",3
Exploring the Impact of Generative AI ChatGPT on Critical Thinking in Higher Education: Passive AI?Directed Use or Human每AI Supported Collaboration?,"Generative AI is weaving into the fabric of many human aspects through its transformative power to mimic human-generated content. It is not a mere technology; it functions as a generative virtual assistant, raising concerns about its impact on cognition and critical thinking. This mixed-methods study investigates how GenAI ChatGPT affects critical thinking across cognitive presence (CP) phases. Forty students from a four-year university in the southwestern United States completed a survey; six provided their ChatGPT scripts, and two engaged in semi-structured interviews. Students＊ self-reported survey responses suggested that GenAI ChatGPT improved triggering events (M = 3.60), exploration (M = 3.70), and integration (M = 3.60); however, responses remained neutral during the resolution stage. Two modes of interaction were revealed in the analysis of students＊ ChatGPT scripts: passive, AI-directed use and collaborative, AI-supported interaction. A resolution gap was identified; nonetheless, the interview results revealed that when GenAI ChatGPT was utilized with guidance, all four stages of cognitive presence were completed, leading to enhanced critical thinking and a reconceptualization of ChatGPT as a more knowledgeable other. This research suggests that the effective use of GenAI in education depends on the quality of human每AI interaction. Future directions must orient toward an integration of GenAI in education that positions human and machine intelligence not as a substitution but as co-participation, opening new epistemic horizons while reconfiguring assessment practices to ensure that human oversight, critical inquiry, and reflective thinking remain at the center of learning.",4
The Impact of ChatGPT on English as a Foreign Language Learners' Writing Skills 每 An Experimental Study at Georgian Universities,"This study explores the impact of ChatGPT on English as a Foreign Language (EFL) students' writing skills. The integration of advanced AI tools like ChatGPT has transformed educational experiences, offering significant potential to enhance writing competence through personalized feedback and interactive writing practice. Conducted in a Georgian higher education context, the study involved 33 B2-level students divided into experimental and control groups over six weeks. The experimental group used ChatGPT for writing assistance, while the control group received traditional instruction. Results showed that ChatGPT significantly improved students' writing performance, highlighting its efficacy as an educational tool. However, concerns about ethical use and over-reliance on AI were noted, emphasizing the need for a balanced integration of technology in language learning.",3
