<!doctype html><html data-n-head-ssr lang="en" data-n-head="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D%7D"><head ><meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" name="viewport" content="width=device-width, initial-scale=1"><meta data-n-head="ssr" name="msapplication-TileColor" content="#247CB3"><meta data-n-head="ssr" name="msapplication-TileImage" content="https://asset.jmir.pub/assets/static/images/mstile-144x144.png"><meta data-n-head="ssr" name="description" content="Large language model (LLM)-powered services are gaining popularity in various applications due to their exceptional performance in many tasks, such as sentiment analysis and question answering. Recently, research has been exploring their potential use in digital health contexts, particularly in the mental health domain. However, implementing LLM-enhanced conversational artificial intelligence (CAI) presents significant ethical, technical, and clinical challenges. In this work, we discuss two challenges that affect the utilization of LLM-enhanced CAI for individuals with mental health issues, focusing on the use case of depressed patients: the tendency to humanize LLM-enhanced CAI and their lack of contextualized robustness. Our approach is interdisciplinary, relying on considerations from philosophy, psychology, and computer science. We argue that the humanization of LLM-enhanced CAI hinges on the reflection of what it means to simulate “human-like” features with LLMs and what role these systems should have in interactions with humans. Further, to ensure contextualizing robustness of LLMs requires considering the specificities of language production in depressed individuals, as well as its evolution over time. Finally, we provide a series of recommendations to foster the responsible design and deployment of LLM-enhanced CAI for the therapeutic support of individuals with depression."><meta data-n-head="ssr" name="keywords" content="mental health; depression; ethics; digital health; artificial intelligence; machine learning; digital interventions; deep learning; natural language processing; digital technology; mental illness; digital intervention; mental illnesses; large language model; large language models; generative ai; nlp; ai; ml; llm; llms; mental disease; mental diseases"><meta data-n-head="ssr" name="DC.Title" content="The Role of Humanization and Robustness of Large Language Models in Conversational Artificial Intelligence for Individuals With Depression: A Critical Analysis"><meta data-n-head="ssr" name="DC.Subject" content="mental health; depression; ethics; digital health; artificial intelligence; machine learning; digital interventions; deep learning; natural language processing; digital technology; mental illness; digital intervention; mental illnesses; large language model; large language models; generative ai; nlp; ai; ml; llm; llms; mental disease; mental diseases"><meta data-n-head="ssr" name="DC.Description" content="Large language model (LLM)-powered services are gaining popularity in various applications due to their exceptional performance in many tasks, such as sentiment analysis and question answering. Recently, research has been exploring their potential use in digital health contexts, particularly in the mental health domain. However, implementing LLM-enhanced conversational artificial intelligence (CAI) presents significant ethical, technical, and clinical challenges. In this work, we discuss two challenges that affect the utilization of LLM-enhanced CAI for individuals with mental health issues, focusing on the use case of depressed patients: the tendency to humanize LLM-enhanced CAI and their lack of contextualized robustness. Our approach is interdisciplinary, relying on considerations from philosophy, psychology, and computer science. We argue that the humanization of LLM-enhanced CAI hinges on the reflection of what it means to simulate “human-like” features with LLMs and what role these systems should have in interactions with humans. Further, to ensure contextualizing robustness of LLMs requires considering the specificities of language production in depressed individuals, as well as its evolution over time. Finally, we provide a series of recommendations to foster the responsible design and deployment of LLM-enhanced CAI for the therapeutic support of individuals with depression."><meta data-n-head="ssr" name="DC.Publisher" content="JMIR Mental Health"><meta data-n-head="ssr" name="DC.Publisher.Address" content="JMIR Publications // 130 Queens Quay East, Unit 1100 // Toronto, ON, M5A 0P6"><meta data-n-head="ssr" name="DC.Date" scheme="ISO8601" content="2024-07-02"><meta data-n-head="ssr" name="DC.Type" content="Text.Serial.Journal"><meta data-n-head="ssr" name="DC.Format" scheme="IMT" content="text/xml"><meta data-n-head="ssr" name="DC.Identifier" content="doi:10.2196/56569"><meta data-n-head="ssr" name="DC.Language" scheme="ISO639-1" content="EN"><meta data-n-head="ssr" name="DC.Relation" content="World"><meta data-n-head="ssr" name="DC.Source" content="JMIR Ment Health 2024;11:e56569 https://mental.jmir.org/2024/1/e56569"><meta data-n-head="ssr" name="DC.Rights" content="Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work (&quot;first published in the Journal of Medical Internet Research...&quot;) is properly cited with original URL and bibliographic citation information. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included."><meta data-n-head="ssr" property="og:title" content="The Role of Humanization and Robustness of Large Language Models in Conversational Artificial Intelligence for Individuals With Depression: A Critical Analysis"><meta data-n-head="ssr" property="og:type" content="article"><meta data-n-head="ssr" property="og:url" content="https://mental.jmir.org/2024/1/e56569"><meta data-n-head="ssr" property="og:image" content="https://asset.jmir.pub/assets/c5a135a21a23692e7b6cb5f40e6b9dda.png"><meta data-n-head="ssr" property="og:site_name" content="JMIR Mental Health"><meta data-n-head="ssr" name="twitter:card" content="summary_large_image"><meta data-n-head="ssr" name="twitter:site" content="@jmirpub"><meta data-n-head="ssr" name="twitter:title" content="The Role of Humanization and Robustness of Large Language Models in Conversational Artificial Intelligence for Individuals With Depression: A Critical Analysis"><meta data-n-head="ssr" name="twitter:description" content="Large language model (LLM)-powered services are gaining popularity in various applications due to their exceptional performance in many tasks, such as sentiment analysis and question answering. Recently, research has been exploring their potential use in digital health contexts, particularly in the mental health domain. However, implementing LLM-enhanced conversational artificial intelligence (CAI) presents significant ethical, technical, and clinical challenges. In this work, we discuss two challenges that affect the utilization of LLM-enhanced CAI for individuals with mental health issues, focusing on the use case of depressed patients: the tendency to humanize LLM-enhanced CAI and their lack of contextualized robustness. Our approach is interdisciplinary, relying on considerations from philosophy, psychology, and computer science. We argue that the humanization of LLM-enhanced CAI hinges on the reflection of what it means to simulate “human-like” features with LLMs and what role these systems should have in interactions with humans. Further, to ensure contextualizing robustness of LLMs requires considering the specificities of language production in depressed individuals, as well as its evolution over time. Finally, we provide a series of recommendations to foster the responsible design and deployment of LLM-enhanced CAI for the therapeutic support of individuals with depression."><meta data-n-head="ssr" name="twitter:image" content="https://asset.jmir.pub/assets/c5a135a21a23692e7b6cb5f40e6b9dda.png"><meta data-n-head="ssr" name="citation_title" content="The Role of Humanization and Robustness of Large Language Models in Conversational Artificial Intelligence for Individuals With Depression: A Critical Analysis"><meta data-n-head="ssr" name="citation_journal_title" content="JMIR Mental Health"><meta data-n-head="ssr" name="citation_publisher" content="JMIR Publications Inc., Toronto, Canada"><meta data-n-head="ssr" name="citation_doi" content="10.2196/56569"><meta data-n-head="ssr" name="citation_issue" content="1"><meta data-n-head="ssr" name="citation_volume" content="11"><meta data-n-head="ssr" name="citation_firstpage" content="e56569"><meta data-n-head="ssr" name="citation_date" content="2024-07-02"><meta data-n-head="ssr" name="citation_abstract_html_url" content="https://mental.jmir.org/2024/1/e56569"><meta data-n-head="ssr" name="citation_abstract_pdf_url" content="https://mental.jmir.org/2024/1/e56569/PDF"><meta data-n-head="ssr" name="DC.Creator" content="Andrea Ferrario"><meta data-n-head="ssr" name="DC.Contributor" content="Andrea Ferrario"><meta data-n-head="ssr" name="DC.Contributor" content="Jana Sedlakova"><meta data-n-head="ssr" name="DC.Contributor" content="Manuel Trachsel"><meta data-n-head="ssr" name="citation_authors" content="Andrea Ferrario"><meta data-n-head="ssr" name="citation_authors" content="Jana Sedlakova"><meta data-n-head="ssr" name="citation_authors" content="Manuel Trachsel"><title>JMIR Mental Health - The Role of Humanization and Robustness of Large Language Models in Conversational Artificial Intelligence for Individuals With Depression: A Critical Analysis</title><link data-n-head="ssr" rel="apple-touch-icon" sizes="57x57" href="https://asset.jmir.pub/assets/static/images/apple-touch-icon-57x57.png"><link data-n-head="ssr" rel="apple-touch-icon" sizes="114x114" href="https://asset.jmir.pub/assets/static/images/apple-touch-icon-114x114.png"><link data-n-head="ssr" rel="apple-touch-icon" sizes="72x72" href="https://asset.jmir.pub/assets/static/images/apple-touch-icon-72x72.png"><link data-n-head="ssr" rel="apple-touch-icon" sizes="144x144" href="https://asset.jmir.pub/assets/static/images/apple-touch-icon-144x144.png"><link data-n-head="ssr" rel="apple-touch-icon" sizes="60x60" href="https://asset.jmir.pub/assets/static/images/apple-touch-icon-60x60.png"><link data-n-head="ssr" rel="apple-touch-icon" sizes="120x120" href="https://asset.jmir.pub/assets/static/images/apple-touch-icon-120x120.png"><link data-n-head="ssr" rel="apple-touch-icon" sizes="76x76" href="https://asset.jmir.pub/assets/static/images/apple-touch-icon-76x76.png"><link data-n-head="ssr" rel="apple-touch-icon" sizes="152x152" href="https://asset.jmir.pub/assets/static/images/apple-touch-icon-152x152.png"><link data-n-head="ssr" rel="icon" type="image/png" href="https://asset.jmir.pub/assets/static/images/favicon-196x196.png" sizes="196x196"><link data-n-head="ssr" rel="icon" type="image/png" href="https://asset.jmir.pub/assets/static/images/favicon-160x160.png" sizes="160x160"><link data-n-head="ssr" rel="icon" type="image/png" href="https://asset.jmir.pub/assets/static/images/favicon-96x96.png" sizes="96x96"><link data-n-head="ssr" rel="icon" type="image/png" href="https://asset.jmir.pub/assets/static/images/favicon-16x16.png" sizes="16x16"><link data-n-head="ssr" rel="icon" type="image/png" href="https://asset.jmir.pub/assets/static/images/favicon-32x32.png" sizes="32x32"><link data-n-head="ssr" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap-grid.min.css" defer><link data-n-head="ssr" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" defer><link data-n-head="ssr" rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:100,100i,300,300i,400,400i,500,500i,700,700i,900,900i&amp;display=swap" defer><link data-n-head="ssr" rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><link data-n-head="ssr" rel="canonical" href="/2024/1/e56569"><script data-n-head="ssr" data-hid="gtm-script">if(!window._gtm_init){window._gtm_init=1;(function(w,n,d,m,e,p){w[d]=(w[d]==1||n[d]=='yes'||n[d]==1||n[m]==1||(w[e]&&w[e][p]&&w[e][p]()))?1:0})(window,navigator,'doNotTrack','msDoNotTrack','external','msTrackingProtectionEnabled');(function(w,d,s,l,x,y){w[x]={};w._gtm_inject=function(i){w[x][i]=1;w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s);j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i;f.parentNode.insertBefore(j,f);};w[y]('GTM-58BHBF4V')})(window,document,'script','dataLayer','_gtm_ids','_gtm_inject')}</script><script data-n-head="ssr" type="text/javascript" id="hs-script-loader" src="//js.hs-scripts.com/19668141.js"></script><script data-n-head="ssr" data-hid="twitter-script" type="text/javascript" charset="utf-8">
                !function(e,t,n,s,u,a){e.twq||(s=e.twq=function(){s.exe?s.exe.apply(s,arguments):s.queue.push(arguments);},s.version='1.1',s.queue=[],u=t.createElement(n),u.async=!0,u.src='https://static.ads-twitter.com/uwt.js',a=t.getElementsByTagName(n)[0],a.parentNode.insertBefore(u,a))}(window,document,'script');twq('config','o7i83');
                </script><script data-n-head="ssr" src="https://js.trendmd.com/trendmd-ns.min.js" defer data-trendmdconfig="{"element": "#trendmd-suggestions"}"></script><link rel="preload" href="/_nuxt/9c7c1e4.js" as="script"><link rel="preload" href="/_nuxt/797995a.js" as="script"><link rel="preload" href="/_nuxt/d965382.js" as="script"><link rel="preload" href="/_nuxt/4927325.js" as="script"><link rel="preload" href="/_nuxt/2bde5b8.js" as="script"><link rel="preload" href="/_nuxt/1326996.js" as="script"><link rel="preload" href="/_nuxt/09b1d65.js" as="script"><link rel="preload" href="/_nuxt/366ad09.js" as="script"><link rel="preload" href="/_nuxt/95fde3b.js" as="script"><link rel="preload" href="/_nuxt/d0c41c5.js" as="script"><link rel="preload" href="/_nuxt/e6dad64.js" as="script"><link rel="preload" href="/_nuxt/84066b5.js" as="script"><link rel="preload" href="/_nuxt/fc6cf93.js" as="script"><link rel="preload" href="/_nuxt/14f78e7.js" as="script"><link rel="preload" href="/_nuxt/aa08135.js" as="script"><link rel="preload" href="/_nuxt/75832c0.js" as="script"><link rel="preload" href="/_nuxt/4436098.js" as="script"><link rel="preload" href="/_nuxt/bcc9d63.js" as="script"><link rel="preload" href="/_nuxt/3d6a000.js" as="script"><link rel="preload" href="/_nuxt/98a1aa4.js" as="script"><link rel="preload" href="/_nuxt/89ba270.js" as="script"><link rel="preload" href="/_nuxt/bc9dad6.js" as="script"><link rel="preload" href="/_nuxt/fc087e0.js" as="script"><link rel="preload" href="/_nuxt/b643d0c.js" as="script"><link rel="preload" href="/_nuxt/68827e8.js" as="script"><link rel="preload" href="/_nuxt/421b4ad.js" as="script"><link rel="preload" href="/_nuxt/bbb2307.js" as="script"><link rel="preload" href="/_nuxt/d9f2686.js" as="script"><link rel="preload" href="/_nuxt/255fd1e.js" as="script"><link rel="preload" href="/_nuxt/0bceff3.js" as="script"><link rel="preload" href="/_nuxt/7b27d0b.js" as="script"><link rel="preload" href="/_nuxt/e8be31d.js" as="script"><link rel="preload" href="/_nuxt/70e9da6.js" as="script"><link rel="preload" href="/_nuxt/beec627.js" as="script"><link rel="preload" href="/_nuxt/f98275c.js" as="script"><link rel="preload" href="/_nuxt/4c795dc.js" as="script"><link rel="preload" href="/_nuxt/08b91c7.js" as="script"><link rel="preload" href="/_nuxt/3df9693.js" as="script"><link rel="preload" href="/_nuxt/9a1b312.js" as="script"><link rel="preload" href="/_nuxt/21899a6.js" as="script"><link rel="preload" href="/_nuxt/bf91a67.js" as="script"><link rel="preload" href="/_nuxt/e7d56e2.js" as="script"><link rel="preload" href="/_nuxt/9c711d7.js" as="script"><link rel="preload" href="/_nuxt/a116589.js" as="script"><link rel="preload" href="/_nuxt/e8da5fa.js" as="script"><link rel="preload" href="/_nuxt/b70fdb7.js" as="script"><link rel="preload" href="/_nuxt/4916c14.js" as="script"><link rel="preload" href="/_nuxt/8043cc4.js" as="script"><style data-vue-ssr-id="7975b328:0 b8d2539e:0 f8852dd4:0 5afb56e8:0 19d22970:0 e58746f2:0 6f03c485:0 483225a2:0 0c0ff74d:0 27636745:0 1f7e98f9:0 d8137ec4:0">.mt-0{margin-top:0!important}.mt-5{margin-top:5px!important}.mt-10{margin-top:10px!important}.mt-15{margin-top:15px!important}.mt-20{margin-top:20px!important}.mt-25{margin-top:25px!important}.mt-30{margin-top:30px!important}.mt-35{margin-top:35px!important}.mt-40{margin-top:40px!important}.mt-45{margin-top:45px!important}.mt-50{margin-top:50px!important}.mt-55{margin-top:55px!important}.mt-60{margin-top:60px!important}.mt-65{margin-top:65px!important}.mt-70{margin-top:70px!important}.mt-75{margin-top:75px!important}.mt-80{margin-top:80px!important}.mt-85{margin-top:85px!important}.mt-90{margin-top:90px!important}.mt-95{margin-top:95px!important}.mt-100{margin-top:100px!important}.mb-0{margin-bottom:0!important}.mb-5{margin-bottom:5px!important}.mb-10{margin-bottom:10px!important}.mb-15{margin-bottom:15px!important}.mb-20{margin-bottom:20px!important}.mb-25{margin-bottom:25px!important}.mb-30{margin-bottom:30px!important}.mb-35{margin-bottom:35px!important}.mb-40{margin-bottom:40px!important}.mb-45{margin-bottom:45px!important}.mb-50{margin-bottom:50px!important}.mb-55{margin-bottom:55px!important}.mb-60{margin-bottom:60px!important}.mb-65{margin-bottom:65px!important}.mb-70{margin-bottom:70px!important}.mb-75{margin-bottom:75px!important}.mb-80{margin-bottom:80px!important}.mb-85{margin-bottom:85px!important}.mb-90{margin-bottom:90px!important}.mb-95{margin-bottom:95px!important}.mb-100{margin-bottom:100px!important}.ml-0{margin-left:0!important}.ml-5{margin-left:5px!important}.ml-10{margin-left:10px!important}.ml-15{margin-left:15px!important}.ml-20{margin-left:20px!important}.ml-25{margin-left:25px!important}.ml-30{margin-left:30px!important}.ml-35{margin-left:35px!important}.ml-40{margin-left:40px!important}.ml-45{margin-left:45px!important}.ml-50{margin-left:50px!important}.ml-55{margin-left:55px!important}.ml-60{margin-left:60px!important}.ml-65{margin-left:65px!important}.ml-70{margin-left:70px!important}.ml-75{margin-left:75px!important}.ml-80{margin-left:80px!important}.ml-85{margin-left:85px!important}.ml-90{margin-left:90px!important}.ml-95{margin-left:95px!important}.ml-100{margin-left:100px!important}.mr-0{margin-right:0!important}.mr-5{margin-right:5px!important}.mr-10{margin-right:10px!important}.mr-15{margin-right:15px!important}.mr-20{margin-right:20px!important}.mr-25{margin-right:25px!important}.mr-30{margin-right:30px!important}.mr-35{margin-right:35px!important}.mr-40{margin-right:40px!important}.mr-45{margin-right:45px!important}.mr-50{margin-right:50px!important}.mr-55{margin-right:55px!important}.mr-60{margin-right:60px!important}.mr-65{margin-right:65px!important}.mr-70{margin-right:70px!important}.mr-75{margin-right:75px!important}.mr-80{margin-right:80px!important}.mr-85{margin-right:85px!important}.mr-90{margin-right:90px!important}.mr-95{margin-right:95px!important}.mr-100{margin-right:100px!important}.pt-0{padding-top:0!important}.pt-5{padding-top:5px!important}.pt-10{padding-top:10px!important}.pt-15{padding-top:15px!important}.pt-20{padding-top:20px!important}.pt-25{padding-top:25px!important}.pt-30{padding-top:30px!important}.pt-35{padding-top:35px!important}.pt-40{padding-top:40px!important}.pt-45{padding-top:45px!important}.pt-50{padding-top:50px!important}.pt-55{padding-top:55px!important}.pt-60{padding-top:60px!important}.pt-65{padding-top:65px!important}.pt-70{padding-top:70px!important}.pt-75{padding-top:75px!important}.pt-80{padding-top:80px!important}.pt-85{padding-top:85px!important}.pt-90{padding-top:90px!important}.pt-95{padding-top:95px!important}.pt-100{padding-top:100px!important}.pb-0{padding-bottom:0!important}.pb-5{padding-bottom:5px!important}.pb-10{padding-bottom:10px!important}.pb-15{padding-bottom:15px!important}.pb-20{padding-bottom:20px!important}.pb-25{padding-bottom:25px!important}.pb-30{padding-bottom:30px!important}.pb-35{padding-bottom:35px!important}.pb-40{padding-bottom:40px!important}.pb-45{padding-bottom:45px!important}.pb-50{padding-bottom:50px!important}.pb-55{padding-bottom:55px!important}.pb-60{padding-bottom:60px!important}.pb-65{padding-bottom:65px!important}.pb-70{padding-bottom:70px!important}.pb-75{padding-bottom:75px!important}.pb-80{padding-bottom:80px!important}.pb-85{padding-bottom:85px!important}.pb-90{padding-bottom:90px!important}.pb-95{padding-bottom:95px!important}.pb-100{padding-bottom:100px!important}.pl-0{padding-left:0!important}.pl-5{padding-left:5px!important}.pl-10{padding-left:10px!important}.pl-15{padding-left:15px!important}.pl-20{padding-left:20px!important}.pl-25{padding-left:25px!important}.pl-30{padding-left:30px!important}.pl-35{padding-left:35px!important}.pl-40{padding-left:40px!important}.pl-45{padding-left:45px!important}.pl-50{padding-left:50px!important}.pl-55{padding-left:55px!important}.pl-60{padding-left:60px!important}.pl-65{padding-left:65px!important}.pl-70{padding-left:70px!important}.pl-75{padding-left:75px!important}.pl-80{padding-left:80px!important}.pl-85{padding-left:85px!important}.pl-90{padding-left:90px!important}.pl-95{padding-left:95px!important}.pl-100{padding-left:100px!important}.pr-0{padding-right:0!important}.pr-5{padding-right:5px!important}.pr-10{padding-right:10px!important}.pr-15{padding-right:15px!important}.pr-20{padding-right:20px!important}.pr-25{padding-right:25px!important}.pr-30{padding-right:30px!important}.pr-35{padding-right:35px!important}.pr-40{padding-right:40px!important}.pr-45{padding-right:45px!important}.pr-50{padding-right:50px!important}.pr-55{padding-right:55px!important}.pr-60{padding-right:60px!important}.pr-65{padding-right:65px!important}.pr-70{padding-right:70px!important}.pr-75{padding-right:75px!important}.pr-80{padding-right:80px!important}.pr-85{padding-right:85px!important}.pr-90{padding-right:90px!important}.pr-95{padding-right:95px!important}.pr-100{padding-right:100px!important}input,select,textarea{border-radius:3px!important;font-size:1.6rem!important}textarea{font-family:Roboto-Regular,Roboto}input[type=date],input[type=email],input[type=hidden],input[type=number],input[type=search],input[type=tel],input[type=text],input[type=url]{border:1px solid rgba(26,37,76,.396);height:3.2rem;padding:0 10px}input[type=date]:focus,input[type=email]:focus,input[type=hidden]:focus,input[type=number]:focus,input[type=search]:focus,input[type=tel]:focus,input[type=text]:focus,input[type=url]:focus{background-color:rgba(48,136,223,.071);border:1px solid #1e70c2;outline:none}input::-moz-placeholder{opacity:.4}input::placeholder{opacity:.4}.v-select .vs__selected{margin:2px}.v-select .vs__dropdown-toggle{border:1px solid rgba(26,37,76,.396)!important;padding:0!important}.v-select input{border:1px solid transparent!important;margin:0}.v-select ul.vs__dropdown-menu{paddinng-top:0!important}.v-select.vs--single .vs__selected{margin:0 3px 0 5px}textarea{border:1px solid rgba(26,37,76,.396);padding:5px 10px;width:100%}textarea:focus{background-color:rgba(48,136,223,.071);border:1px solid #1e70c2;outline:none}select{border:1px solid rgba(26,37,76,.396);cursor:pointer;height:3.2rem}select:focus{background-color:rgba(48,136,223,.071);border:1px solid #1e70c2;outline:none}input::-webkit-input-placeholder,textarea::-webkit-input-placeholder{font-size:1.2rem}select::-webkit-input-placeholder{font-size:1.2rem}::-moz-selection{background-color:#1e70c2;color:#fff}::selection{background-color:#1e70c2;color:#fff}a{color:#1e70c2;outline:none;-webkit-text-decoration:none;text-decoration:none}a:focus,a:hover{-webkit-text-decoration:underline;text-decoration:underline}a:focus{font-weight:700}button:focus{outline:none}.deactive{cursor:not-allowed;pointer-events:none}.element-wrapper{margin-bottom:7rem}.page-heading{background-color:#f1f3f5;border-bottom:1px solid hsla(0,0%,44%,.161);margin-bottom:60px;padding:30px 0}.page-heading h1{margin:0}.link{color:#2078cf;outline:none;-webkit-text-decoration:none;text-decoration:none}.link:focus,.link:hover{color:#2078cf;-webkit-text-decoration:underline;text-decoration:underline}.title-link{color:#1a254c;outline:none;-webkit-text-decoration:none;text-decoration:none}.title-link:focus,.title-link:hover{color:#2078cf;-webkit-text-decoration:underline;text-decoration:underline}.h1,.h2,.h3,.h4,.h5,.h6,h2,h3,h4,h5,h6,pwdh1{font-weight:700}.h1,h1{font-size:4rem;line-height:5rem}.h2,h2{font-size:3.2rem;line-height:4rem}.h3,h3{font-size:2.6rem;line-height:3.4rem}.h4,h4{font-size:1.8rem;line-height:2.4rem}.h5,h5{font-size:1.6rem;line-height:2.2rem}.h6,h6{font-size:1.4rem}.h6,h6,p{line-height:2rem}small{line-height:1.8rem}.h1{font-size:4rem!important;line-height:5rem!important}.h2{font-size:3.2rem!important;line-height:4rem!important}.h3{font-size:2.6rem!important;line-height:3.4rem!important}.h4{font-size:1.8rem!important;line-height:2.4rem!important}.h5{font-size:1.6rem!important;line-height:2.2rem!important}.h6{font-size:1.4rem!important;line-height:2rem!important}input.disabled,select.disabled,textarea.disabled{background:hsla(0,0%,82%,.29);cursor:not-allowed}button.disabled{cursor:not-allowed;opacity:.5;pointer-events:none}strong{font-weight:700!important}.disabled-section{cursor:not-allowed;opacity:.5}.fa,.fas{font-weight:900}.errors{color:red;display:block}.screen-readers-only{height:1px;left:-10000px;overflow:hidden;position:absolute;top:auto;width:1px}input[type=text].input-error{border:1px solid red!important;border-radius:3px}.input-error{border:1px solid red!important;border-radius:3px}.popper{max-width:400px;padding:10px;text-align:justify}.vue-notification{margin:20px 20px 0 0}.vue-notification.toast-success{background:#4caf50;border-left:5px solid #1a254c}.vue-dropzone{border:2px dashed #e5e5e5}.vue-dropzone .icon{display:block;font-size:25px;margin-bottom:10px}.required:before{color:red;content:"*"}.grey-heading-underline{border-bottom:2px solid #c8cad4}.green-heading-underline{border-bottom:2px solid #367c3a}.green-underline{background:#367c3a;content:"";height:3px;margin:0 auto 40px;width:100px}.separator{color:#000;margin:0 10px;opacity:.4}.list-style-none{list-style-type:none}.list-style-none li{margin-bottom:10px}.width-100{width:100%!important}.width-fit-content{width:-moz-fit-content;width:fit-content}.break-word{word-break:break-word}.text-center{text-align:center}.d-inline-block{display:inline-block}.d-flex{display:flex}.d-block{display:block}.flex-direction-column{flex-direction:column}.justify-content-space-between{justify-content:space-between}.align-items-center{align-items:center}.align-items-baseline{align-items:baseline}.fs-10{font-size:1rem;line-height:1.6rem}.fs-12{font-size:1.2rem;line-height:1.8rem}.fs-14{font-size:1.4rem;line-height:2rem}.fs-16{font-size:1.6rem;line-height:2.4rem}.fs-18{font-size:1.8rem;line-height:2.6rem}.fs-20{font-size:2rem;line-height:3rem}.fs-italic{font-style:italic}.fw-bold{font-weight:700}.color-blue{color:#1e70c2}.color-green{color:#367c3a}.color-red{color:#b30000}.ql-toolbar{background-color:#f8f9fa}.btn{cursor:pointer;opacity:1;text-align:center;transition:.3s}.btn:focus,.btn:hover{font-weight:400;opacity:.9;-webkit-text-decoration:none;text-decoration:none}.btn:focus{outline:2px solid #f69038!important;outline-offset:6px!important}.btn-disabled{cursor:not-allowed;opacity:.6;pointer-events:none}.btn-small{font-size:1.2rem;padding:5px 10px}.btn-medium{font-size:1.4rem;padding:10px 20px}.btn-large{font-size:1.8rem;padding:20px 40px}.btn-blue{background-color:#1e70c2;border:1px solid #1e70c2;color:#fff}.btn-blue:active{background-color:#2b7bca;border:1px solid #2b7bca}.btn-green{background-color:#367c3a;border:1px solid #367c3a;color:#fff}.btn-green:active{background-color:#3b9d3f;border:1px solid #3b9d3f}.btn-grey{background-color:#f1f3f5;border:1px solid #dcdee0;color:#1a254c}.btn-grey:active{background-color:#dcdee0}.btn-red{background-color:#b30000;border:1px solid #b30000;color:#fff}.btn-red:active{background-color:#ba302d;border:1px solid #ba302d}.btn-blue-pill{background-color:inherit;border:none;border-radius:20px;color:#1e70c2;cursor:pointer;font-size:1.4rem;padding:5px 10px;transition:.3s}.btn-blue-pill:focus,.btn-blue-pill:hover{background-color:rgba(48,136,223,.161);-webkit-text-decoration:none;text-decoration:none}.btn-blue-pill:active{background-color:rgba(48,136,223,.29)}.btn-green-pill{background-color:inherit;border:none;border-radius:20px;color:#367c3a;cursor:pointer;font-size:1.4rem;padding:5px 10px;transition:.3s}.btn-green-pill:focus,.btn-green-pill:hover{background-color:rgba(76,175,80,.188);-webkit-text-decoration:none;text-decoration:none}.btn-green-pill:active{background-color:rgba(76,175,80,.29)}.btn-grey-pill{background-color:inherit;border:none;border-radius:20px;color:#1a254c;cursor:pointer;font-size:1.4rem;padding:5px 10px;transition:.3s}.btn-grey-pill:focus,.btn-grey-pill:hover{background-color:#dcdee0;-webkit-text-decoration:none;text-decoration:none}.btn-grey-pill:active{background-color:#cccdce}.btn-red-pill{background-color:inherit;border:none;border-radius:20px;color:#fa2a24;cursor:pointer;font-size:1.4rem;padding:5px 10px;transition:.3s}.btn-red-pill:focus,.btn-red-pill:hover{background-color:rgba(255,0,0,.122);-webkit-text-decoration:none;text-decoration:none}.btn-red-pill:active{background-color:rgba(255,0,0,.22)}.sm-icons a{border-radius:50%;color:#fff;cursor:pointer;display:inline-block;font-size:14px;height:25px;line-height:25px;padding:0;text-align:center;-webkit-text-decoration:none;text-decoration:none;transition:.3s;width:25px}.sm-icons a:hover{opacity:.9}.sm-icons a:focus{opacity:.9;outline:none;transform:scale(1.2)}.sm-icons .bluesky{background-color:#0085ff}.sm-icons .bluesky:before{content:"";font-family:"Font Awesome 6 Brands"}.sm-icons .twitter{background-color:#000}.sm-icons .twitter:before{content:"";font-family:"Font Awesome 5 Brands";font-weight:900}.sm-icons .facebook{background-color:#3b5a98}.sm-icons .facebook:before{content:"";font-family:"Font Awesome 5 Brands";font-weight:900}.sm-icons .linkedin{background-color:#0077b5}.sm-icons .linkedin:before{content:"";font-family:"Font Awesome 5 Brands";font-weight:900}.sm-icons .youtube{background-color:red}.sm-icons .youtube:before{content:"";font-family:"Font Awesome 5 Brands";font-weight:900}.sm-icons .instagram{background:radial-gradient(circle at 30% 107%,#fdf497 0,#fdf497 5%,#fd5949 45%,#d6249f 60%,#285aeb 90%)}.sm-icons .instagram:before{content:"";font-family:"Font Awesome 5 Brands";font-weight:900}.sm-icons .email{background-color:#cc2126}.sm-icons .email:before{content:"";font-family:"Font Awesome 5 Free";font-weight:900}.sm-icons .rss{background-color:#ee802f}.sm-icons .rss:before{content:"";font-family:"Font Awesome 5 Free";font-weight:900}.full-width-card-wrapper .full-width-card{border:1px solid #ced1dc;display:flex;margin:10px 0 20px}@media screen and (max-width:61.9375em){.full-width-card-wrapper .full-width-card{flex-wrap:wrap;justify-content:space-between}}.full-width-card-wrapper .full-width-card-img{height:auto;position:relative;width:250px}@media screen and (max-width:61.9375em){.full-width-card-wrapper .full-width-card-img{flex-basis:50%}}@media screen and (max-width:47.9375em){.full-width-card-wrapper .full-width-card-img{width:100%}}.full-width-card-wrapper .full-width-card-img img{border:1px solid #ced1dc;height:auto;width:100%}.full-width-card-wrapper .full-width-card-img-info{background-color:#1e70c2;border-radius:3px 0 0 0;bottom:4px;cursor:pointer;outline:none;padding:11px;position:absolute;right:1px}.full-width-card-wrapper .full-width-card-img-info .icon{color:#fff;font-size:1.8rem;transition:all .3s ease}.full-width-card-wrapper .full-width-card-img-info:hover{padding-bottom:10px}.full-width-card-wrapper .full-width-card-img-info:hover .icon{font-size:2rem}.full-width-card-wrapper .full-width-card-img-info:focus .icon{font-size:2.4rem}.full-width-card-wrapper .full-width-card-info{flex-grow:1;padding:15px 15px 15px 0}@media screen and (max-width:61.9375em){.full-width-card-wrapper .full-width-card-info{flex-basis:50%}}@media screen and (max-width:47.9375em){.full-width-card-wrapper .full-width-card-info{flex-basis:100%;padding:15px}}.full-width-card-wrapper .full-width-card-info-title{margin-top:0}.full-width-card-wrapper .full-width-card-highlight:after,.full-width-card-wrapper .full-width-card-highlight:before{color:#5d6581;content:"..."}.full-width-card-wrapper .full-width-card-info-download-links a{margin-right:9px}@media screen and (max-width:61.9375em){.full-width-card-wrapper .full-width-card-info-button button{margin:10px 0 0;width:100%}}.full-width-card-wrapper .full-width-card-info-group-buttons{display:flex;margin-top:14px}@media screen and (max-width:61.9375em){.full-width-card-wrapper .full-width-card-info-group-buttons a:first-child{display:block;margin-bottom:14px;margin-left:0!important;margin-right:0!important}.full-width-card-wrapper .full-width-card-info-group-buttons a:last-child{display:block;margin-left:0!important;margin-right:0!important}.full-width-card-wrapper .full-width-card-info-group-buttons{display:block}}.full-width-card-wrapper .full-width-card-info-group-buttons button{margin-right:10px}@media screen and (max-width:61.9375em){.full-width-card-wrapper .full-width-card-info-group-buttons button{margin:10px 0 0;width:100%}}.full-width-card-wrapper .full-width-card-info-date-published{margin-bottom:20px}.full-width-card-wrapper .full-width-card-altmetric{align-self:center;margin-left:auto;padding-right:15px}@media screen and (max-width:61.9375em){.full-width-card-wrapper .full-width-card-altmetric{margin:10px auto 15px;padding:0}}.full-width-card-wrapper .full-width-card-altmetric img{width:auto}.img-cont{padding:15px}@media screen and (max-width:47.9375em){.img-cont{width:100%}}.cards{justify-content:space-between;margin-bottom:14px}.cards,.cards .card{display:flex;flex-wrap:wrap}.cards .card{flex-basis:31%;flex-direction:column;flex-grow:0;flex-shrink:0;transition:.3s}@media screen and (max-width:61.9375em){.cards .card{flex-basis:48%}}@media screen and (max-width:47.9375em){.cards .card{flex-basis:100%}}.cards .card:hover .card-header .card-img img{filter:brightness(1);transform:scale(1.1);transition:all .3s ease}.cards .card-header,.cards .card-img{border-radius:10px;border-radius:3px;overflow:hidden}.cards .card-img{height:200px;position:relative}.cards .card-img img{filter:brightness(.6);height:auto;transition:all .3s ease;width:100%}@media screen and (max-width:61.9375em){.cards .card-img{height:180px}}@media screen and (max-width:47.9375em){.cards .card-img{height:200px}}.cards .card-img-info{background-color:#1e70c2;border-radius:3px 0 0 0;cursor:pointer;outline:none;padding:11px;position:absolute;right:0;top:160px}@media screen and (max-width:61.9375em){.cards .card-img-info{top:140px}}@media screen and (max-width:47.9375em){.cards .card-img-info{top:160px}}.cards .card-img-info .icon{color:#fff;font-size:1.8rem;transition:all .3s ease}.cards .card-img-info:hover .icon{font-size:2rem}.cards .card-img-info:focus .icon{font-size:2.4rem}.cards .card-body{flex-grow:1;flex-shrink:0}.cards .card-body,.cards .card-title{display:flex;flex-direction:column}.cards .card-title a{color:#1a254c;outline:none;transition:all .3s ease}.cards .card-title a:focus,.cards .card-title a:hover{color:#1e70c2;-webkit-text-decoration:underline;text-decoration:underline;transition:all .3s ease}.cards .card-info p{max-height:125px;overflow:scroll}.cards .card-info p a{color:#1e70c2;cursor:pointer}.cards .card-info p a:hover{-webkit-text-decoration:underline;text-decoration:underline}.cards .card-years{display:flex;flex-wrap:wrap}.cards .card-years a{color:#1e70c2;cursor:pointer;margin:0 10px 5px 0}.cards .card-years a:focus,.cards .card-years a:hover{outline:none;-webkit-text-decoration:underline;text-decoration:underline}.cards .card-date-social{color:#5d6581;display:flex;flex-wrap:wrap}.v--modal-overlay{background:rgba(17,26,55,.7);box-sizing:border-box;height:100vh;left:0;opacity:1;position:fixed;top:0;width:100%;z-index:99999}.v--modal-overlay .v--modal-background-click{min-height:100%;padding-bottom:10px;width:100%}.v--modal-overlay .v--modal-background-click .v--modal-top-right{display:block;position:absolute;right:0;top:0}.v--modal-overlay .v--modal-background-click .v--modal-box{box-sizing:border-box;position:relative}.v--modal-overlay .v--modal-background-click .v--modal{border-radius:3px;box-shadow:0 20px 60px -2px rgba(27,33,58,.4);text-align:left}.modal-window{background-color:#fff;height:100%;overflow:hidden;position:relative}.modal-window-header{background:#f3f3f5;border-bottom:1px solid #bab4b4;display:flex;flex-wrap:wrap;justify-content:space-between;padding:10px 20px}.modal-window-title{margin:0}.modal-window-close{background-color:#f3f3f5;border:none;color:gray;cursor:pointer;font-size:2rem;transition:.3s}.modal-window-close:hover{color:#000}.modal-window-body{height:-webkit-fill-available;max-height:400px;overflow-y:auto;padding:20px}.modal-window-footer{background-color:#f8f9fa;border-top:1px solid #bab4b4}.modal-window-footer div{float:right;padding:10px 20px}.ads-bottom-banner,.ads-top-banner{display:flex;justify-content:center;margin:8px 0;width:100%}.ads-sidebar-container{margin:20px 0}.ads-sidebar-item{margin-bottom:20px;width:100%}.ads-sidebar-item:last-child{margin-bottom:0}
.vue-modal-resizer{bottom:0;cursor:se-resize;height:12px;overflow:hidden;right:0;width:12px;z-index:9999999}.vue-modal-resizer,.vue-modal-resizer:after{background:transparent;display:block;position:absolute}.vue-modal-resizer:after{border-bottom:10px solid #ddd;border-left:10px solid transparent;content:"";height:0;left:0;top:0;width:0}.vue-modal-resizer.clicked:after{border-bottom:10px solid #369be9}.v--modal-block-scroll{overflow:hidden;width:100vw}.v--modal-overlay{background:rgba(0,0,0,.2);box-sizing:border-box;height:100vh;left:0;opacity:1;position:fixed;top:0;width:100%;z-index:999}.v--modal-overlay.scrollable{-webkit-overflow-scrolling:touch;height:100%;min-height:100vh;overflow-y:auto}.v--modal-overlay .v--modal-background-click{height:auto;min-height:100%;width:100%}.v--modal-overlay .v--modal-box{box-sizing:border-box;overflow:hidden;position:relative}.v--modal-overlay.scrollable .v--modal-box{margin-bottom:2px}.v--modal{background-color:#fff;border-radius:3px;box-shadow:0 20px 60px -2px rgba(27,33,58,.4);padding:0;text-align:left}.v--modal.v--modal-fullscreen{height:100vh;left:0;margin:0;top:0;width:100vw}.v--modal-top-right{display:block;position:absolute;right:0;top:0}.overlay-fade-enter-active,.overlay-fade-leave-active{transition:all .2s}.overlay-fade-enter,.overlay-fade-leave-active{opacity:0}.nice-modal-fade-enter-active,.nice-modal-fade-leave-active{transition:all .4s}.nice-modal-fade-enter,.nice-modal-fade-leave-active{opacity:0;-webkit-transform:translateY(-20px);transform:translateY(-20px)}.vue-dialog div{box-sizing:border-box}.vue-dialog .dialog-flex{height:100%;width:100%}.vue-dialog .dialog-content{flex:1 0 auto;font-size:14px;padding:15px;width:100%}.vue-dialog .dialog-c-title{font-weight:600;padding-bottom:15px}.vue-dialog .vue-dialog-buttons{border-top:1px solid #eee;display:flex;flex:0 1 auto;width:100%}.vue-dialog .vue-dialog-buttons-none{padding-bottom:15px;width:100%}.vue-dialog-button{background:transparent;border:0;box-sizing:border-box;color:inherit;cursor:pointer;font-size:12px!important;height:40px;line-height:40px;font:inherit;margin:0;outline:none;padding:0}.vue-dialog-button:hover{background:rgba(0,0,0,.01)}.vue-dialog-button:active{background:rgba(0,0,0,.025)}.vue-dialog-button:not(:first-of-type){border-left:1px solid #eee}
.nuxt-progress{background-color:#3088df;height:2px;left:0;opacity:1;position:fixed;right:0;top:0;transition:width .1s,opacity .4s;width:0;z-index:999999}.nuxt-progress.nuxt-progress-notransition{transition:none}.nuxt-progress-failed{background-color:red}
.mt-0{margin-top:0!important}.mt-5{margin-top:5px!important}.mt-10{margin-top:10px!important}.mt-15{margin-top:15px!important}.mt-20{margin-top:20px!important}.mt-25{margin-top:25px!important}.mt-30{margin-top:30px!important}.mt-35{margin-top:35px!important}.mt-40{margin-top:40px!important}.mt-45{margin-top:45px!important}.mt-50{margin-top:50px!important}.mt-55{margin-top:55px!important}.mt-60{margin-top:60px!important}.mt-65{margin-top:65px!important}.mt-70{margin-top:70px!important}.mt-75{margin-top:75px!important}.mt-80{margin-top:80px!important}.mt-85{margin-top:85px!important}.mt-90{margin-top:90px!important}.mt-95{margin-top:95px!important}.mt-100{margin-top:100px!important}.mb-0{margin-bottom:0!important}.mb-5{margin-bottom:5px!important}.mb-10{margin-bottom:10px!important}.mb-15{margin-bottom:15px!important}.mb-20{margin-bottom:20px!important}.mb-25{margin-bottom:25px!important}.mb-30{margin-bottom:30px!important}.mb-35{margin-bottom:35px!important}.mb-40{margin-bottom:40px!important}.mb-45{margin-bottom:45px!important}.mb-50{margin-bottom:50px!important}.mb-55{margin-bottom:55px!important}.mb-60{margin-bottom:60px!important}.mb-65{margin-bottom:65px!important}.mb-70{margin-bottom:70px!important}.mb-75{margin-bottom:75px!important}.mb-80{margin-bottom:80px!important}.mb-85{margin-bottom:85px!important}.mb-90{margin-bottom:90px!important}.mb-95{margin-bottom:95px!important}.mb-100{margin-bottom:100px!important}.ml-0{margin-left:0!important}.ml-5{margin-left:5px!important}.ml-10{margin-left:10px!important}.ml-15{margin-left:15px!important}.ml-20{margin-left:20px!important}.ml-25{margin-left:25px!important}.ml-30{margin-left:30px!important}.ml-35{margin-left:35px!important}.ml-40{margin-left:40px!important}.ml-45{margin-left:45px!important}.ml-50{margin-left:50px!important}.ml-55{margin-left:55px!important}.ml-60{margin-left:60px!important}.ml-65{margin-left:65px!important}.ml-70{margin-left:70px!important}.ml-75{margin-left:75px!important}.ml-80{margin-left:80px!important}.ml-85{margin-left:85px!important}.ml-90{margin-left:90px!important}.ml-95{margin-left:95px!important}.ml-100{margin-left:100px!important}.mr-0{margin-right:0!important}.mr-5{margin-right:5px!important}.mr-10{margin-right:10px!important}.mr-15{margin-right:15px!important}.mr-20{margin-right:20px!important}.mr-25{margin-right:25px!important}.mr-30{margin-right:30px!important}.mr-35{margin-right:35px!important}.mr-40{margin-right:40px!important}.mr-45{margin-right:45px!important}.mr-50{margin-right:50px!important}.mr-55{margin-right:55px!important}.mr-60{margin-right:60px!important}.mr-65{margin-right:65px!important}.mr-70{margin-right:70px!important}.mr-75{margin-right:75px!important}.mr-80{margin-right:80px!important}.mr-85{margin-right:85px!important}.mr-90{margin-right:90px!important}.mr-95{margin-right:95px!important}.mr-100{margin-right:100px!important}.pt-0{padding-top:0!important}.pt-5{padding-top:5px!important}.pt-10{padding-top:10px!important}.pt-15{padding-top:15px!important}.pt-20{padding-top:20px!important}.pt-25{padding-top:25px!important}.pt-30{padding-top:30px!important}.pt-35{padding-top:35px!important}.pt-40{padding-top:40px!important}.pt-45{padding-top:45px!important}.pt-50{padding-top:50px!important}.pt-55{padding-top:55px!important}.pt-60{padding-top:60px!important}.pt-65{padding-top:65px!important}.pt-70{padding-top:70px!important}.pt-75{padding-top:75px!important}.pt-80{padding-top:80px!important}.pt-85{padding-top:85px!important}.pt-90{padding-top:90px!important}.pt-95{padding-top:95px!important}.pt-100{padding-top:100px!important}.pb-0{padding-bottom:0!important}.pb-5{padding-bottom:5px!important}.pb-10{padding-bottom:10px!important}.pb-15{padding-bottom:15px!important}.pb-20{padding-bottom:20px!important}.pb-25{padding-bottom:25px!important}.pb-30{padding-bottom:30px!important}.pb-35{padding-bottom:35px!important}.pb-40{padding-bottom:40px!important}.pb-45{padding-bottom:45px!important}.pb-50{padding-bottom:50px!important}.pb-55{padding-bottom:55px!important}.pb-60{padding-bottom:60px!important}.pb-65{padding-bottom:65px!important}.pb-70{padding-bottom:70px!important}.pb-75{padding-bottom:75px!important}.pb-80{padding-bottom:80px!important}.pb-85{padding-bottom:85px!important}.pb-90{padding-bottom:90px!important}.pb-95{padding-bottom:95px!important}.pb-100{padding-bottom:100px!important}.pl-0{padding-left:0!important}.pl-5{padding-left:5px!important}.pl-10{padding-left:10px!important}.pl-15{padding-left:15px!important}.pl-20{padding-left:20px!important}.pl-25{padding-left:25px!important}.pl-30{padding-left:30px!important}.pl-35{padding-left:35px!important}.pl-40{padding-left:40px!important}.pl-45{padding-left:45px!important}.pl-50{padding-left:50px!important}.pl-55{padding-left:55px!important}.pl-60{padding-left:60px!important}.pl-65{padding-left:65px!important}.pl-70{padding-left:70px!important}.pl-75{padding-left:75px!important}.pl-80{padding-left:80px!important}.pl-85{padding-left:85px!important}.pl-90{padding-left:90px!important}.pl-95{padding-left:95px!important}.pl-100{padding-left:100px!important}.pr-0{padding-right:0!important}.pr-5{padding-right:5px!important}.pr-10{padding-right:10px!important}.pr-15{padding-right:15px!important}.pr-20{padding-right:20px!important}.pr-25{padding-right:25px!important}.pr-30{padding-right:30px!important}.pr-35{padding-right:35px!important}.pr-40{padding-right:40px!important}.pr-45{padding-right:45px!important}.pr-50{padding-right:50px!important}.pr-55{padding-right:55px!important}.pr-60{padding-right:60px!important}.pr-65{padding-right:65px!important}.pr-70{padding-right:70px!important}.pr-75{padding-right:75px!important}.pr-80{padding-right:80px!important}.pr-85{padding-right:85px!important}.pr-90{padding-right:90px!important}.pr-95{padding-right:95px!important}.pr-100{padding-right:100px!important}*,:after,:before{box-sizing:inherit}html{font-size:62.5%}body{background-color:#fff;box-sizing:border-box;color:#1a254c;font-family:"Roboto",sans-serif;font-size:1.4rem;font-weight:400;margin:0;padding:0}#jmir-html{position:relative}#skip-link a{font-size:1.6rem;font-weight:700;height:1px;left:-10000px;margin:10px 0 10px 10px;overflow:hidden;padding:10px;position:absolute;-webkit-text-decoration:underline;text-decoration:underline;top:auto;width:1px}#skip-link a:focus{border:2px solid #f69038;display:inline-block;height:auto;position:static;width:auto}#main-layout-container{display:flex;flex-direction:column;height:100vh;justify-content:space-between}.toasted-container.top-right{right:2%!important;top:2%!important}._hj-3ZiaL__MinimizedWidgetBottom__container{bottom:.5%!important;flex-direction:row!important;justify-content:flex-end;width:84%!important}span a.a-select-membership{font-size:1.2rem;padding:5px 10px;-webkit-text-decoration:none!important;text-decoration:none!important}
.mt-0[data-v-6301a668]{margin-top:0!important}.mt-5[data-v-6301a668]{margin-top:5px!important}.mt-10[data-v-6301a668]{margin-top:10px!important}.mt-15[data-v-6301a668]{margin-top:15px!important}.mt-20[data-v-6301a668]{margin-top:20px!important}.mt-25[data-v-6301a668]{margin-top:25px!important}.mt-30[data-v-6301a668]{margin-top:30px!important}.mt-35[data-v-6301a668]{margin-top:35px!important}.mt-40[data-v-6301a668]{margin-top:40px!important}.mt-45[data-v-6301a668]{margin-top:45px!important}.mt-50[data-v-6301a668]{margin-top:50px!important}.mt-55[data-v-6301a668]{margin-top:55px!important}.mt-60[data-v-6301a668]{margin-top:60px!important}.mt-65[data-v-6301a668]{margin-top:65px!important}.mt-70[data-v-6301a668]{margin-top:70px!important}.mt-75[data-v-6301a668]{margin-top:75px!important}.mt-80[data-v-6301a668]{margin-top:80px!important}.mt-85[data-v-6301a668]{margin-top:85px!important}.mt-90[data-v-6301a668]{margin-top:90px!important}.mt-95[data-v-6301a668]{margin-top:95px!important}.mt-100[data-v-6301a668]{margin-top:100px!important}.mb-0[data-v-6301a668]{margin-bottom:0!important}.mb-5[data-v-6301a668]{margin-bottom:5px!important}.mb-10[data-v-6301a668]{margin-bottom:10px!important}.mb-15[data-v-6301a668]{margin-bottom:15px!important}.mb-20[data-v-6301a668]{margin-bottom:20px!important}.mb-25[data-v-6301a668]{margin-bottom:25px!important}.mb-30[data-v-6301a668]{margin-bottom:30px!important}.mb-35[data-v-6301a668]{margin-bottom:35px!important}.mb-40[data-v-6301a668]{margin-bottom:40px!important}.mb-45[data-v-6301a668]{margin-bottom:45px!important}.mb-50[data-v-6301a668]{margin-bottom:50px!important}.mb-55[data-v-6301a668]{margin-bottom:55px!important}.mb-60[data-v-6301a668]{margin-bottom:60px!important}.mb-65[data-v-6301a668]{margin-bottom:65px!important}.mb-70[data-v-6301a668]{margin-bottom:70px!important}.mb-75[data-v-6301a668]{margin-bottom:75px!important}.mb-80[data-v-6301a668]{margin-bottom:80px!important}.mb-85[data-v-6301a668]{margin-bottom:85px!important}.mb-90[data-v-6301a668]{margin-bottom:90px!important}.mb-95[data-v-6301a668]{margin-bottom:95px!important}.mb-100[data-v-6301a668]{margin-bottom:100px!important}.ml-0[data-v-6301a668]{margin-left:0!important}.ml-5[data-v-6301a668]{margin-left:5px!important}.ml-10[data-v-6301a668]{margin-left:10px!important}.ml-15[data-v-6301a668]{margin-left:15px!important}.ml-20[data-v-6301a668]{margin-left:20px!important}.ml-25[data-v-6301a668]{margin-left:25px!important}.ml-30[data-v-6301a668]{margin-left:30px!important}.ml-35[data-v-6301a668]{margin-left:35px!important}.ml-40[data-v-6301a668]{margin-left:40px!important}.ml-45[data-v-6301a668]{margin-left:45px!important}.ml-50[data-v-6301a668]{margin-left:50px!important}.ml-55[data-v-6301a668]{margin-left:55px!important}.ml-60[data-v-6301a668]{margin-left:60px!important}.ml-65[data-v-6301a668]{margin-left:65px!important}.ml-70[data-v-6301a668]{margin-left:70px!important}.ml-75[data-v-6301a668]{margin-left:75px!important}.ml-80[data-v-6301a668]{margin-left:80px!important}.ml-85[data-v-6301a668]{margin-left:85px!important}.ml-90[data-v-6301a668]{margin-left:90px!important}.ml-95[data-v-6301a668]{margin-left:95px!important}.ml-100[data-v-6301a668]{margin-left:100px!important}.mr-0[data-v-6301a668]{margin-right:0!important}.mr-5[data-v-6301a668]{margin-right:5px!important}.mr-10[data-v-6301a668]{margin-right:10px!important}.mr-15[data-v-6301a668]{margin-right:15px!important}.mr-20[data-v-6301a668]{margin-right:20px!important}.mr-25[data-v-6301a668]{margin-right:25px!important}.mr-30[data-v-6301a668]{margin-right:30px!important}.mr-35[data-v-6301a668]{margin-right:35px!important}.mr-40[data-v-6301a668]{margin-right:40px!important}.mr-45[data-v-6301a668]{margin-right:45px!important}.mr-50[data-v-6301a668]{margin-right:50px!important}.mr-55[data-v-6301a668]{margin-right:55px!important}.mr-60[data-v-6301a668]{margin-right:60px!important}.mr-65[data-v-6301a668]{margin-right:65px!important}.mr-70[data-v-6301a668]{margin-right:70px!important}.mr-75[data-v-6301a668]{margin-right:75px!important}.mr-80[data-v-6301a668]{margin-right:80px!important}.mr-85[data-v-6301a668]{margin-right:85px!important}.mr-90[data-v-6301a668]{margin-right:90px!important}.mr-95[data-v-6301a668]{margin-right:95px!important}.mr-100[data-v-6301a668]{margin-right:100px!important}.pt-0[data-v-6301a668]{padding-top:0!important}.pt-5[data-v-6301a668]{padding-top:5px!important}.pt-10[data-v-6301a668]{padding-top:10px!important}.pt-15[data-v-6301a668]{padding-top:15px!important}.pt-20[data-v-6301a668]{padding-top:20px!important}.pt-25[data-v-6301a668]{padding-top:25px!important}.pt-30[data-v-6301a668]{padding-top:30px!important}.pt-35[data-v-6301a668]{padding-top:35px!important}.pt-40[data-v-6301a668]{padding-top:40px!important}.pt-45[data-v-6301a668]{padding-top:45px!important}.pt-50[data-v-6301a668]{padding-top:50px!important}.pt-55[data-v-6301a668]{padding-top:55px!important}.pt-60[data-v-6301a668]{padding-top:60px!important}.pt-65[data-v-6301a668]{padding-top:65px!important}.pt-70[data-v-6301a668]{padding-top:70px!important}.pt-75[data-v-6301a668]{padding-top:75px!important}.pt-80[data-v-6301a668]{padding-top:80px!important}.pt-85[data-v-6301a668]{padding-top:85px!important}.pt-90[data-v-6301a668]{padding-top:90px!important}.pt-95[data-v-6301a668]{padding-top:95px!important}.pt-100[data-v-6301a668]{padding-top:100px!important}.pb-0[data-v-6301a668]{padding-bottom:0!important}.pb-5[data-v-6301a668]{padding-bottom:5px!important}.pb-10[data-v-6301a668]{padding-bottom:10px!important}.pb-15[data-v-6301a668]{padding-bottom:15px!important}.pb-20[data-v-6301a668]{padding-bottom:20px!important}.pb-25[data-v-6301a668]{padding-bottom:25px!important}.pb-30[data-v-6301a668]{padding-bottom:30px!important}.pb-35[data-v-6301a668]{padding-bottom:35px!important}.pb-40[data-v-6301a668]{padding-bottom:40px!important}.pb-45[data-v-6301a668]{padding-bottom:45px!important}.pb-50[data-v-6301a668]{padding-bottom:50px!important}.pb-55[data-v-6301a668]{padding-bottom:55px!important}.pb-60[data-v-6301a668]{padding-bottom:60px!important}.pb-65[data-v-6301a668]{padding-bottom:65px!important}.pb-70[data-v-6301a668]{padding-bottom:70px!important}.pb-75[data-v-6301a668]{padding-bottom:75px!important}.pb-80[data-v-6301a668]{padding-bottom:80px!important}.pb-85[data-v-6301a668]{padding-bottom:85px!important}.pb-90[data-v-6301a668]{padding-bottom:90px!important}.pb-95[data-v-6301a668]{padding-bottom:95px!important}.pb-100[data-v-6301a668]{padding-bottom:100px!important}.pl-0[data-v-6301a668]{padding-left:0!important}.pl-5[data-v-6301a668]{padding-left:5px!important}.pl-10[data-v-6301a668]{padding-left:10px!important}.pl-15[data-v-6301a668]{padding-left:15px!important}.pl-20[data-v-6301a668]{padding-left:20px!important}.pl-25[data-v-6301a668]{padding-left:25px!important}.pl-30[data-v-6301a668]{padding-left:30px!important}.pl-35[data-v-6301a668]{padding-left:35px!important}.pl-40[data-v-6301a668]{padding-left:40px!important}.pl-45[data-v-6301a668]{padding-left:45px!important}.pl-50[data-v-6301a668]{padding-left:50px!important}.pl-55[data-v-6301a668]{padding-left:55px!important}.pl-60[data-v-6301a668]{padding-left:60px!important}.pl-65[data-v-6301a668]{padding-left:65px!important}.pl-70[data-v-6301a668]{padding-left:70px!important}.pl-75[data-v-6301a668]{padding-left:75px!important}.pl-80[data-v-6301a668]{padding-left:80px!important}.pl-85[data-v-6301a668]{padding-left:85px!important}.pl-90[data-v-6301a668]{padding-left:90px!important}.pl-95[data-v-6301a668]{padding-left:95px!important}.pl-100[data-v-6301a668]{padding-left:100px!important}.pr-0[data-v-6301a668]{padding-right:0!important}.pr-5[data-v-6301a668]{padding-right:5px!important}.pr-10[data-v-6301a668]{padding-right:10px!important}.pr-15[data-v-6301a668]{padding-right:15px!important}.pr-20[data-v-6301a668]{padding-right:20px!important}.pr-25[data-v-6301a668]{padding-right:25px!important}.pr-30[data-v-6301a668]{padding-right:30px!important}.pr-35[data-v-6301a668]{padding-right:35px!important}.pr-40[data-v-6301a668]{padding-right:40px!important}.pr-45[data-v-6301a668]{padding-right:45px!important}.pr-50[data-v-6301a668]{padding-right:50px!important}.pr-55[data-v-6301a668]{padding-right:55px!important}.pr-60[data-v-6301a668]{padding-right:60px!important}.pr-65[data-v-6301a668]{padding-right:65px!important}.pr-70[data-v-6301a668]{padding-right:70px!important}.pr-75[data-v-6301a668]{padding-right:75px!important}.pr-80[data-v-6301a668]{padding-right:80px!important}.pr-85[data-v-6301a668]{padding-right:85px!important}.pr-90[data-v-6301a668]{padding-right:90px!important}.pr-95[data-v-6301a668]{padding-right:95px!important}.pr-100[data-v-6301a668]{padding-right:100px!important}.top-hero-banner[data-v-6301a668]{background-color:#e5f2fe;padding:0 10vw 0 5vw;position:relative}.top-hero-banner__divider[data-v-6301a668]{border-top:1px solid #1a254c}.top-hero-banner__close[data-v-6301a668]{color:#1a254c;cursor:pointer;font-size:2rem;position:absolute;right:10vw;transition:.3s}.top-hero-banner__close[data-v-6301a668]:hover{color:#2e4185}.top-hero-banner__info[data-v-6301a668]{display:flex}.top-hero-banner__info .icon[data-v-6301a668]{font-size:2rem;margin-top:3px}.top-hero-banner__actions[data-v-6301a668]{margin-left:2.9rem}.top-hero-banner__actions a[data-v-6301a668]{display:inline-block;margin-right:2rem}@media screen and (max-width:31.25em){.top-hero-banner__actions a[data-v-6301a668]{padding:5px 0}}.top-hero-banner__link[data-v-6301a668]{color:#1a254c;display:inline-block;font-size:1.6rem;font-weight:700;margin-bottom:5px;margin-right:4rem;-webkit-text-decoration:none;text-decoration:none}.top-hero-banner__link[data-v-6301a668]:focus,.top-hero-banner__link[data-v-6301a668]:hover{-webkit-text-decoration:underline;text-decoration:underline}@media screen and (max-width:47.9375em){.top-hero-banner__link[data-v-6301a668]{display:block;margin-right:0}}
.mt-0[data-v-49c694ee]{margin-top:0!important}.mt-5[data-v-49c694ee]{margin-top:5px!important}.mt-10[data-v-49c694ee]{margin-top:10px!important}.mt-15[data-v-49c694ee]{margin-top:15px!important}.mt-20[data-v-49c694ee]{margin-top:20px!important}.mt-25[data-v-49c694ee]{margin-top:25px!important}.mt-30[data-v-49c694ee]{margin-top:30px!important}.mt-35[data-v-49c694ee]{margin-top:35px!important}.mt-40[data-v-49c694ee]{margin-top:40px!important}.mt-45[data-v-49c694ee]{margin-top:45px!important}.mt-50[data-v-49c694ee]{margin-top:50px!important}.mt-55[data-v-49c694ee]{margin-top:55px!important}.mt-60[data-v-49c694ee]{margin-top:60px!important}.mt-65[data-v-49c694ee]{margin-top:65px!important}.mt-70[data-v-49c694ee]{margin-top:70px!important}.mt-75[data-v-49c694ee]{margin-top:75px!important}.mt-80[data-v-49c694ee]{margin-top:80px!important}.mt-85[data-v-49c694ee]{margin-top:85px!important}.mt-90[data-v-49c694ee]{margin-top:90px!important}.mt-95[data-v-49c694ee]{margin-top:95px!important}.mt-100[data-v-49c694ee]{margin-top:100px!important}.mb-0[data-v-49c694ee]{margin-bottom:0!important}.mb-5[data-v-49c694ee]{margin-bottom:5px!important}.mb-10[data-v-49c694ee]{margin-bottom:10px!important}.mb-15[data-v-49c694ee]{margin-bottom:15px!important}.mb-20[data-v-49c694ee]{margin-bottom:20px!important}.mb-25[data-v-49c694ee]{margin-bottom:25px!important}.mb-30[data-v-49c694ee]{margin-bottom:30px!important}.mb-35[data-v-49c694ee]{margin-bottom:35px!important}.mb-40[data-v-49c694ee]{margin-bottom:40px!important}.mb-45[data-v-49c694ee]{margin-bottom:45px!important}.mb-50[data-v-49c694ee]{margin-bottom:50px!important}.mb-55[data-v-49c694ee]{margin-bottom:55px!important}.mb-60[data-v-49c694ee]{margin-bottom:60px!important}.mb-65[data-v-49c694ee]{margin-bottom:65px!important}.mb-70[data-v-49c694ee]{margin-bottom:70px!important}.mb-75[data-v-49c694ee]{margin-bottom:75px!important}.mb-80[data-v-49c694ee]{margin-bottom:80px!important}.mb-85[data-v-49c694ee]{margin-bottom:85px!important}.mb-90[data-v-49c694ee]{margin-bottom:90px!important}.mb-95[data-v-49c694ee]{margin-bottom:95px!important}.mb-100[data-v-49c694ee]{margin-bottom:100px!important}.ml-0[data-v-49c694ee]{margin-left:0!important}.ml-5[data-v-49c694ee]{margin-left:5px!important}.ml-10[data-v-49c694ee]{margin-left:10px!important}.ml-15[data-v-49c694ee]{margin-left:15px!important}.ml-20[data-v-49c694ee]{margin-left:20px!important}.ml-25[data-v-49c694ee]{margin-left:25px!important}.ml-30[data-v-49c694ee]{margin-left:30px!important}.ml-35[data-v-49c694ee]{margin-left:35px!important}.ml-40[data-v-49c694ee]{margin-left:40px!important}.ml-45[data-v-49c694ee]{margin-left:45px!important}.ml-50[data-v-49c694ee]{margin-left:50px!important}.ml-55[data-v-49c694ee]{margin-left:55px!important}.ml-60[data-v-49c694ee]{margin-left:60px!important}.ml-65[data-v-49c694ee]{margin-left:65px!important}.ml-70[data-v-49c694ee]{margin-left:70px!important}.ml-75[data-v-49c694ee]{margin-left:75px!important}.ml-80[data-v-49c694ee]{margin-left:80px!important}.ml-85[data-v-49c694ee]{margin-left:85px!important}.ml-90[data-v-49c694ee]{margin-left:90px!important}.ml-95[data-v-49c694ee]{margin-left:95px!important}.ml-100[data-v-49c694ee]{margin-left:100px!important}.mr-0[data-v-49c694ee]{margin-right:0!important}.mr-5[data-v-49c694ee]{margin-right:5px!important}.mr-10[data-v-49c694ee]{margin-right:10px!important}.mr-15[data-v-49c694ee]{margin-right:15px!important}.mr-20[data-v-49c694ee]{margin-right:20px!important}.mr-25[data-v-49c694ee]{margin-right:25px!important}.mr-30[data-v-49c694ee]{margin-right:30px!important}.mr-35[data-v-49c694ee]{margin-right:35px!important}.mr-40[data-v-49c694ee]{margin-right:40px!important}.mr-45[data-v-49c694ee]{margin-right:45px!important}.mr-50[data-v-49c694ee]{margin-right:50px!important}.mr-55[data-v-49c694ee]{margin-right:55px!important}.mr-60[data-v-49c694ee]{margin-right:60px!important}.mr-65[data-v-49c694ee]{margin-right:65px!important}.mr-70[data-v-49c694ee]{margin-right:70px!important}.mr-75[data-v-49c694ee]{margin-right:75px!important}.mr-80[data-v-49c694ee]{margin-right:80px!important}.mr-85[data-v-49c694ee]{margin-right:85px!important}.mr-90[data-v-49c694ee]{margin-right:90px!important}.mr-95[data-v-49c694ee]{margin-right:95px!important}.mr-100[data-v-49c694ee]{margin-right:100px!important}.pt-0[data-v-49c694ee]{padding-top:0!important}.pt-5[data-v-49c694ee]{padding-top:5px!important}.pt-10[data-v-49c694ee]{padding-top:10px!important}.pt-15[data-v-49c694ee]{padding-top:15px!important}.pt-20[data-v-49c694ee]{padding-top:20px!important}.pt-25[data-v-49c694ee]{padding-top:25px!important}.pt-30[data-v-49c694ee]{padding-top:30px!important}.pt-35[data-v-49c694ee]{padding-top:35px!important}.pt-40[data-v-49c694ee]{padding-top:40px!important}.pt-45[data-v-49c694ee]{padding-top:45px!important}.pt-50[data-v-49c694ee]{padding-top:50px!important}.pt-55[data-v-49c694ee]{padding-top:55px!important}.pt-60[data-v-49c694ee]{padding-top:60px!important}.pt-65[data-v-49c694ee]{padding-top:65px!important}.pt-70[data-v-49c694ee]{padding-top:70px!important}.pt-75[data-v-49c694ee]{padding-top:75px!important}.pt-80[data-v-49c694ee]{padding-top:80px!important}.pt-85[data-v-49c694ee]{padding-top:85px!important}.pt-90[data-v-49c694ee]{padding-top:90px!important}.pt-95[data-v-49c694ee]{padding-top:95px!important}.pt-100[data-v-49c694ee]{padding-top:100px!important}.pb-0[data-v-49c694ee]{padding-bottom:0!important}.pb-5[data-v-49c694ee]{padding-bottom:5px!important}.pb-10[data-v-49c694ee]{padding-bottom:10px!important}.pb-15[data-v-49c694ee]{padding-bottom:15px!important}.pb-20[data-v-49c694ee]{padding-bottom:20px!important}.pb-25[data-v-49c694ee]{padding-bottom:25px!important}.pb-30[data-v-49c694ee]{padding-bottom:30px!important}.pb-35[data-v-49c694ee]{padding-bottom:35px!important}.pb-40[data-v-49c694ee]{padding-bottom:40px!important}.pb-45[data-v-49c694ee]{padding-bottom:45px!important}.pb-50[data-v-49c694ee]{padding-bottom:50px!important}.pb-55[data-v-49c694ee]{padding-bottom:55px!important}.pb-60[data-v-49c694ee]{padding-bottom:60px!important}.pb-65[data-v-49c694ee]{padding-bottom:65px!important}.pb-70[data-v-49c694ee]{padding-bottom:70px!important}.pb-75[data-v-49c694ee]{padding-bottom:75px!important}.pb-80[data-v-49c694ee]{padding-bottom:80px!important}.pb-85[data-v-49c694ee]{padding-bottom:85px!important}.pb-90[data-v-49c694ee]{padding-bottom:90px!important}.pb-95[data-v-49c694ee]{padding-bottom:95px!important}.pb-100[data-v-49c694ee]{padding-bottom:100px!important}.pl-0[data-v-49c694ee]{padding-left:0!important}.pl-5[data-v-49c694ee]{padding-left:5px!important}.pl-10[data-v-49c694ee]{padding-left:10px!important}.pl-15[data-v-49c694ee]{padding-left:15px!important}.pl-20[data-v-49c694ee]{padding-left:20px!important}.pl-25[data-v-49c694ee]{padding-left:25px!important}.pl-30[data-v-49c694ee]{padding-left:30px!important}.pl-35[data-v-49c694ee]{padding-left:35px!important}.pl-40[data-v-49c694ee]{padding-left:40px!important}.pl-45[data-v-49c694ee]{padding-left:45px!important}.pl-50[data-v-49c694ee]{padding-left:50px!important}.pl-55[data-v-49c694ee]{padding-left:55px!important}.pl-60[data-v-49c694ee]{padding-left:60px!important}.pl-65[data-v-49c694ee]{padding-left:65px!important}.pl-70[data-v-49c694ee]{padding-left:70px!important}.pl-75[data-v-49c694ee]{padding-left:75px!important}.pl-80[data-v-49c694ee]{padding-left:80px!important}.pl-85[data-v-49c694ee]{padding-left:85px!important}.pl-90[data-v-49c694ee]{padding-left:90px!important}.pl-95[data-v-49c694ee]{padding-left:95px!important}.pl-100[data-v-49c694ee]{padding-left:100px!important}.pr-0[data-v-49c694ee]{padding-right:0!important}.pr-5[data-v-49c694ee]{padding-right:5px!important}.pr-10[data-v-49c694ee]{padding-right:10px!important}.pr-15[data-v-49c694ee]{padding-right:15px!important}.pr-20[data-v-49c694ee]{padding-right:20px!important}.pr-25[data-v-49c694ee]{padding-right:25px!important}.pr-30[data-v-49c694ee]{padding-right:30px!important}.pr-35[data-v-49c694ee]{padding-right:35px!important}.pr-40[data-v-49c694ee]{padding-right:40px!important}.pr-45[data-v-49c694ee]{padding-right:45px!important}.pr-50[data-v-49c694ee]{padding-right:50px!important}.pr-55[data-v-49c694ee]{padding-right:55px!important}.pr-60[data-v-49c694ee]{padding-right:60px!important}.pr-65[data-v-49c694ee]{padding-right:65px!important}.pr-70[data-v-49c694ee]{padding-right:70px!important}.pr-75[data-v-49c694ee]{padding-right:75px!important}.pr-80[data-v-49c694ee]{padding-right:80px!important}.pr-85[data-v-49c694ee]{padding-right:85px!important}.pr-90[data-v-49c694ee]{padding-right:90px!important}.pr-95[data-v-49c694ee]{padding-right:95px!important}.pr-100[data-v-49c694ee]{padding-right:100px!important}.universal-access-btn[data-v-49c694ee]{background-color:#fff;border:2px solid transparent;border-radius:100px;color:#1e70c2;cursor:pointer;display:block;font-size:4rem;position:fixed;right:2px;top:2px;z-index:200}.universal-access-btn[data-v-49c694ee]:focus{border:2px solid #f69038;outline:none}.accessibility *[data-v-49c694ee]{line-height:inherit!important}.accessibility[data-v-49c694ee] :not(.icon){font-weight:400!important}.accessibility[data-v-49c694ee]{background-color:#fff;border:2px solid #f69038;border-radius:20px 20px 20px 20px;box-shadow:0 0 40px -10px rgba(0,0,0,.75);padding:30px 30px 10px;position:fixed;right:0;top:0;z-index:1000000000000000}@media screen and (max-width:33.1875em){.accessibility[data-v-49c694ee]{width:100%}}.accessibility__wrapper[data-v-49c694ee]{position:relative}@media screen and (max-width:59.6875em){.accessibility__wrapper[data-v-49c694ee]{flex-direction:column}}.accessibility__wrapper button[data-v-49c694ee]{border:2px solid #dcdee0}.accessibility__wrapper button[data-v-49c694ee]:focus{border:2px solid #f69038}.accessibility__wrapper h3[data-v-49c694ee]{font-size:26px!important}.accessibility__wrapper h3 .icon[data-v-49c694ee]{color:#1e70c2}.accessibility__wrapper h4[data-v-49c694ee]{font-size:18px!important}.accessibility__settings[data-v-49c694ee]{max-height:600px;overflow-x:hidden;overflow-y:auto;padding-right:20px}.accessibility__settings[data-v-49c694ee]::-webkit-scrollbar{-webkit-appearance:none}.accessibility__settings[data-v-49c694ee]::-webkit-scrollbar-track{border-radius:8px;box-shadow:inset 0 0 5px #dcdee0}.accessibility__settings[data-v-49c694ee]::-webkit-scrollbar:vertical{width:3px}.accessibility__settings[data-v-49c694ee]::-webkit-scrollbar-thumb{background-color:#1e70c2;border-radius:1px}.accessibility__settings button[data-v-49c694ee]{border-radius:10px;width:150px}@media screen and (max-width:45.9375em){.accessibility__settings button[data-v-49c694ee]{width:100%}}@media screen and (max-width:59.6875em){.accessibility__settings[data-v-49c694ee]{max-height:200px;padding-right:0;width:100%}}.accessibility__close-top[data-v-49c694ee]{background-color:transparent;border:2px solid #fff!important;color:gray;cursor:pointer;font-size:20px;position:absolute;right:-27px;top:-27px;transition:.3s;width:auto!important}.accessibility__close-top[data-v-49c694ee]:hover{color:#000}.accessibility__close-top[data-v-49c694ee]:focus{border:2px solid #f69038!important;color:#000}.accessibility__link[data-v-49c694ee]{font-size:14px;font-weight:400}.accessibility__link[data-v-49c694ee],.accessibility__section[data-v-49c694ee]{text-align:left!important}.accessibility__colour button[data-v-49c694ee],.accessibility__content button[data-v-49c694ee],.accessibility__font button[data-v-49c694ee]{text-align:center}.accessibility__colour button span[data-v-49c694ee],.accessibility__content button span[data-v-49c694ee],.accessibility__font button span[data-v-49c694ee]{display:block;font-size:20px}.accessibility__font-menu[data-v-49c694ee]{background-color:#f0f3f5;border-radius:20px;padding:20px}.accessibility__font-menu button[data-v-49c694ee]{text-align:center;width:-moz-fit-content;width:fit-content}.accessibility__font-menu button span[data-v-49c694ee]{display:block;font-size:20px}.accessibility__font-menu p[data-v-49c694ee]{display:inline-block;font-size:14px}.accessibility__content[data-v-49c694ee]{margin-bottom:20px}.accessibility__footer[data-v-49c694ee]{float:right;margin-top:20px}.accessibility__reset-settings[data-v-49c694ee]{border:2px solid #dcdee0}.accessibility__reset-settings[data-v-49c694ee]:focus{border:2px solid #f69038}.accessibility__close-bottom[data-v-49c694ee]{border:2px solid #dcdee0}.accessibility__close-bottom[data-v-49c694ee]:focus{border:2px solid #f69038}.accessibility .btn[data-v-49c694ee]{outline:none!important}.accessibility .deactive[data-v-49c694ee]{color:#000;cursor:not-allowed;opacity:.5;pointer-events:none}.accessibility .acc-active[data-v-49c694ee]{background-color:#1e70c2!important;border:1px solid #1e70c2!important;color:#fff!important}.accessibility button[data-v-49c694ee]{font-size:14px!important}
.mt-0[data-v-575455fb]{margin-top:0!important}.mt-5[data-v-575455fb]{margin-top:5px!important}.mt-10[data-v-575455fb]{margin-top:10px!important}.mt-15[data-v-575455fb]{margin-top:15px!important}.mt-20[data-v-575455fb]{margin-top:20px!important}.mt-25[data-v-575455fb]{margin-top:25px!important}.mt-30[data-v-575455fb]{margin-top:30px!important}.mt-35[data-v-575455fb]{margin-top:35px!important}.mt-40[data-v-575455fb]{margin-top:40px!important}.mt-45[data-v-575455fb]{margin-top:45px!important}.mt-50[data-v-575455fb]{margin-top:50px!important}.mt-55[data-v-575455fb]{margin-top:55px!important}.mt-60[data-v-575455fb]{margin-top:60px!important}.mt-65[data-v-575455fb]{margin-top:65px!important}.mt-70[data-v-575455fb]{margin-top:70px!important}.mt-75[data-v-575455fb]{margin-top:75px!important}.mt-80[data-v-575455fb]{margin-top:80px!important}.mt-85[data-v-575455fb]{margin-top:85px!important}.mt-90[data-v-575455fb]{margin-top:90px!important}.mt-95[data-v-575455fb]{margin-top:95px!important}.mt-100[data-v-575455fb]{margin-top:100px!important}.mb-0[data-v-575455fb]{margin-bottom:0!important}.mb-5[data-v-575455fb]{margin-bottom:5px!important}.mb-10[data-v-575455fb]{margin-bottom:10px!important}.mb-15[data-v-575455fb]{margin-bottom:15px!important}.mb-20[data-v-575455fb]{margin-bottom:20px!important}.mb-25[data-v-575455fb]{margin-bottom:25px!important}.mb-30[data-v-575455fb]{margin-bottom:30px!important}.mb-35[data-v-575455fb]{margin-bottom:35px!important}.mb-40[data-v-575455fb]{margin-bottom:40px!important}.mb-45[data-v-575455fb]{margin-bottom:45px!important}.mb-50[data-v-575455fb]{margin-bottom:50px!important}.mb-55[data-v-575455fb]{margin-bottom:55px!important}.mb-60[data-v-575455fb]{margin-bottom:60px!important}.mb-65[data-v-575455fb]{margin-bottom:65px!important}.mb-70[data-v-575455fb]{margin-bottom:70px!important}.mb-75[data-v-575455fb]{margin-bottom:75px!important}.mb-80[data-v-575455fb]{margin-bottom:80px!important}.mb-85[data-v-575455fb]{margin-bottom:85px!important}.mb-90[data-v-575455fb]{margin-bottom:90px!important}.mb-95[data-v-575455fb]{margin-bottom:95px!important}.mb-100[data-v-575455fb]{margin-bottom:100px!important}.ml-0[data-v-575455fb]{margin-left:0!important}.ml-5[data-v-575455fb]{margin-left:5px!important}.ml-10[data-v-575455fb]{margin-left:10px!important}.ml-15[data-v-575455fb]{margin-left:15px!important}.ml-20[data-v-575455fb]{margin-left:20px!important}.ml-25[data-v-575455fb]{margin-left:25px!important}.ml-30[data-v-575455fb]{margin-left:30px!important}.ml-35[data-v-575455fb]{margin-left:35px!important}.ml-40[data-v-575455fb]{margin-left:40px!important}.ml-45[data-v-575455fb]{margin-left:45px!important}.ml-50[data-v-575455fb]{margin-left:50px!important}.ml-55[data-v-575455fb]{margin-left:55px!important}.ml-60[data-v-575455fb]{margin-left:60px!important}.ml-65[data-v-575455fb]{margin-left:65px!important}.ml-70[data-v-575455fb]{margin-left:70px!important}.ml-75[data-v-575455fb]{margin-left:75px!important}.ml-80[data-v-575455fb]{margin-left:80px!important}.ml-85[data-v-575455fb]{margin-left:85px!important}.ml-90[data-v-575455fb]{margin-left:90px!important}.ml-95[data-v-575455fb]{margin-left:95px!important}.ml-100[data-v-575455fb]{margin-left:100px!important}.mr-0[data-v-575455fb]{margin-right:0!important}.mr-5[data-v-575455fb]{margin-right:5px!important}.mr-10[data-v-575455fb]{margin-right:10px!important}.mr-15[data-v-575455fb]{margin-right:15px!important}.mr-20[data-v-575455fb]{margin-right:20px!important}.mr-25[data-v-575455fb]{margin-right:25px!important}.mr-30[data-v-575455fb]{margin-right:30px!important}.mr-35[data-v-575455fb]{margin-right:35px!important}.mr-40[data-v-575455fb]{margin-right:40px!important}.mr-45[data-v-575455fb]{margin-right:45px!important}.mr-50[data-v-575455fb]{margin-right:50px!important}.mr-55[data-v-575455fb]{margin-right:55px!important}.mr-60[data-v-575455fb]{margin-right:60px!important}.mr-65[data-v-575455fb]{margin-right:65px!important}.mr-70[data-v-575455fb]{margin-right:70px!important}.mr-75[data-v-575455fb]{margin-right:75px!important}.mr-80[data-v-575455fb]{margin-right:80px!important}.mr-85[data-v-575455fb]{margin-right:85px!important}.mr-90[data-v-575455fb]{margin-right:90px!important}.mr-95[data-v-575455fb]{margin-right:95px!important}.mr-100[data-v-575455fb]{margin-right:100px!important}.pt-0[data-v-575455fb]{padding-top:0!important}.pt-5[data-v-575455fb]{padding-top:5px!important}.pt-10[data-v-575455fb]{padding-top:10px!important}.pt-15[data-v-575455fb]{padding-top:15px!important}.pt-20[data-v-575455fb]{padding-top:20px!important}.pt-25[data-v-575455fb]{padding-top:25px!important}.pt-30[data-v-575455fb]{padding-top:30px!important}.pt-35[data-v-575455fb]{padding-top:35px!important}.pt-40[data-v-575455fb]{padding-top:40px!important}.pt-45[data-v-575455fb]{padding-top:45px!important}.pt-50[data-v-575455fb]{padding-top:50px!important}.pt-55[data-v-575455fb]{padding-top:55px!important}.pt-60[data-v-575455fb]{padding-top:60px!important}.pt-65[data-v-575455fb]{padding-top:65px!important}.pt-70[data-v-575455fb]{padding-top:70px!important}.pt-75[data-v-575455fb]{padding-top:75px!important}.pt-80[data-v-575455fb]{padding-top:80px!important}.pt-85[data-v-575455fb]{padding-top:85px!important}.pt-90[data-v-575455fb]{padding-top:90px!important}.pt-95[data-v-575455fb]{padding-top:95px!important}.pt-100[data-v-575455fb]{padding-top:100px!important}.pb-0[data-v-575455fb]{padding-bottom:0!important}.pb-5[data-v-575455fb]{padding-bottom:5px!important}.pb-10[data-v-575455fb]{padding-bottom:10px!important}.pb-15[data-v-575455fb]{padding-bottom:15px!important}.pb-20[data-v-575455fb]{padding-bottom:20px!important}.pb-25[data-v-575455fb]{padding-bottom:25px!important}.pb-30[data-v-575455fb]{padding-bottom:30px!important}.pb-35[data-v-575455fb]{padding-bottom:35px!important}.pb-40[data-v-575455fb]{padding-bottom:40px!important}.pb-45[data-v-575455fb]{padding-bottom:45px!important}.pb-50[data-v-575455fb]{padding-bottom:50px!important}.pb-55[data-v-575455fb]{padding-bottom:55px!important}.pb-60[data-v-575455fb]{padding-bottom:60px!important}.pb-65[data-v-575455fb]{padding-bottom:65px!important}.pb-70[data-v-575455fb]{padding-bottom:70px!important}.pb-75[data-v-575455fb]{padding-bottom:75px!important}.pb-80[data-v-575455fb]{padding-bottom:80px!important}.pb-85[data-v-575455fb]{padding-bottom:85px!important}.pb-90[data-v-575455fb]{padding-bottom:90px!important}.pb-95[data-v-575455fb]{padding-bottom:95px!important}.pb-100[data-v-575455fb]{padding-bottom:100px!important}.pl-0[data-v-575455fb]{padding-left:0!important}.pl-5[data-v-575455fb]{padding-left:5px!important}.pl-10[data-v-575455fb]{padding-left:10px!important}.pl-15[data-v-575455fb]{padding-left:15px!important}.pl-20[data-v-575455fb]{padding-left:20px!important}.pl-25[data-v-575455fb]{padding-left:25px!important}.pl-30[data-v-575455fb]{padding-left:30px!important}.pl-35[data-v-575455fb]{padding-left:35px!important}.pl-40[data-v-575455fb]{padding-left:40px!important}.pl-45[data-v-575455fb]{padding-left:45px!important}.pl-50[data-v-575455fb]{padding-left:50px!important}.pl-55[data-v-575455fb]{padding-left:55px!important}.pl-60[data-v-575455fb]{padding-left:60px!important}.pl-65[data-v-575455fb]{padding-left:65px!important}.pl-70[data-v-575455fb]{padding-left:70px!important}.pl-75[data-v-575455fb]{padding-left:75px!important}.pl-80[data-v-575455fb]{padding-left:80px!important}.pl-85[data-v-575455fb]{padding-left:85px!important}.pl-90[data-v-575455fb]{padding-left:90px!important}.pl-95[data-v-575455fb]{padding-left:95px!important}.pl-100[data-v-575455fb]{padding-left:100px!important}.pr-0[data-v-575455fb]{padding-right:0!important}.pr-5[data-v-575455fb]{padding-right:5px!important}.pr-10[data-v-575455fb]{padding-right:10px!important}.pr-15[data-v-575455fb]{padding-right:15px!important}.pr-20[data-v-575455fb]{padding-right:20px!important}.pr-25[data-v-575455fb]{padding-right:25px!important}.pr-30[data-v-575455fb]{padding-right:30px!important}.pr-35[data-v-575455fb]{padding-right:35px!important}.pr-40[data-v-575455fb]{padding-right:40px!important}.pr-45[data-v-575455fb]{padding-right:45px!important}.pr-50[data-v-575455fb]{padding-right:50px!important}.pr-55[data-v-575455fb]{padding-right:55px!important}.pr-60[data-v-575455fb]{padding-right:60px!important}.pr-65[data-v-575455fb]{padding-right:65px!important}.pr-70[data-v-575455fb]{padding-right:70px!important}.pr-75[data-v-575455fb]{padding-right:75px!important}.pr-80[data-v-575455fb]{padding-right:80px!important}.pr-85[data-v-575455fb]{padding-right:85px!important}.pr-90[data-v-575455fb]{padding-right:90px!important}.pr-95[data-v-575455fb]{padding-right:95px!important}.pr-100[data-v-575455fb]{padding-right:100px!important}.top-nav[data-v-575455fb]{background-color:#fff}@media screen and (max-width:64.0625em){.top-nav[data-v-575455fb]{margin-top:35px}}@media screen and (max-width:61.9375em){.top-nav .container[data-v-575455fb]{max-width:none}}.top-nav .corporate[data-v-575455fb]{align-items:center;display:flex;flex-wrap:wrap;justify-content:space-between}@media screen and (max-width:47.9375em){.top-nav .corporate[data-v-575455fb]{justify-content:flex-start}}.top-nav .corporate__logo[data-v-575455fb]{order:1}.top-nav .corporate__logo a[data-v-575455fb]:focus{display:block;font-weight:400!important;outline:2px solid #f69038!important;outline-offset:6px!important}@media screen and (max-width:47.9375em){.top-nav .corporate__logo[data-v-575455fb]{margin-right:auto}}.top-nav .corporate__mobile-search[data-v-575455fb]{display:none}@media screen and (max-width:47.9375em){.top-nav .corporate__mobile-search[data-v-575455fb]{display:block;order:2}}.top-nav .corporate__mobile-search-btn[data-v-575455fb]{background-color:#fff;border:none;margin-right:15px;padding:0}@media screen and (max-width:28.125em){.top-nav .corporate__mobile-search-btn[data-v-575455fb]{display:block}}.top-nav .corporate__mobile-search-btn .icon[data-v-575455fb]{font-size:2.5rem}.top-nav .corporate__mobile-search-invisible[data-v-575455fb]{margin-top:3px}.top-nav .corporate__mobile-search-visible[data-v-575455fb]{position:relative}.top-nav .corporate__mobile-search-visible .icon.fas.fa-search[data-v-575455fb]{margin-top:3px}.top-nav .corporate__mobile-search-visible .icon.fas.fa-slash[data-v-575455fb]{left:-5px;position:absolute;top:0;transform:rotate(90deg)}.top-nav .corporate__mobile-menu[data-v-575455fb]{display:none}@media screen and (max-width:59.625em){.top-nav .corporate__mobile-menu[data-v-575455fb]{display:block;order:3}}.top-nav .corporate__mobile-menu button[data-v-575455fb]{background-color:#fff;border:none;padding:0}.top-nav .corporate__mobile-menu button .icon[data-v-575455fb]{font-size:2.5rem}.top-nav .corporate__search[data-v-575455fb]{align-items:strech;background:#fff;border-radius:3px;display:flex;flex:1;margin:0 25px;order:2;position:relative;z-index:99999}@media screen and (max-width:47.9375em){.top-nav .corporate__search[data-v-575455fb]{flex-basis:100%;margin:5px 0 10px;order:4}}.top-nav .corporate__search-form[data-v-575455fb]{display:flex;flex:1;position:relative}.top-nav .corporate__search-select[data-v-575455fb]{-moz-appearance:none;appearance:none;-webkit-appearance:none;background-color:#fff;background-image:linear-gradient(45deg,transparent 50%,#5d6581 0),linear-gradient(135deg,#5d6581 50%,transparent 0);background-position:calc(100% - 8px) calc(1em - 1px),calc(100% - 3px) calc(1em - 1px),100% 0;background-repeat:no-repeat;background-size:5px 5px,5px 5px,2.5em 2.5em;border-radius:3px 0 0 3px!important;-webkit-border-radius:0;border-right:1px solid transparent;padding:0 20px 0 5px}.top-nav .corporate__search-select[data-v-575455fb]:focus{background-color:rgba(48,136,223,.071);border:1px solid #3088df;outline:none}.top-nav .corporate__search-input[data-v-575455fb]{font-size:1.2rem;margin-left:auto;transition:.3s;width:100%}.top-nav .corporate__search-input[data-v-575455fb]:focus{outline:none}.top-nav .corporate__search-box[data-v-575455fb]{background-color:#fff;border:1px solid #b1b4bf;border-radius:3px;box-shadow:0 4px 10px 0 rgba(0,0,0,.2);display:block;position:absolute;top:32px;width:130%;z-index:99999}@media screen and (max-width:59.625em){.top-nav .corporate__search-box[data-v-575455fb]{width:100%}}.top-nav .corporate__search-main-link[data-v-575455fb]{color:#1a254c;display:block;font-size:1.6rem;padding:7px 10px;-webkit-text-decoration:none;text-decoration:none;transition:all .3s;width:100%;word-break:break-word}.top-nav .corporate__search-main-link[data-v-575455fb]:hover{background-color:#e3edfe;text-indent:3px}.top-nav .corporate__search-results[data-v-575455fb]{background-color:#fff;border-top:1px solid #1a254c;list-style:none;margin:0;max-height:410px;overflow-y:scroll;padding:0}.top-nav .corporate__search-heading-search[data-v-575455fb]{color:gray;font-size:1.2rem;font-weight:700;margin-bottom:0;padding:0 10px}.top-nav .corporate__search-list[data-v-575455fb]{display:flex;padding:7px 10px;transition:all .3s}.top-nav .corporate__search-list[data-v-575455fb]:hover{background-color:#e8ecee}.top-nav .corporate__search-list .icon[data-v-575455fb]{color:#1a254c;font-size:1rem;margin-right:5px;margin-top:2px}.top-nav .corporate__search-link[data-v-575455fb]{color:#1a254c;display:inline-block}.top-nav .corporate__search-link[data-v-575455fb],.top-nav .corporate__search-related-link[data-v-575455fb]{cursor:pointer;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:-moz-fit-content;width:fit-content}.top-nav .corporate__search-related-link[data-v-575455fb]{color:#3088df;font-size:1.2rem;line-height:17px;margin-left:5px}.top-nav .corporate__search-related-link[data-v-575455fb]:hover{-webkit-text-decoration:underline;text-decoration:underline}.top-nav .corporate__search-btn[data-v-575455fb]{border-radius:0 3px 3px 0;margin:0;padding:6px 25px}.top-nav .corporate__search-btn[data-v-575455fb]:focus{outline:2px solid #f69038!important;outline-offset:6px!important}.top-nav .corporate__nav[data-v-575455fb]{order:3}@media screen and (max-width:59.625em){.top-nav .corporate__nav[data-v-575455fb]{display:none}}.top-nav .corporate__links[data-v-575455fb]{display:flex;flex-wrap:wrap;padding:0}.top-nav .corporate__link-item[data-v-575455fb]{list-style:none;outline:none;padding:10px 0;position:relative}.top-nav .corporate__link-item[data-v-575455fb]:not(:last-child){align-self:center;margin-right:15px}.top-nav .corporate__link-item[data-v-575455fb]:focus-within,.top-nav .corporate__link-item[data-v-575455fb]:hover{background-color:hsla(0,0%,100%,.2);transition:all .2s ease}.top-nav .corporate__link-item:focus-within .corporate__link[data-v-575455fb],.top-nav .corporate__link-item:hover .corporate__link[data-v-575455fb]{color:#1e70c2}.top-nav .corporate__link-item:focus-within .corporate__link-submenu[data-v-575455fb],.top-nav .corporate__link-item:hover .corporate__link-submenu[data-v-575455fb]{visibility:visible}.top-nav .corporate__link-item:first-child:hover span[data-v-575455fb]{color:#1e70c2;transition:all .2s ease}.top-nav .corporate__link-item:focus-within .icon[data-v-575455fb],.top-nav .corporate__link-item:hover .icon[data-v-575455fb]{color:#1e70c2;transform:rotate(180deg);transition:transform .2s ease}.top-nav .corporate__link-item .icon[data-v-575455fb]{color:#1a254c;transition:transform .2s ease}.top-nav .corporate__link-item .icon[data-v-575455fb]:hover{cursor:pointer}.top-nav .corporate__link[data-v-575455fb]{color:#1a254c;cursor:pointer;font-size:1.6rem;-webkit-text-decoration:none;text-decoration:none;transition:all .2s ease}.top-nav .corporate__link-submenu[data-v-575455fb]{background-color:#fff;box-shadow:0 0 10px 0 rgba(0,0,0,.2);display:block;padding:0;position:absolute;top:35px;visibility:hidden;white-space:nowrap;z-index:300}.top-nav .corporate__link-submenu[data-v-575455fb]:before{border:7px solid transparent;border-bottom-color:#fff;content:"";height:0;left:50%;position:absolute;top:-14px;transform:translateX(-50%);width:14px}.top-nav .corporate__link-submenu li[data-v-575455fb]{list-style:none}.top-nav .corporate__link-submenu li a[data-v-575455fb]{color:#1a254c;display:block;padding:10px 20px;-webkit-text-decoration:none!important;text-decoration:none!important}.top-nav .corporate__link-submenu li a[data-v-575455fb]:focus-within,.top-nav .corporate__link-submenu li a[data-v-575455fb]:hover{background-color:#eceff9;font-weight:400}.top-nav .corporate__link-submenu--my-roles[data-v-575455fb]:focus{outline:2px solid #f69038!important;outline-offset:6px!important}.top-nav .corporate__link-item--logged-in[data-v-575455fb]{list-style:none}.top-nav .corporate__logged-in-link[data-v-575455fb]{cursor:pointer;font-weight:400;-webkit-text-decoration:none;text-decoration:none}.top-nav .corporate__user-account[data-v-575455fb]{align-items:center;display:flex;flex-wrap:wrap;justify-content:space-between}.top-nav .corporate__user-info[data-v-575455fb]{margin-left:5px;margin-right:5px}.top-nav .corporate__user-info p[data-v-575455fb]{color:#1a254c;line-height:10px}.top-nav .corporate__user-info small[data-v-575455fb]{color:#1a254c;opacity:.7}.top-nav .corporate__user-img[data-v-575455fb]{border-radius:50px;overflow:hidden}.top-nav .corporate__user-img img[data-v-575455fb]{height:auto;width:35px}.top-nav .corporate__user-details .icon[data-v-575455fb]{color:#1a254c!important;font-size:1.4rem}.top-nav .corporate__link-submenu--user[data-v-575455fb]{min-width:180px;padding:0;top:50px}.top-nav .corporate__link-submenu--user p[data-v-575455fb]{font-weight:700;padding:0 20px}.bottom-nav-1[data-v-575455fb]{background-color:#1a254c}@media screen and (max-width:59.625em){.bottom-nav-1[data-v-575455fb]{display:none}}@media screen and (max-width:47.9375em){.bottom-nav-1 .container[data-v-575455fb]{margin-left:0;margin-right:0;max-width:none;padding:0}}@media screen and (max-width:61.9375em){.bottom-nav-1 .container[data-v-575455fb]{max-width:none}}@media screen and (max-width:59.6875em){.bottom-nav-2[data-v-575455fb]{background-color:#1a254c;padding:0}}@media screen and (min-width:59.6875em){.bottom-nav-2[data-v-575455fb]{display:none}}.bottom-nav-2 .journal ul[data-v-575455fb]{margin:0;padding:0;width:100%}.bottom-nav-2 .journal__link-item--journals[data-v-575455fb]{width:100%}@media screen and (max-width:37.5em){.bottom-nav-2 .journal__link-submenu-journals li a[data-v-575455fb]{padding:10px}}@media screen and (max-width:26.9375em){.bottom-nav-2 .journal__link-submenu-journals li a[data-v-575455fb]{padding:10px 10px 15px}}@media screen and (max-width:37.5em){.bottom-nav-2 .journal__link--home[data-v-575455fb]{padding:10px}}.journal[data-v-575455fb]{align-items:center;display:flex;flex-wrap:wrap;justify-content:flex-start}.journal__nav[data-v-575455fb]{background-color:#1a254c;display:flex}.journal__links[data-v-575455fb]{display:flex;flex-wrap:wrap;margin:0;padding:0}.journal__link-item[data-v-575455fb]{cursor:pointer;list-style:none;outline:none;padding:16px 0;position:relative;transition:all .2s ease}@media screen and (max-width:45.9375em){.journal__link-item[data-v-575455fb]{width:100%}}.journal__link-item:focus-within .journal__link[data-v-575455fb],.journal__link-item:hover .journal__link[data-v-575455fb]{color:#b3b3b3;transition:all .2s ease}.journal__link-item:focus-within .icon.fa-caret-down[data-v-575455fb],.journal__link-item:hover .icon.fa-caret-down[data-v-575455fb]{color:#b3b3b3;transform:rotate(180deg);transition:all .2s ease}.journal__link-item:focus-within .journal__link-submenu[data-v-575455fb],.journal__link-item:hover .journal__link-submenu[data-v-575455fb]{visibility:visible}.journal__link-item .icon[data-v-575455fb]{color:#fff;font-size:14px}.journal__link-item--journals[data-v-575455fb]{padding:0}.journal__journals-list[data-v-575455fb]{outline:none}.journal__journals-list:focus .icon[data-v-575455fb]{border:1px solid #fff;transform:rotate(1turn);transition:.5s}.journal__journals-list a[data-v-575455fb]{padding-right:10px}.journal__journals-list .icon[data-v-575455fb]{border-left:1px solid #fff;font-size:1.6rem}.journal__journals-list .icon.fas.fa-arrow-down[data-v-575455fb]{padding:16px}@media screen and (max-width:37.5em){.journal__journals-list .icon.fas.fa-arrow-down[data-v-575455fb]{padding:12px}}.journal__journals-list .icon.fas.fa-times[data-v-575455fb]{padding:16px 17.5px}@media screen and (max-width:37.5em){.journal__journals-list .icon.fas.fa-times[data-v-575455fb]{padding:12px 13.5px}}.journal__link-item-container[data-v-575455fb]{align-items:center;display:flex;justify-content:space-between}.journal__link[data-v-575455fb]{color:#fff;cursor:pointer;font-size:1.6rem;-webkit-text-decoration:none;text-decoration:none;transition:all .2s ease}@media screen and (max-width:45.9375em){.journal__link[data-v-575455fb]{padding-left:30px}}.journal__link--home[data-v-575455fb]{color:#fff;cursor:pointer;font-size:1.6rem;font-weight:400!important;padding:16px;-webkit-text-decoration:none;text-decoration:none;transition:.3s;width:100%}.journal__link--home[data-v-575455fb]:focus{text-indent:4px}.journal__link-submenu[data-v-575455fb]{background:#fff;box-shadow:0 0 10px 0 rgba(0,0,0,.2);display:block;padding:0;position:absolute;top:42px;visibility:hidden;white-space:nowrap;z-index:300}.journal__link-submenu[data-v-575455fb]:before{border:7px solid transparent;border-bottom-color:#fff;content:"";height:0;left:50%;position:absolute;top:-14px;transform:translateX(-50%);width:14px}@media screen and (max-width:45.9375em){.journal__link-submenu[data-v-575455fb]:before{display:none}.journal__link-submenu[data-v-575455fb]{position:static}}.journal__link-submenu li[data-v-575455fb]{list-style:none}.journal__link-submenu li a[data-v-575455fb]{color:#1a254c;display:block;padding:10px 20px;-webkit-text-decoration:none!important;text-decoration:none!important}.journal__link-submenu li a[data-v-575455fb]:focus,.journal__link-submenu li a[data-v-575455fb]:hover{background-color:#eceff9;font-weight:400}@media screen and (max-width:45.9375em){.journal__link-submenu li a[data-v-575455fb]{padding:10px 40px}}.journal__link-submenu-journals[data-v-575455fb]{background:#1e70c2;box-shadow:0 4px 10px 0 rgba(0,0,0,.2);display:none;height:400px;left:0;overflow-y:scroll;padding:0;position:absolute;top:51px;white-space:nowrap;width:437px;z-index:300}@media screen and (max-width:45.9375em){.journal__link-submenu-journals[data-v-575455fb]{position:static}}.journal__link-submenu-journals li[data-v-575455fb]{border-top:1px solid #fff;list-style:none;transition:all .3s ease}.journal__link-submenu-journals li[data-v-575455fb]:focus,.journal__link-submenu-journals li[data-v-575455fb]:hover{background-color:#2d77c6;font-weight:400;text-indent:8px}.journal__link-submenu-journals li a[data-v-575455fb]{color:#fff;display:flex;flex-wrap:wrap;font-size:1.6rem;justify-content:space-between;padding:10px 10px 10px 15px;position:relative;-webkit-text-decoration:none!important;text-decoration:none!important}@media screen and (max-width:22.1875em){.journal__link-submenu-journals li a[data-v-575455fb]{font-size:1.4rem}}.journal__link-submenu-journals li a span.articles-number[data-v-575455fb]{align-self:center;font-size:1rem}.journal__link-item--journal-info[data-v-575455fb]{margin-left:29px}.journal__link-item--browse[data-v-575455fb],.journal__link-item--journal-info[data-v-575455fb]{margin-right:29px}.journal__link-item--journals[data-v-575455fb]{background-color:#1e70c2;width:437px}.journal__link-submenu--journal-info[data-v-575455fb]{left:-50px}.journal__link-submenu--browse[data-v-575455fb]{left:-30px}.journal__link-submenu--select[data-v-575455fb]{align-items:center;display:flex;padding:10px 20px}@media screen and (max-width:45.9375em){.journal__link-submenu--select[data-v-575455fb]{padding:10px 40px!important}}.journal__link-submenu--select label[data-v-575455fb]{margin-right:10px}.journal__link-submenu--select select[data-v-575455fb]{width:-webkit-fill-available}.journal__link-submenu--select select[data-v-575455fb]:focus{outline:none}.journal__submit-article[data-v-575455fb]{font-size:1.6rem!important;-webkit-text-decoration:none!important;text-decoration:none!important}.journal__submit-article[data-v-575455fb]:focus{font-weight:400;outline:2px solid #f69038!important;outline-offset:6px!important}@media screen and (max-width:45.9375em){.journal__submit-article[data-v-575455fb]{margin-left:30px;padding:12px}}.mobile-nav[data-v-575455fb]{background-color:#1a254c}@media screen and (max-width:59.625em){.mobile-nav[data-v-575455fb]{display:block}}.mobile-nav a[data-v-575455fb]{-webkit-text-decoration:none;text-decoration:none}.mobile-nav__links[data-v-575455fb]{display:flex;flex-direction:column;flex-wrap:wrap}.mobile-nav__links a[data-v-575455fb]{border-bottom:1px solid #485170;color:#fff;padding:12px 15px}.mobile-nav__links[data-v-575455fb]:first-child{border-top:1px solid #485170}.mobile-nav__expandable[data-v-575455fb]{align-items:center;justify-content:space-between}.mobile-nav__expandable[data-v-575455fb],.mobile-nav__user-account[data-v-575455fb]{display:flex;flex-wrap:wrap}.mobile-nav__user-img[data-v-575455fb]{border:2px solid #fff;border-radius:50px;margin-right:10px;overflow:hidden}.mobile-nav__user-img img[data-v-575455fb]{height:auto;width:35px}.mobile-nav__user-info small[data-v-575455fb]{opacity:.7}.mobile-nav__user-submenu[data-v-575455fb]{background-color:#313b5e;display:flex;flex-basis:100%;flex-direction:column}.mobile-nav__user-submenu p[data-v-575455fb]{color:#fff;font-weight:700;opacity:.5;padding:0 15px}.mobile-nav__user-submenu a[data-v-575455fb]{border-bottom:none}.mobile-nav__social-media[data-v-575455fb]{padding:12px 15px}.mobile-nav__social-media p[data-v-575455fb]{color:#fff;font-weight:700}input[data-v-575455fb]{border-radius:0!important}.show-journals[data-v-575455fb]{display:block!important}.journal__link-submenu-journals[data-v-575455fb]::-webkit-scrollbar{width:7px}.journal__link-submenu-journals[data-v-575455fb]::-webkit-scrollbar-track{background-color:#fff;border:1px solid rgba(0,0,0,.15)}.journal__link-submenu-journals[data-v-575455fb]::-webkit-scrollbar-thumb{background:#2d77c6;border-radius:20px}.journal__link-submenu-journals[data-v-575455fb]::-webkit-scrollbar-thumb:hover{background:#1e60bc}.corporate__search-results[data-v-575455fb]::-webkit-scrollbar{width:5.5px}.corporate__search-results[data-v-575455fb]::-webkit-scrollbar-track{background-color:#fff;border:1px solid rgba(0,0,0,.15);border-radius:3px}.corporate__search-results[data-v-575455fb]::-webkit-scrollbar-thumb{background:#1e70c2;border-radius:20px}.overlay[data-v-575455fb]{background:rgba(17,26,55,.702);height:100vh;left:0;padding:200vh 200vw;position:fixed;top:0;width:100%;z-index:999}.remove-styling[data-v-575455fb]{border:0!important;padding:0!important}
.mt-0{margin-top:0!important}.mt-5{margin-top:5px!important}.mt-10{margin-top:10px!important}.mt-15{margin-top:15px!important}.mt-20{margin-top:20px!important}.mt-25{margin-top:25px!important}.mt-30{margin-top:30px!important}.mt-35{margin-top:35px!important}.mt-40{margin-top:40px!important}.mt-45{margin-top:45px!important}.mt-50{margin-top:50px!important}.mt-55{margin-top:55px!important}.mt-60{margin-top:60px!important}.mt-65{margin-top:65px!important}.mt-70{margin-top:70px!important}.mt-75{margin-top:75px!important}.mt-80{margin-top:80px!important}.mt-85{margin-top:85px!important}.mt-90{margin-top:90px!important}.mt-95{margin-top:95px!important}.mt-100{margin-top:100px!important}.mb-0{margin-bottom:0!important}.mb-5{margin-bottom:5px!important}.mb-10{margin-bottom:10px!important}.mb-15{margin-bottom:15px!important}.mb-20{margin-bottom:20px!important}.mb-25{margin-bottom:25px!important}.mb-30{margin-bottom:30px!important}.mb-35{margin-bottom:35px!important}.mb-40{margin-bottom:40px!important}.mb-45{margin-bottom:45px!important}.mb-50{margin-bottom:50px!important}.mb-55{margin-bottom:55px!important}.mb-60{margin-bottom:60px!important}.mb-65{margin-bottom:65px!important}.mb-70{margin-bottom:70px!important}.mb-75{margin-bottom:75px!important}.mb-80{margin-bottom:80px!important}.mb-85{margin-bottom:85px!important}.mb-90{margin-bottom:90px!important}.mb-95{margin-bottom:95px!important}.mb-100{margin-bottom:100px!important}.ml-0{margin-left:0!important}.ml-5{margin-left:5px!important}.ml-10{margin-left:10px!important}.ml-15{margin-left:15px!important}.ml-20{margin-left:20px!important}.ml-25{margin-left:25px!important}.ml-30{margin-left:30px!important}.ml-35{margin-left:35px!important}.ml-40{margin-left:40px!important}.ml-45{margin-left:45px!important}.ml-50{margin-left:50px!important}.ml-55{margin-left:55px!important}.ml-60{margin-left:60px!important}.ml-65{margin-left:65px!important}.ml-70{margin-left:70px!important}.ml-75{margin-left:75px!important}.ml-80{margin-left:80px!important}.ml-85{margin-left:85px!important}.ml-90{margin-left:90px!important}.ml-95{margin-left:95px!important}.ml-100{margin-left:100px!important}.mr-0{margin-right:0!important}.mr-5{margin-right:5px!important}.mr-10{margin-right:10px!important}.mr-15{margin-right:15px!important}.mr-20{margin-right:20px!important}.mr-25{margin-right:25px!important}.mr-30{margin-right:30px!important}.mr-35{margin-right:35px!important}.mr-40{margin-right:40px!important}.mr-45{margin-right:45px!important}.mr-50{margin-right:50px!important}.mr-55{margin-right:55px!important}.mr-60{margin-right:60px!important}.mr-65{margin-right:65px!important}.mr-70{margin-right:70px!important}.mr-75{margin-right:75px!important}.mr-80{margin-right:80px!important}.mr-85{margin-right:85px!important}.mr-90{margin-right:90px!important}.mr-95{margin-right:95px!important}.mr-100{margin-right:100px!important}.pt-0{padding-top:0!important}.pt-5{padding-top:5px!important}.pt-10{padding-top:10px!important}.pt-15{padding-top:15px!important}.pt-20{padding-top:20px!important}.pt-25{padding-top:25px!important}.pt-30{padding-top:30px!important}.pt-35{padding-top:35px!important}.pt-40{padding-top:40px!important}.pt-45{padding-top:45px!important}.pt-50{padding-top:50px!important}.pt-55{padding-top:55px!important}.pt-60{padding-top:60px!important}.pt-65{padding-top:65px!important}.pt-70{padding-top:70px!important}.pt-75{padding-top:75px!important}.pt-80{padding-top:80px!important}.pt-85{padding-top:85px!important}.pt-90{padding-top:90px!important}.pt-95{padding-top:95px!important}.pt-100{padding-top:100px!important}.pb-0{padding-bottom:0!important}.pb-5{padding-bottom:5px!important}.pb-10{padding-bottom:10px!important}.pb-15{padding-bottom:15px!important}.pb-20{padding-bottom:20px!important}.pb-25{padding-bottom:25px!important}.pb-30{padding-bottom:30px!important}.pb-35{padding-bottom:35px!important}.pb-40{padding-bottom:40px!important}.pb-45{padding-bottom:45px!important}.pb-50{padding-bottom:50px!important}.pb-55{padding-bottom:55px!important}.pb-60{padding-bottom:60px!important}.pb-65{padding-bottom:65px!important}.pb-70{padding-bottom:70px!important}.pb-75{padding-bottom:75px!important}.pb-80{padding-bottom:80px!important}.pb-85{padding-bottom:85px!important}.pb-90{padding-bottom:90px!important}.pb-95{padding-bottom:95px!important}.pb-100{padding-bottom:100px!important}.pl-0{padding-left:0!important}.pl-5{padding-left:5px!important}.pl-10{padding-left:10px!important}.pl-15{padding-left:15px!important}.pl-20{padding-left:20px!important}.pl-25{padding-left:25px!important}.pl-30{padding-left:30px!important}.pl-35{padding-left:35px!important}.pl-40{padding-left:40px!important}.pl-45{padding-left:45px!important}.pl-50{padding-left:50px!important}.pl-55{padding-left:55px!important}.pl-60{padding-left:60px!important}.pl-65{padding-left:65px!important}.pl-70{padding-left:70px!important}.pl-75{padding-left:75px!important}.pl-80{padding-left:80px!important}.pl-85{padding-left:85px!important}.pl-90{padding-left:90px!important}.pl-95{padding-left:95px!important}.pl-100{padding-left:100px!important}.pr-0{padding-right:0!important}.pr-5{padding-right:5px!important}.pr-10{padding-right:10px!important}.pr-15{padding-right:15px!important}.pr-20{padding-right:20px!important}.pr-25{padding-right:25px!important}.pr-30{padding-right:30px!important}.pr-35{padding-right:35px!important}.pr-40{padding-right:40px!important}.pr-45{padding-right:45px!important}.pr-50{padding-right:50px!important}.pr-55{padding-right:55px!important}.pr-60{padding-right:60px!important}.pr-65{padding-right:65px!important}.pr-70{padding-right:70px!important}.pr-75{padding-right:75px!important}.pr-80{padding-right:80px!important}.pr-85{padding-right:85px!important}.pr-90{padding-right:90px!important}.pr-95{padding-right:95px!important}.pr-100{padding-right:100px!important}.logo-img{max-width:340px;width:100%}
.mt-0{margin-top:0!important}.mt-5{margin-top:5px!important}.mt-10{margin-top:10px!important}.mt-15{margin-top:15px!important}.mt-20{margin-top:20px!important}.mt-25{margin-top:25px!important}.mt-30{margin-top:30px!important}.mt-35{margin-top:35px!important}.mt-40{margin-top:40px!important}.mt-45{margin-top:45px!important}.mt-50{margin-top:50px!important}.mt-55{margin-top:55px!important}.mt-60{margin-top:60px!important}.mt-65{margin-top:65px!important}.mt-70{margin-top:70px!important}.mt-75{margin-top:75px!important}.mt-80{margin-top:80px!important}.mt-85{margin-top:85px!important}.mt-90{margin-top:90px!important}.mt-95{margin-top:95px!important}.mt-100{margin-top:100px!important}.mb-0{margin-bottom:0!important}.mb-5{margin-bottom:5px!important}.mb-10{margin-bottom:10px!important}.mb-15{margin-bottom:15px!important}.mb-20{margin-bottom:20px!important}.mb-25{margin-bottom:25px!important}.mb-30{margin-bottom:30px!important}.mb-35{margin-bottom:35px!important}.mb-40{margin-bottom:40px!important}.mb-45{margin-bottom:45px!important}.mb-50{margin-bottom:50px!important}.mb-55{margin-bottom:55px!important}.mb-60{margin-bottom:60px!important}.mb-65{margin-bottom:65px!important}.mb-70{margin-bottom:70px!important}.mb-75{margin-bottom:75px!important}.mb-80{margin-bottom:80px!important}.mb-85{margin-bottom:85px!important}.mb-90{margin-bottom:90px!important}.mb-95{margin-bottom:95px!important}.mb-100{margin-bottom:100px!important}.ml-0{margin-left:0!important}.ml-5{margin-left:5px!important}.ml-10{margin-left:10px!important}.ml-15{margin-left:15px!important}.ml-20{margin-left:20px!important}.ml-25{margin-left:25px!important}.ml-30{margin-left:30px!important}.ml-35{margin-left:35px!important}.ml-40{margin-left:40px!important}.ml-45{margin-left:45px!important}.ml-50{margin-left:50px!important}.ml-55{margin-left:55px!important}.ml-60{margin-left:60px!important}.ml-65{margin-left:65px!important}.ml-70{margin-left:70px!important}.ml-75{margin-left:75px!important}.ml-80{margin-left:80px!important}.ml-85{margin-left:85px!important}.ml-90{margin-left:90px!important}.ml-95{margin-left:95px!important}.ml-100{margin-left:100px!important}.mr-0{margin-right:0!important}.mr-5{margin-right:5px!important}.mr-10{margin-right:10px!important}.mr-15{margin-right:15px!important}.mr-20{margin-right:20px!important}.mr-25{margin-right:25px!important}.mr-30{margin-right:30px!important}.mr-35{margin-right:35px!important}.mr-40{margin-right:40px!important}.mr-45{margin-right:45px!important}.mr-50{margin-right:50px!important}.mr-55{margin-right:55px!important}.mr-60{margin-right:60px!important}.mr-65{margin-right:65px!important}.mr-70{margin-right:70px!important}.mr-75{margin-right:75px!important}.mr-80{margin-right:80px!important}.mr-85{margin-right:85px!important}.mr-90{margin-right:90px!important}.mr-95{margin-right:95px!important}.mr-100{margin-right:100px!important}.pt-0{padding-top:0!important}.pt-5{padding-top:5px!important}.pt-10{padding-top:10px!important}.pt-15{padding-top:15px!important}.pt-20{padding-top:20px!important}.pt-25{padding-top:25px!important}.pt-30{padding-top:30px!important}.pt-35{padding-top:35px!important}.pt-40{padding-top:40px!important}.pt-45{padding-top:45px!important}.pt-50{padding-top:50px!important}.pt-55{padding-top:55px!important}.pt-60{padding-top:60px!important}.pt-65{padding-top:65px!important}.pt-70{padding-top:70px!important}.pt-75{padding-top:75px!important}.pt-80{padding-top:80px!important}.pt-85{padding-top:85px!important}.pt-90{padding-top:90px!important}.pt-95{padding-top:95px!important}.pt-100{padding-top:100px!important}.pb-0{padding-bottom:0!important}.pb-5{padding-bottom:5px!important}.pb-10{padding-bottom:10px!important}.pb-15{padding-bottom:15px!important}.pb-20{padding-bottom:20px!important}.pb-25{padding-bottom:25px!important}.pb-30{padding-bottom:30px!important}.pb-35{padding-bottom:35px!important}.pb-40{padding-bottom:40px!important}.pb-45{padding-bottom:45px!important}.pb-50{padding-bottom:50px!important}.pb-55{padding-bottom:55px!important}.pb-60{padding-bottom:60px!important}.pb-65{padding-bottom:65px!important}.pb-70{padding-bottom:70px!important}.pb-75{padding-bottom:75px!important}.pb-80{padding-bottom:80px!important}.pb-85{padding-bottom:85px!important}.pb-90{padding-bottom:90px!important}.pb-95{padding-bottom:95px!important}.pb-100{padding-bottom:100px!important}.pl-0{padding-left:0!important}.pl-5{padding-left:5px!important}.pl-10{padding-left:10px!important}.pl-15{padding-left:15px!important}.pl-20{padding-left:20px!important}.pl-25{padding-left:25px!important}.pl-30{padding-left:30px!important}.pl-35{padding-left:35px!important}.pl-40{padding-left:40px!important}.pl-45{padding-left:45px!important}.pl-50{padding-left:50px!important}.pl-55{padding-left:55px!important}.pl-60{padding-left:60px!important}.pl-65{padding-left:65px!important}.pl-70{padding-left:70px!important}.pl-75{padding-left:75px!important}.pl-80{padding-left:80px!important}.pl-85{padding-left:85px!important}.pl-90{padding-left:90px!important}.pl-95{padding-left:95px!important}.pl-100{padding-left:100px!important}.pr-0{padding-right:0!important}.pr-5{padding-right:5px!important}.pr-10{padding-right:10px!important}.pr-15{padding-right:15px!important}.pr-20{padding-right:20px!important}.pr-25{padding-right:25px!important}.pr-30{padding-right:30px!important}.pr-35{padding-right:35px!important}.pr-40{padding-right:40px!important}.pr-45{padding-right:45px!important}.pr-50{padding-right:50px!important}.pr-55{padding-right:55px!important}.pr-60{padding-right:60px!important}.pr-65{padding-right:65px!important}.pr-70{padding-right:70px!important}.pr-75{padding-right:75px!important}.pr-80{padding-right:80px!important}.pr-85{padding-right:85px!important}.pr-90{padding-right:90px!important}.pr-95{padding-right:95px!important}.pr-100{padding-right:100px!important}.tabs{border-bottom:2px solid #939ab1;display:flex;justify-content:space-evenly;margin:40px 0 30px}@media screen and (max-width:33.1875em){.tabs{text-align:center}}.tabs a{border-bottom:2px solid #939ab1;color:#1a254c;font-size:1.6rem;font-weight:700;margin-bottom:-2px;padding:10px 10px 5px}.tabs a:focus,.tabs a:hover{background-color:#b8d6f4;border-bottom:2px solid #1e70c2;outline:none;-webkit-text-decoration:none;text-decoration:none}.tabs .nuxt-link-exact-active{border-bottom:2px solid #1e70c2;color:#1e70c2}.tabs-metrics,.tabs-tweetations{align-items:baseline;display:flex;flex-wrap:wrap;justify-content:flex-start;margin-bottom:20px}.tabs-metrics a,.tabs-tweetations a{color:#1a254c;cursor:pointer;padding:10px 0 5px;text-align:center}.tabs-metrics a:focus,.tabs-metrics a:hover,.tabs-tweetations a:focus,.tabs-tweetations a:hover{color:#1e70c2}.tabs-metrics span,.tabs-tweetations span{margin:0 10px}.active{border-bottom:2px solid #1e70c2!important;color:#1e70c2!important}.mobile-show{display:none}@media screen and (max-width:47.9375em){.mobile-show{display:block}}.desktop-show{display:block}@media screen and (max-width:47.9375em){.desktop-show{display:none}}.advertisement{margin-top:25px}.advertisement:focus .advertisement__text,.advertisement:hover .advertisement__text{color:#1e70c2}.advertisement__link{background-color:#f1f3f5;border-radius:3px;display:flex;font-weight:700;justify-content:space-between;padding:20px;-webkit-text-decoration:none;text-decoration:none}@media screen and (max-width:33.1875em){.advertisement__link{flex-wrap:wrap}}.advertisement__text{color:#000;font-size:1.8rem;padding-right:10px}.advertisement__button{align-self:center;background-color:#1e70c2;border-radius:3px;color:#fff;font-size:2rem;padding:15px 20px;position:relative;transition:.3s;width:200px}@media screen and (max-width:74.9375em){.advertisement__button{width:150px}}@media screen and (max-width:47.9375em){.advertisement__button{width:200px}}@media screen and (max-width:33.1875em){.advertisement__button{margin-left:auto;margin-top:10px;padding:10px 20px;width:170px}}.advertisement__button .advertisement__icon{font-size:1.7rem;position:absolute;right:2.2rem;top:2rem;transition:.3s}@media screen and (max-width:33.1875em){.advertisement__button .advertisement__icon{top:1.5rem}}.advertisement__button:focus,.advertisement__button:hover{opacity:.9}.advertisement__button:focus .advertisement__icon,.advertisement__button:hover .advertisement__icon{right:1.5rem}.authors-for-screen-reader{height:1px;left:-10000px;overflow:hidden;position:absolute;top:auto;width:1px}.authors-for-screen-reader:focus{display:block;font-weight:700;height:auto;outline:2px solid #f69038!important;outline-offset:6px!important;overflow:hidden;position:static;width:auto}.main .details{background-color:#f1f3f5;border-radius:3px;margin-top:25px;padding:10px}.main .details p{font-size:1.6rem;font-weight:700;margin:0}.main .preprints-version{align-items:baseline;display:flex;margin-top:10px}.info{display:flex;flex-wrap:wrap}.info__article-img{cursor:pointer;flex:0 0 22%;height:-moz-fit-content;height:fit-content;margin-right:20px;position:relative}@media screen and (max-width:61.9375em){.info__article-img{display:none}}.info__article-img img{display:block;width:100%}.info__article-img-info{background-color:rgba(26,37,76,.749);bottom:0;color:#fff;height:0;left:0;margin:0;overflow:hidden;position:absolute;right:0;text-align:center;transition:.5s ease;width:100%}.info__article-img-info .icon{font-size:3rem;margin-top:30%}.info__article-img:hover .info__article-img-info{height:100%}.info__title-authors{flex:0 0 75%}@media screen and (max-width:61.9375em){.info__title-authors{flex:0 0 100%}}.info__title-authors h3:focus{outline:2px solid #f69038!important;outline-offset:6px!important}.info__hidden-title{height:1px;left:-10000px;overflow:hidden;position:absolute;top:auto;width:1px}.info__authors{display:inline-block}.info__orcid-img{height:15px}.tabs a{flex-grow:1;text-align:center}@media screen and (max-width:47.9375em){.tabs{flex-direction:column}}.sidebar-citation .export-metadata div{margin-bottom:10px}.sidebar-citation .collection h4:focus{outline:2px solid #f69038!important;outline-offset:6px!important}.sidebar-citation .collection__span{display:block}@media screen and (max-width:61.9375em){.sidebar-citation .collection__span{display:inline-block}}.sidebar-citation .collection__link{background:#1e70c2;border-radius:3px;color:#fff;display:block;font-size:1.2rem;margin-bottom:5px;padding:5px 10px;width:-moz-fit-content;width:fit-content}.sidebar-citation .download-btns{display:flex;flex-wrap:wrap;justify-content:space-between;margin-bottom:20px}@media screen and (max-width:61.9375em){.sidebar-citation .download-btns{justify-content:flex-start}.sidebar-citation .download-btns a{margin-right:10px}}.article-content h3{font-size:2.2rem;line-height:2.4rem}.article-content ol li,.article-content ul li{margin-bottom:10px}.main-article-content a{color:#1e70c2}.main-article-content a:hover{-webkit-text-decoration:underline;text-decoration:underline}.author-affiliation-details,.authors-container .authors.clearfix .clearfix,.corresponding-author-and-affiliations,.h4-original-paper{display:none}.authors .clearfix{display:flex;flex-wrap:wrap;list-style:none;padding:0}.authors .clearfix li{margin-right:10px}.authors .clearfix li a{color:#1e70c2}.article-content figure{background-color:#f1f3f5;border-radius:3px;margin:0;padding:20px}#Abstract{margin-top:10px}#Abstract,#Discussion,#Introduction,#Keywords,#Methods,#Results{border-bottom:1px solid #ccd1d5}.abstract-sub-heading{display:block;font-size:1.6rem;font-weight:700}.figure-table{background:#f1f3f5;border-radius:3px;height:auto;margin-bottom:20px;overflow-x:auto;overflow-y:hidden;padding:20px 20px 0}.figure-table::-webkit-scrollbar{-webkit-appearance:none}.figure-table::-webkit-scrollbar-track{border-radius:8px;box-shadow:inset 0 0 5px #5d6581}.figure-table::-webkit-scrollbar:vertical{width:8px}.figure-table::-webkit-scrollbar:horizontal{height:8px}.figure-table::-webkit-scrollbar-thumb{background-color:#1e70c2;border-radius:8px}.textbox-container{border:2px solid #333;padding:15px}.textbox-container h5{margin-bottom:0;margin-top:0}.footnotes ol{word-wrap:break-word}img.figure-image,img.graphic-image,img.inline-graphic-image{width:100%}table{margin:0}td,th{padding:5px 0 5px 15px}.careers{margin-top:25px}.career-widget{border-bottom:1px solid #ccc;cursor:pointer;padding:5px 20px 20px;transition:box-shadow .3s ease}.career-widget:hover{box-shadow:0 0 10px 0 rgba(0,0,0,.1)}.job,.job:hover{color:inherit;-webkit-text-decoration:none;text-decoration:none}.job:hover .job-title{-webkit-text-decoration:underline;text-decoration:underline}.job-title{font-weight:700;margin-top:20px}.icon-prereview{margin-top:5px}.pre-review-container{display:flex;line-height:16pt;margin-top:10px}.pre-review-text{display:inline-block;margin-left:5px}.pre-review-text a{-webkit-text-decoration:underline;text-decoration:underline}
.mt-0{margin-top:0!important}.mt-5{margin-top:5px!important}.mt-10{margin-top:10px!important}.mt-15{margin-top:15px!important}.mt-20{margin-top:20px!important}.mt-25{margin-top:25px!important}.mt-30{margin-top:30px!important}.mt-35{margin-top:35px!important}.mt-40{margin-top:40px!important}.mt-45{margin-top:45px!important}.mt-50{margin-top:50px!important}.mt-55{margin-top:55px!important}.mt-60{margin-top:60px!important}.mt-65{margin-top:65px!important}.mt-70{margin-top:70px!important}.mt-75{margin-top:75px!important}.mt-80{margin-top:80px!important}.mt-85{margin-top:85px!important}.mt-90{margin-top:90px!important}.mt-95{margin-top:95px!important}.mt-100{margin-top:100px!important}.mb-0{margin-bottom:0!important}.mb-5{margin-bottom:5px!important}.mb-10{margin-bottom:10px!important}.mb-15{margin-bottom:15px!important}.mb-20{margin-bottom:20px!important}.mb-25{margin-bottom:25px!important}.mb-30{margin-bottom:30px!important}.mb-35{margin-bottom:35px!important}.mb-40{margin-bottom:40px!important}.mb-45{margin-bottom:45px!important}.mb-50{margin-bottom:50px!important}.mb-55{margin-bottom:55px!important}.mb-60{margin-bottom:60px!important}.mb-65{margin-bottom:65px!important}.mb-70{margin-bottom:70px!important}.mb-75{margin-bottom:75px!important}.mb-80{margin-bottom:80px!important}.mb-85{margin-bottom:85px!important}.mb-90{margin-bottom:90px!important}.mb-95{margin-bottom:95px!important}.mb-100{margin-bottom:100px!important}.ml-0{margin-left:0!important}.ml-5{margin-left:5px!important}.ml-10{margin-left:10px!important}.ml-15{margin-left:15px!important}.ml-20{margin-left:20px!important}.ml-25{margin-left:25px!important}.ml-30{margin-left:30px!important}.ml-35{margin-left:35px!important}.ml-40{margin-left:40px!important}.ml-45{margin-left:45px!important}.ml-50{margin-left:50px!important}.ml-55{margin-left:55px!important}.ml-60{margin-left:60px!important}.ml-65{margin-left:65px!important}.ml-70{margin-left:70px!important}.ml-75{margin-left:75px!important}.ml-80{margin-left:80px!important}.ml-85{margin-left:85px!important}.ml-90{margin-left:90px!important}.ml-95{margin-left:95px!important}.ml-100{margin-left:100px!important}.mr-0{margin-right:0!important}.mr-5{margin-right:5px!important}.mr-10{margin-right:10px!important}.mr-15{margin-right:15px!important}.mr-20{margin-right:20px!important}.mr-25{margin-right:25px!important}.mr-30{margin-right:30px!important}.mr-35{margin-right:35px!important}.mr-40{margin-right:40px!important}.mr-45{margin-right:45px!important}.mr-50{margin-right:50px!important}.mr-55{margin-right:55px!important}.mr-60{margin-right:60px!important}.mr-65{margin-right:65px!important}.mr-70{margin-right:70px!important}.mr-75{margin-right:75px!important}.mr-80{margin-right:80px!important}.mr-85{margin-right:85px!important}.mr-90{margin-right:90px!important}.mr-95{margin-right:95px!important}.mr-100{margin-right:100px!important}.pt-0{padding-top:0!important}.pt-5{padding-top:5px!important}.pt-10{padding-top:10px!important}.pt-15{padding-top:15px!important}.pt-20{padding-top:20px!important}.pt-25{padding-top:25px!important}.pt-30{padding-top:30px!important}.pt-35{padding-top:35px!important}.pt-40{padding-top:40px!important}.pt-45{padding-top:45px!important}.pt-50{padding-top:50px!important}.pt-55{padding-top:55px!important}.pt-60{padding-top:60px!important}.pt-65{padding-top:65px!important}.pt-70{padding-top:70px!important}.pt-75{padding-top:75px!important}.pt-80{padding-top:80px!important}.pt-85{padding-top:85px!important}.pt-90{padding-top:90px!important}.pt-95{padding-top:95px!important}.pt-100{padding-top:100px!important}.pb-0{padding-bottom:0!important}.pb-5{padding-bottom:5px!important}.pb-10{padding-bottom:10px!important}.pb-15{padding-bottom:15px!important}.pb-20{padding-bottom:20px!important}.pb-25{padding-bottom:25px!important}.pb-30{padding-bottom:30px!important}.pb-35{padding-bottom:35px!important}.pb-40{padding-bottom:40px!important}.pb-45{padding-bottom:45px!important}.pb-50{padding-bottom:50px!important}.pb-55{padding-bottom:55px!important}.pb-60{padding-bottom:60px!important}.pb-65{padding-bottom:65px!important}.pb-70{padding-bottom:70px!important}.pb-75{padding-bottom:75px!important}.pb-80{padding-bottom:80px!important}.pb-85{padding-bottom:85px!important}.pb-90{padding-bottom:90px!important}.pb-95{padding-bottom:95px!important}.pb-100{padding-bottom:100px!important}.pl-0{padding-left:0!important}.pl-5{padding-left:5px!important}.pl-10{padding-left:10px!important}.pl-15{padding-left:15px!important}.pl-20{padding-left:20px!important}.pl-25{padding-left:25px!important}.pl-30{padding-left:30px!important}.pl-35{padding-left:35px!important}.pl-40{padding-left:40px!important}.pl-45{padding-left:45px!important}.pl-50{padding-left:50px!important}.pl-55{padding-left:55px!important}.pl-60{padding-left:60px!important}.pl-65{padding-left:65px!important}.pl-70{padding-left:70px!important}.pl-75{padding-left:75px!important}.pl-80{padding-left:80px!important}.pl-85{padding-left:85px!important}.pl-90{padding-left:90px!important}.pl-95{padding-left:95px!important}.pl-100{padding-left:100px!important}.pr-0{padding-right:0!important}.pr-5{padding-right:5px!important}.pr-10{padding-right:10px!important}.pr-15{padding-right:15px!important}.pr-20{padding-right:20px!important}.pr-25{padding-right:25px!important}.pr-30{padding-right:30px!important}.pr-35{padding-right:35px!important}.pr-40{padding-right:40px!important}.pr-45{padding-right:45px!important}.pr-50{padding-right:50px!important}.pr-55{padding-right:55px!important}.pr-60{padding-right:60px!important}.pr-65{padding-right:65px!important}.pr-70{padding-right:70px!important}.pr-75{padding-right:75px!important}.pr-80{padding-right:80px!important}.pr-85{padding-right:85px!important}.pr-90{padding-right:90px!important}.pr-95{padding-right:95px!important}.pr-100{padding-right:100px!important}@media screen and (max-width:61.9375em){.sidebar-sections{display:none}}.sidebar-sections ul{color:#1a254c;padding:0 10px 0 15px}.sidebar-sections ul li{margin-bottom:1rem}.sidebar-sections ul li a{color:#1a254c;font-weight:400!important;word-break:break-word}.sidebar-sections ul li a:hover{color:#1e70c2}.sidebar-sections ul li a:focus{-webkit-text-decoration:none!important;text-decoration:none!important}.sidebar-sections ul li:hover .active{-webkit-text-decoration:none;text-decoration:none}.sidebar-sections ul li .active{font-weight:400!important;-webkit-text-decoration:none;text-decoration:none}.sidebar-nav{height:100%;left:0;position:absolute;top:0;width:100%}.sidebar-nav-sticky{position:sticky;top:0}.article{padding:0}.tooltip{cursor:pointer;position:relative}.tooltip .tooltiptext{background-color:#000;border-radius:6px;color:#fff;font-family:"Helvetica","Sans-serif";font-size:.9rem;left:50%;margin-left:-125px;margin-top:2px;min-width:250px;padding:10px;position:absolute;text-align:center;text-transform:none;top:100%;visibility:hidden;z-index:1}@media(max-width:768px){.tooltip .tooltiptext{display:none}}.tooltip:hover .tooltiptext{visibility:visible}@media(min-width:768px){.visual-abstract{display:none}}@media(max-width:767px){.visual-abstract{display:block}}.figure-table ul{margin:auto}named-content{display:block;white-space:pre-wrap}
.mt-0{margin-top:0!important}.mt-5{margin-top:5px!important}.mt-10{margin-top:10px!important}.mt-15{margin-top:15px!important}.mt-20{margin-top:20px!important}.mt-25{margin-top:25px!important}.mt-30{margin-top:30px!important}.mt-35{margin-top:35px!important}.mt-40{margin-top:40px!important}.mt-45{margin-top:45px!important}.mt-50{margin-top:50px!important}.mt-55{margin-top:55px!important}.mt-60{margin-top:60px!important}.mt-65{margin-top:65px!important}.mt-70{margin-top:70px!important}.mt-75{margin-top:75px!important}.mt-80{margin-top:80px!important}.mt-85{margin-top:85px!important}.mt-90{margin-top:90px!important}.mt-95{margin-top:95px!important}.mt-100{margin-top:100px!important}.mb-0{margin-bottom:0!important}.mb-5{margin-bottom:5px!important}.mb-10{margin-bottom:10px!important}.mb-15{margin-bottom:15px!important}.mb-20{margin-bottom:20px!important}.mb-25{margin-bottom:25px!important}.mb-30{margin-bottom:30px!important}.mb-35{margin-bottom:35px!important}.mb-40{margin-bottom:40px!important}.mb-45{margin-bottom:45px!important}.mb-50{margin-bottom:50px!important}.mb-55{margin-bottom:55px!important}.mb-60{margin-bottom:60px!important}.mb-65{margin-bottom:65px!important}.mb-70{margin-bottom:70px!important}.mb-75{margin-bottom:75px!important}.mb-80{margin-bottom:80px!important}.mb-85{margin-bottom:85px!important}.mb-90{margin-bottom:90px!important}.mb-95{margin-bottom:95px!important}.mb-100{margin-bottom:100px!important}.ml-0{margin-left:0!important}.ml-5{margin-left:5px!important}.ml-10{margin-left:10px!important}.ml-15{margin-left:15px!important}.ml-20{margin-left:20px!important}.ml-25{margin-left:25px!important}.ml-30{margin-left:30px!important}.ml-35{margin-left:35px!important}.ml-40{margin-left:40px!important}.ml-45{margin-left:45px!important}.ml-50{margin-left:50px!important}.ml-55{margin-left:55px!important}.ml-60{margin-left:60px!important}.ml-65{margin-left:65px!important}.ml-70{margin-left:70px!important}.ml-75{margin-left:75px!important}.ml-80{margin-left:80px!important}.ml-85{margin-left:85px!important}.ml-90{margin-left:90px!important}.ml-95{margin-left:95px!important}.ml-100{margin-left:100px!important}.mr-0{margin-right:0!important}.mr-5{margin-right:5px!important}.mr-10{margin-right:10px!important}.mr-15{margin-right:15px!important}.mr-20{margin-right:20px!important}.mr-25{margin-right:25px!important}.mr-30{margin-right:30px!important}.mr-35{margin-right:35px!important}.mr-40{margin-right:40px!important}.mr-45{margin-right:45px!important}.mr-50{margin-right:50px!important}.mr-55{margin-right:55px!important}.mr-60{margin-right:60px!important}.mr-65{margin-right:65px!important}.mr-70{margin-right:70px!important}.mr-75{margin-right:75px!important}.mr-80{margin-right:80px!important}.mr-85{margin-right:85px!important}.mr-90{margin-right:90px!important}.mr-95{margin-right:95px!important}.mr-100{margin-right:100px!important}.pt-0{padding-top:0!important}.pt-5{padding-top:5px!important}.pt-10{padding-top:10px!important}.pt-15{padding-top:15px!important}.pt-20{padding-top:20px!important}.pt-25{padding-top:25px!important}.pt-30{padding-top:30px!important}.pt-35{padding-top:35px!important}.pt-40{padding-top:40px!important}.pt-45{padding-top:45px!important}.pt-50{padding-top:50px!important}.pt-55{padding-top:55px!important}.pt-60{padding-top:60px!important}.pt-65{padding-top:65px!important}.pt-70{padding-top:70px!important}.pt-75{padding-top:75px!important}.pt-80{padding-top:80px!important}.pt-85{padding-top:85px!important}.pt-90{padding-top:90px!important}.pt-95{padding-top:95px!important}.pt-100{padding-top:100px!important}.pb-0{padding-bottom:0!important}.pb-5{padding-bottom:5px!important}.pb-10{padding-bottom:10px!important}.pb-15{padding-bottom:15px!important}.pb-20{padding-bottom:20px!important}.pb-25{padding-bottom:25px!important}.pb-30{padding-bottom:30px!important}.pb-35{padding-bottom:35px!important}.pb-40{padding-bottom:40px!important}.pb-45{padding-bottom:45px!important}.pb-50{padding-bottom:50px!important}.pb-55{padding-bottom:55px!important}.pb-60{padding-bottom:60px!important}.pb-65{padding-bottom:65px!important}.pb-70{padding-bottom:70px!important}.pb-75{padding-bottom:75px!important}.pb-80{padding-bottom:80px!important}.pb-85{padding-bottom:85px!important}.pb-90{padding-bottom:90px!important}.pb-95{padding-bottom:95px!important}.pb-100{padding-bottom:100px!important}.pl-0{padding-left:0!important}.pl-5{padding-left:5px!important}.pl-10{padding-left:10px!important}.pl-15{padding-left:15px!important}.pl-20{padding-left:20px!important}.pl-25{padding-left:25px!important}.pl-30{padding-left:30px!important}.pl-35{padding-left:35px!important}.pl-40{padding-left:40px!important}.pl-45{padding-left:45px!important}.pl-50{padding-left:50px!important}.pl-55{padding-left:55px!important}.pl-60{padding-left:60px!important}.pl-65{padding-left:65px!important}.pl-70{padding-left:70px!important}.pl-75{padding-left:75px!important}.pl-80{padding-left:80px!important}.pl-85{padding-left:85px!important}.pl-90{padding-left:90px!important}.pl-95{padding-left:95px!important}.pl-100{padding-left:100px!important}.pr-0{padding-right:0!important}.pr-5{padding-right:5px!important}.pr-10{padding-right:10px!important}.pr-15{padding-right:15px!important}.pr-20{padding-right:20px!important}.pr-25{padding-right:25px!important}.pr-30{padding-right:30px!important}.pr-35{padding-right:35px!important}.pr-40{padding-right:40px!important}.pr-45{padding-right:45px!important}.pr-50{padding-right:50px!important}.pr-55{padding-right:55px!important}.pr-60{padding-right:60px!important}.pr-65{padding-right:65px!important}.pr-70{padding-right:70px!important}.pr-75{padding-right:75px!important}.pr-80{padding-right:80px!important}.pr-85{padding-right:85px!important}.pr-90{padding-right:90px!important}.pr-95{padding-right:95px!important}.pr-100{padding-right:100px!important}.email-subscribtion-button{margin-left:auto}.email-subscribtion-button h3{margin-top:0}@media screen and (max-width:35.9375em){.email-subscribtion-button h3{margin-top:50px}}.email-subscribtion-button a{background-color:#fff;border:2px solid #fff;border-radius:100px;color:#1a254c;cursor:pointer;display:block;margin:auto;padding:10px;position:relative;text-align:center;transition:all .2s ease;width:205px}.email-subscribtion-button a span{font-size:1.6rem;font-weight:700;position:relative}.email-subscribtion-button a span.icon{position:absolute;right:38px;transition:all .2s ease}.email-subscribtion-button a:before{background-color:#1a254c;border-radius:28px;content:"";display:block;height:38px;left:0;position:absolute;top:0;transition:all .3s ease;width:50px}.email-subscribtion-button a:hover{color:#fff}.email-subscribtion-button a:hover span.icon{right:25px;transform:rotate(45deg)}.email-subscribtion-button a:hover:before{width:100%}.email-subscribtion-button a:active{color:#1a254c}.email-subscribtion-button a:active span.icon{right:20px}.email-subscribtion-button a:active:before{background-color:#fff}.footer-modal-window .modal-window-body{max-height:650px}.footer-modal-window .mc-field-group ul{padding:0}.footer-modal-window .mc-field-group ul li{list-style-type:none;margin-bottom:2px}.footer-modal-window .mc-field-group ul li input{cursor:pointer;height:15px;width:15px}.footer-modal-window .mc-field-group ul li label{font-size:1.6rem}.footer-modal-window .email-subscribtion label{display:block;font-weight:700;margin:5px 0;max-width:-moz-fit-content;max-width:fit-content}.footer-modal-window .email-subscribtion input{width:100%}.footer-modal-window .email-subscribtion input.error{background-color:#fcf1f1!important;border:1px solid red!important}.footer-modal-window .email-subscribtion small.error{color:red;display:block}.footer{background:#1a254c}.footer-journal-name{background:#111831;padding:7px 0}.footer-journal-name h2{color:#fff;font-size:1.8rem;line-height:2.4rem;margin:5px 0;text-align:center}.footer-title{color:#fff;font-size:1.6rem;font-weight:700;line-height:2.2rem;margin:50px 0 18px}.footer-title:focus{outline:2px solid #f69038!important;outline-offset:6px!important}.footer ul{padding:0}.footer ul li{list-style-type:none;margin-bottom:12px}.footer ul li a{color:#fff;font-size:1.6rem;font-weight:light;opacity:.6;-webkit-text-decoration:none;text-decoration:none}.footer ul li a:focus,.footer ul li a:hover{opacity:1}.footer-social .bluesky a{background-color:#0085ff;border-radius:50px;margin-right:1px;padding:4px 5px;text-align:center;transition:all .2s ease}.footer-social .bluesky a:hover{background-color:#0078e6;transition:all .2s ease}.footer-social .twitter a{border-radius:50px;margin-right:1px;padding:4px 5px;text-align:center}.footer-social .twitter a,.footer-social .twitter a:hover{background-color:#000;transition:all .2s ease}.footer-social .facebook a{background-color:#3b5a98;border-radius:50px;margin-right:1px;padding:4px 5px;text-align:center;transition:all .2s ease}.footer-social .facebook a:hover{background-color:#344f86;transition:all .2s ease}.footer-social .linkedin a{background-color:#0077b5;border-radius:50px;margin-right:1px;padding:4px 5px;text-align:center;transition:all .2s ease}.footer-social .linkedin a:hover{background-color:#00669c;transition:all .2s ease}.footer-social .youtube a{background-color:red;border-radius:50px;margin-right:1px;padding:4px 5px;text-align:center;transition:all .2s ease}.footer-social .youtube a:hover{background-color:#e60000;transition:all .2s ease}.footer-social a:hover{-webkit-text-decoration:none;text-decoration:none}.footer-social a i{color:#fff;text-align:center;width:14px}.footer-copyright{border-top:1px solid #fff;color:#fff;font-size:1.2rem;margin:20px 0 40px;opacity:.6;padding-top:20px}@media screen and (max-width:20.6875em){.footer .rss{margin-top:.25rem}}
.mt-0{margin-top:0!important}.mt-5{margin-top:5px!important}.mt-10{margin-top:10px!important}.mt-15{margin-top:15px!important}.mt-20{margin-top:20px!important}.mt-25{margin-top:25px!important}.mt-30{margin-top:30px!important}.mt-35{margin-top:35px!important}.mt-40{margin-top:40px!important}.mt-45{margin-top:45px!important}.mt-50{margin-top:50px!important}.mt-55{margin-top:55px!important}.mt-60{margin-top:60px!important}.mt-65{margin-top:65px!important}.mt-70{margin-top:70px!important}.mt-75{margin-top:75px!important}.mt-80{margin-top:80px!important}.mt-85{margin-top:85px!important}.mt-90{margin-top:90px!important}.mt-95{margin-top:95px!important}.mt-100{margin-top:100px!important}.mb-0{margin-bottom:0!important}.mb-5{margin-bottom:5px!important}.mb-10{margin-bottom:10px!important}.mb-15{margin-bottom:15px!important}.mb-20{margin-bottom:20px!important}.mb-25{margin-bottom:25px!important}.mb-30{margin-bottom:30px!important}.mb-35{margin-bottom:35px!important}.mb-40{margin-bottom:40px!important}.mb-45{margin-bottom:45px!important}.mb-50{margin-bottom:50px!important}.mb-55{margin-bottom:55px!important}.mb-60{margin-bottom:60px!important}.mb-65{margin-bottom:65px!important}.mb-70{margin-bottom:70px!important}.mb-75{margin-bottom:75px!important}.mb-80{margin-bottom:80px!important}.mb-85{margin-bottom:85px!important}.mb-90{margin-bottom:90px!important}.mb-95{margin-bottom:95px!important}.mb-100{margin-bottom:100px!important}.ml-0{margin-left:0!important}.ml-5{margin-left:5px!important}.ml-10{margin-left:10px!important}.ml-15{margin-left:15px!important}.ml-20{margin-left:20px!important}.ml-25{margin-left:25px!important}.ml-30{margin-left:30px!important}.ml-35{margin-left:35px!important}.ml-40{margin-left:40px!important}.ml-45{margin-left:45px!important}.ml-50{margin-left:50px!important}.ml-55{margin-left:55px!important}.ml-60{margin-left:60px!important}.ml-65{margin-left:65px!important}.ml-70{margin-left:70px!important}.ml-75{margin-left:75px!important}.ml-80{margin-left:80px!important}.ml-85{margin-left:85px!important}.ml-90{margin-left:90px!important}.ml-95{margin-left:95px!important}.ml-100{margin-left:100px!important}.mr-0{margin-right:0!important}.mr-5{margin-right:5px!important}.mr-10{margin-right:10px!important}.mr-15{margin-right:15px!important}.mr-20{margin-right:20px!important}.mr-25{margin-right:25px!important}.mr-30{margin-right:30px!important}.mr-35{margin-right:35px!important}.mr-40{margin-right:40px!important}.mr-45{margin-right:45px!important}.mr-50{margin-right:50px!important}.mr-55{margin-right:55px!important}.mr-60{margin-right:60px!important}.mr-65{margin-right:65px!important}.mr-70{margin-right:70px!important}.mr-75{margin-right:75px!important}.mr-80{margin-right:80px!important}.mr-85{margin-right:85px!important}.mr-90{margin-right:90px!important}.mr-95{margin-right:95px!important}.mr-100{margin-right:100px!important}.pt-0{padding-top:0!important}.pt-5{padding-top:5px!important}.pt-10{padding-top:10px!important}.pt-15{padding-top:15px!important}.pt-20{padding-top:20px!important}.pt-25{padding-top:25px!important}.pt-30{padding-top:30px!important}.pt-35{padding-top:35px!important}.pt-40{padding-top:40px!important}.pt-45{padding-top:45px!important}.pt-50{padding-top:50px!important}.pt-55{padding-top:55px!important}.pt-60{padding-top:60px!important}.pt-65{padding-top:65px!important}.pt-70{padding-top:70px!important}.pt-75{padding-top:75px!important}.pt-80{padding-top:80px!important}.pt-85{padding-top:85px!important}.pt-90{padding-top:90px!important}.pt-95{padding-top:95px!important}.pt-100{padding-top:100px!important}.pb-0{padding-bottom:0!important}.pb-5{padding-bottom:5px!important}.pb-10{padding-bottom:10px!important}.pb-15{padding-bottom:15px!important}.pb-20{padding-bottom:20px!important}.pb-25{padding-bottom:25px!important}.pb-30{padding-bottom:30px!important}.pb-35{padding-bottom:35px!important}.pb-40{padding-bottom:40px!important}.pb-45{padding-bottom:45px!important}.pb-50{padding-bottom:50px!important}.pb-55{padding-bottom:55px!important}.pb-60{padding-bottom:60px!important}.pb-65{padding-bottom:65px!important}.pb-70{padding-bottom:70px!important}.pb-75{padding-bottom:75px!important}.pb-80{padding-bottom:80px!important}.pb-85{padding-bottom:85px!important}.pb-90{padding-bottom:90px!important}.pb-95{padding-bottom:95px!important}.pb-100{padding-bottom:100px!important}.pl-0{padding-left:0!important}.pl-5{padding-left:5px!important}.pl-10{padding-left:10px!important}.pl-15{padding-left:15px!important}.pl-20{padding-left:20px!important}.pl-25{padding-left:25px!important}.pl-30{padding-left:30px!important}.pl-35{padding-left:35px!important}.pl-40{padding-left:40px!important}.pl-45{padding-left:45px!important}.pl-50{padding-left:50px!important}.pl-55{padding-left:55px!important}.pl-60{padding-left:60px!important}.pl-65{padding-left:65px!important}.pl-70{padding-left:70px!important}.pl-75{padding-left:75px!important}.pl-80{padding-left:80px!important}.pl-85{padding-left:85px!important}.pl-90{padding-left:90px!important}.pl-95{padding-left:95px!important}.pl-100{padding-left:100px!important}.pr-0{padding-right:0!important}.pr-5{padding-right:5px!important}.pr-10{padding-right:10px!important}.pr-15{padding-right:15px!important}.pr-20{padding-right:20px!important}.pr-25{padding-right:25px!important}.pr-30{padding-right:30px!important}.pr-35{padding-right:35px!important}.pr-40{padding-right:40px!important}.pr-45{padding-right:45px!important}.pr-50{padding-right:50px!important}.pr-55{padding-right:55px!important}.pr-60{padding-right:60px!important}.pr-65{padding-right:65px!important}.pr-70{padding-right:70px!important}.pr-75{padding-right:75px!important}.pr-80{padding-right:80px!important}.pr-85{padding-right:85px!important}.pr-90{padding-right:90px!important}.pr-95{padding-right:95px!important}.pr-100{padding-right:100px!important}.scroll-to-very-top{background-color:#1e70c2;border-radius:3px 0 0 3px;bottom:.7vh;box-shadow:0 0 5px rgba(0,0,0,.2);position:fixed;right:0;z-index:2}.scroll-to-very-top:focus,.scroll-to-very-top:hover{opacity:.9}.scroll-to-very-top:focus{border:2px solid #f69038;margin:1px}.scroll-to-very-top .icon{color:#fff;font-size:2.5rem;padding:9px;transition:all .3s}</style></head><body ><noscript data-n-head="ssr" data-hid="gtm-noscript" data-pbody="true"><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-58BHBF4V&" height="0" width="0" style="display:none;visibility:hidden" title="gtm"></iframe></noscript><div data-server-rendered="true" id="__nuxt"><!----><div id="__layout"><div id="jmir-html"><span tabindex="-1"></span> <!----> <div id="skip-link"><a href="#main-content">
            Skip to Main Content <span aria-hidden="true" class="icon fas fa-chevron-down"></span></a> <a href="#footer">
            Skip to Footer <span aria-hidden="true" class="icon fas fa-chevron-down"></span></a></div> <!----> <div data-v-49c694ee><span tabindex="0" aria-label="Accessibility settings" title="Accessibility settings" role="button" class="icon fas fa-universal-access universal-access-btn" data-v-49c694ee></span> <!----> <style type="text/css" data-v-49c694ee>
            html {
            filter: none !important
            }
        
            html {
            font-weight: inherit !important
            }
        
            html {
            font-size: 0.625rem !important
            }
        
            html {
            text-align: initial !important
            }
         
            *:not svg {
            font-weight: inherit
            }
        </style></div> <div id="main-layout-container"><div style="background-color: white;"><div id="scroll-to-very-top"><header id="header"><section class="header"><nav><div data-v-575455fb><nav aria-label="Navigation" data-v-575455fb><section class="top-nav" data-v-575455fb><div class="container" data-v-575455fb><!----> <div class="corporate" data-v-575455fb><div class="corporate__logo" data-v-575455fb><a href="https://jmirpublications.com" aria-label="JMIR Publications main website" data-v-575455fb><div data-v-575455fb><img src="https://asset.jmir.pub/resources/images/logos/JMIR_logo.png" alt="JMIR Publications" class="logo-img"></div></a></div> <div class="corporate__mobile-menu" data-v-575455fb><button data-v-575455fb><span aria-hidden="true" class="icon fas fa-bars" data-v-575455fb></span></button></div> <div class="corporate__search" data-v-575455fb><label for="corporate__search-select" class="screen-readers-only" data-v-575455fb>
                            Select options
                        </label> <select id="corporate__search-select" data-test="search-select" class="corporate__search-select" data-v-575455fb><option value="articles" selected="selected" data-v-575455fb>
                                Articles
                            </option> <option value="help" data-v-575455fb>
                                Help
                            </option></select> <input name="type" type="hidden" value="text" data-v-575455fb> <!----><!----><!----><!----><!----> <button aria-label="Search articles" data-test="unisearch-button" class="btn btn-small btn-blue corporate__search-btn" data-v-575455fb><span aria-hidden="true" class="icon fas fa-search" data-v-575455fb></span></button></div> <div class="corporate__nav" data-v-575455fb><ul class="corporate__links" data-v-575455fb><li tabindex="0" aria-haspopup="true" data-test="resource-center" class="corporate__link-item" data-v-575455fb><a href="https://careers.jmir.org/" class="corporate__link" data-v-575455fb>
                                    Career Center
                                </a></li> <li class="corporate__link-item" data-v-575455fb><a id="button-login" href="javascript:;" data-test="login-button" class="corporate__link" data-v-575455fb>Login</a></li> <li id="button-register" data-test="register-button" class="corporate__link-item" data-v-575455fb><a class="corporate__link" data-v-575455fb>Register</a></li> <!----></ul></div></div></div></section> <section class="bottom-nav-1" data-v-575455fb><div class="container" data-v-575455fb><div class="journal" data-v-575455fb><div class="journal__nav" data-v-575455fb><ul class="journal__links" data-v-575455fb><li class="journal__link-item journal__link-item--journals" data-v-575455fb><div aria-haspopup="true" class="journal__link-item-container" data-v-575455fb><a href="/" aria-label="JMIR Mental Health home page" class="journal__link--home nuxt-link-active" data-v-575455fb><span aria-hidden="true" class="icon fas fa-home" style="font-size:16px;" data-v-575455fb></span>
                                        JMIR Mental Health
                                    </a> <span aria-expanded="false" aria-label="Other journals" tabindex="0" role="button" class="journal__journals-list" data-v-575455fb><span aria-hidden="true" data-test="journal-list-show-dropdown-button" class="icon fas fa-arrow-down" style="padding: 16px 16px;" data-v-575455fb></span></span></div> <ul aria-label="submenu" data-test="journal-list-dropdown" class="journal__link-submenu-journals" data-v-575455fb><li class="m-0" data-v-575455fb><a href="https://www.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>Journal of Medical Internet Research</span> <span class="articles-number" data-v-575455fb>10756 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://www.researchprotocols.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Research Protocols</span> <span class="articles-number" data-v-575455fb>5264 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://formative.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Formative Research</span> <span class="articles-number" data-v-575455fb>4027 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://mhealth.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR mHealth and uHealth</span> <span class="articles-number" data-v-575455fb>2959 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://publichealth.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Public Health and Surveillance</span> <span class="articles-number" data-v-575455fb>1867 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://ojphi.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>Online Journal of Public Health Informatics</span> <span class="articles-number" data-v-575455fb>1751 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://medinform.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Medical Informatics</span> <span class="articles-number" data-v-575455fb>1734 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="/" class="nuxt-link-active" data-v-575455fb><span data-v-575455fb>JMIR Mental Health</span> <span class="articles-number" data-v-575455fb>1227 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://humanfactors.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Human Factors</span> <span class="articles-number" data-v-575455fb>1078 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://games.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Serious Games</span> <span class="articles-number" data-v-575455fb>780 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://mededu.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Medical Education</span> <span class="articles-number" data-v-575455fb>740 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://aging.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Aging</span> <span class="articles-number" data-v-575455fb>634 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://xmed.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIRx Med</span> <span class="articles-number" data-v-575455fb>575 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://cancer.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Cancer</span> <span class="articles-number" data-v-575455fb>539 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://pediatrics.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Pediatrics and Parenting</span> <span class="articles-number" data-v-575455fb>530 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://www.i-jmr.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>Interactive Journal of Medical Research</span> <span class="articles-number" data-v-575455fb>525 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://www.iproc.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>iProceedings</span> <span class="articles-number" data-v-575455fb>510 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://derma.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Dermatology</span> <span class="articles-number" data-v-575455fb>361 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://rehab.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Rehabilitation and Assistive Technologies</span> <span class="articles-number" data-v-575455fb>347 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://diabetes.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Diabetes</span> <span class="articles-number" data-v-575455fb>322 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://cardio.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Cardio</span> <span class="articles-number" data-v-575455fb>258 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://ai.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR AI</span> <span class="articles-number" data-v-575455fb>229 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://infodemiology.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Infodemiology</span> <span class="articles-number" data-v-575455fb>227 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://nursing.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Nursing</span> <span class="articles-number" data-v-575455fb>163 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://jopm.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>Journal of Participatory Medicine</span> <span class="articles-number" data-v-575455fb>148 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://periop.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Perioperative Medicine</span> <span class="articles-number" data-v-575455fb>135 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://biomedeng.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Biomedical Engineering</span> <span class="articles-number" data-v-575455fb>106 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://bioinform.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Bioinformatics and Biotechnology</span> <span class="articles-number" data-v-575455fb>72 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://apinj.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>Asian/Pacific Island Nursing Journal</span> <span class="articles-number" data-v-575455fb>49 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://xr.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR XR and Spatial Computing (JMXR)</span> <span class="articles-number" data-v-575455fb>40 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://xbio.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIRx Bio</span> <span class="articles-number" data-v-575455fb>39 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://neuro.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Neurotechnology</span> <span class="articles-number" data-v-575455fb>33 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://www.medicine20.com" no-prefetch="" data-v-575455fb><span data-v-575455fb>Medicine 2.0</span> <span class="articles-number" data-v-575455fb>26 articles
                                            </span></a></li><li class="m-0" data-v-575455fb><a href="https://data.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Data</span> <!----></a></li><li class="m-0" data-v-575455fb><a href="https://challenges.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Challenges</span> <!----></a></li><li class="m-0" data-v-575455fb><a href="https://preprints.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Preprints</span> <!----></a></li></ul></li> <li tabindex="0" aria-haspopup="true" data-test="journal-information" class="journal__link-item journal__link-item--journal-info" data-v-575455fb><span class="journal__link" data-v-575455fb>
                                    Journal Information
                                </span> <span aria-hidden="true" class="icon fas fa-caret-down" data-v-575455fb></span> <ul aria-label="submenu" data-test="journal-info-popover" class="journal__link-submenu journal__link-submenu--journal-info" data-v-575455fb><li data-v-575455fb><a href="/about-journal/focus-and-scope" data-v-575455fb>
                                            Focus and Scope
                                        </a></li><li data-v-575455fb><a href="/about-journal/editorial-board" data-v-575455fb>
                                            Editorial Board
                                        </a></li><li data-v-575455fb><a href="/author-information/instructions-for-authors" data-v-575455fb>
                                            Author Information
                                        </a></li><li data-v-575455fb><a href="/resource-centre/author-hub" data-v-575455fb>
                                            Resource Center
                                        </a></li><li data-v-575455fb><a href="/about-journal/article-processing-fees" data-v-575455fb>
                                            Article Processing Fees
                                        </a></li><li data-v-575455fb><a href="/publishing-policies/section-policies" data-v-575455fb>
                                            Publishing Policies
                                        </a></li><li data-v-575455fb><a href="/get-involved/new-journal-editor-in-chief-proposals" data-v-575455fb>
                                            Get Involved
                                        </a></li><li data-v-575455fb><a href="/top-articles/overview" data-v-575455fb>
                                            Top Articles
                                        </a></li><li data-v-575455fb><a href="/fees/institutional-partners" data-v-575455fb>
                                            Institutional Partners
                                        </a></li><li data-v-575455fb><a href="/about-journal/indexing-and-impact-factor" data-v-575455fb>
                                            Indexing and Impact Factor
                                        </a></li></ul></li> <li tabindex="0" aria-haspopup="true" class="journal__link-item journal__link-item--browse" data-v-575455fb><span class="journal__link" data-v-575455fb>
                                    Browse Journal
                                </span> <span aria-hidden="true" class="icon fas fa-caret-down" data-v-575455fb></span> <ul aria-label="submenu" data-test="browse-journal-popover" class="journal__link-submenu journal__link-submenu--browse" data-v-575455fb><li class="m-0" data-v-575455fb><div class="journal__link-submenu--select" data-v-575455fb><label for="nav-year" data-v-575455fb>
                                                Year:
                                            </label> <select id="nav-year" data-v-575455fb><option disabled="disabled" value="" data-v-575455fb>
                                                    Select...
                                                </option> <option value="2014" data-v-575455fb>
                                                    2014
                                                </option><option value="2015" data-v-575455fb>
                                                    2015
                                                </option><option value="2016" data-v-575455fb>
                                                    2016
                                                </option><option value="2017" data-v-575455fb>
                                                    2017
                                                </option><option value="2018" data-v-575455fb>
                                                    2018
                                                </option><option value="2019" data-v-575455fb>
                                                    2019
                                                </option><option value="2020" data-v-575455fb>
                                                    2020
                                                </option><option value="2021" data-v-575455fb>
                                                    2021
                                                </option><option value="2022" data-v-575455fb>
                                                    2022
                                                </option><option value="2023" data-v-575455fb>
                                                    2023
                                                </option><option value="2024" data-v-575455fb>
                                                    2024
                                                </option><option value="2025" data-v-575455fb>
                                                    2025
                                                </option></select></div></li> <li data-v-575455fb><a href="/announcements" data-v-575455fb>
                                            Latest Announcements
                                        </a></li><li data-v-575455fb><a href="/search/authors" data-v-575455fb>
                                            Authors
                                        </a></li> <li data-v-575455fb><a href="/themes" data-v-575455fb>
                                            Themes
                                        </a></li><li data-v-575455fb><a href="/issues" data-v-575455fb>
                                            Issues
                                        </a></li> <li data-v-575455fb><a href="https://blog.jmir.org/" data-v-575455fb>
                                            Blog
                                        </a></li></ul></li> <li class="journal__link-item journal__link-item--submit-article" data-v-575455fb><a href="/author" class="btn btn-small btn-blue journal__submit-article" data-v-575455fb>Submit Article</a></li></ul></div></div></div></section> <section class="bottom-nav-2" data-v-575455fb><div class="journal" data-v-575455fb><ul data-v-575455fb><li class="journal__link-item journal__link-item--journals" data-v-575455fb><div class="journal__link-item-container" data-v-575455fb><a href="/" class="journal__link--home nuxt-link-active" data-v-575455fb><span aria-hidden="true" class="icon fas fa-home" style="font-size:16px;" data-v-575455fb></span>
                                JMIR Mental Health
                            </a> <span class="journal__journals-list" data-v-575455fb><span aria-hidden="true" class="icon fas fa-arrow-down" data-v-575455fb></span></span></div> <ul data-test="journal-list" class="journal__link-submenu-journals" data-v-575455fb><li class="m-0" data-v-575455fb><a href="https://www.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>Journal of Medical Internet Research</span> <span class="articles-number" data-v-575455fb>10756 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://www.researchprotocols.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Research Protocols</span> <span class="articles-number" data-v-575455fb>5264 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://formative.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Formative Research</span> <span class="articles-number" data-v-575455fb>4027 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://mhealth.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR mHealth and uHealth</span> <span class="articles-number" data-v-575455fb>2959 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://publichealth.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Public Health and Surveillance</span> <span class="articles-number" data-v-575455fb>1867 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://ojphi.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>Online Journal of Public Health Informatics</span> <span class="articles-number" data-v-575455fb>1751 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://medinform.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Medical Informatics</span> <span class="articles-number" data-v-575455fb>1734 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="/" class="nuxt-link-active" data-v-575455fb><span data-v-575455fb>JMIR Mental Health</span> <span class="articles-number" data-v-575455fb>1227 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://humanfactors.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Human Factors</span> <span class="articles-number" data-v-575455fb>1078 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://games.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Serious Games</span> <span class="articles-number" data-v-575455fb>780 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://mededu.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Medical Education</span> <span class="articles-number" data-v-575455fb>740 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://aging.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Aging</span> <span class="articles-number" data-v-575455fb>634 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://xmed.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIRx Med</span> <span class="articles-number" data-v-575455fb>575 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://cancer.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Cancer</span> <span class="articles-number" data-v-575455fb>539 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://pediatrics.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Pediatrics and Parenting</span> <span class="articles-number" data-v-575455fb>530 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://www.i-jmr.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>Interactive Journal of Medical Research</span> <span class="articles-number" data-v-575455fb>525 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://www.iproc.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>iProceedings</span> <span class="articles-number" data-v-575455fb>510 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://derma.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Dermatology</span> <span class="articles-number" data-v-575455fb>361 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://rehab.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Rehabilitation and Assistive Technologies</span> <span class="articles-number" data-v-575455fb>347 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://diabetes.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Diabetes</span> <span class="articles-number" data-v-575455fb>322 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://cardio.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Cardio</span> <span class="articles-number" data-v-575455fb>258 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://ai.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR AI</span> <span class="articles-number" data-v-575455fb>229 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://infodemiology.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Infodemiology</span> <span class="articles-number" data-v-575455fb>227 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://nursing.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Nursing</span> <span class="articles-number" data-v-575455fb>163 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://jopm.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>Journal of Participatory Medicine</span> <span class="articles-number" data-v-575455fb>148 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://periop.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Perioperative Medicine</span> <span class="articles-number" data-v-575455fb>135 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://biomedeng.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Biomedical Engineering</span> <span class="articles-number" data-v-575455fb>106 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://bioinform.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Bioinformatics and Biotechnology</span> <span class="articles-number" data-v-575455fb>72 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://apinj.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>Asian/Pacific Island Nursing Journal</span> <span class="articles-number" data-v-575455fb>49 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://xr.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR XR and Spatial Computing (JMXR)</span> <span class="articles-number" data-v-575455fb>40 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://xbio.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIRx Bio</span> <span class="articles-number" data-v-575455fb>39 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://neuro.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Neurotechnology</span> <span class="articles-number" data-v-575455fb>33 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://www.medicine20.com" no-prefetch="" data-v-575455fb><span data-v-575455fb>Medicine 2.0</span> <span class="articles-number" data-v-575455fb>26 articles
                                    </span></a></li><li class="m-0" data-v-575455fb><a href="https://data.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Data</span> <!----></a></li><li class="m-0" data-v-575455fb><a href="https://challenges.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Challenges</span> <!----></a></li><li class="m-0" data-v-575455fb><a href="https://preprints.jmir.org" no-prefetch="" data-v-575455fb><span data-v-575455fb>JMIR Preprints</span> <!----></a></li></ul></li></ul></div></section> <!----></nav></div></nav></section></header></div> <div class="container-fluid" style="padding: 0px;"><div class="element-wrapper"><div data-test="main-content" class="container"><div class="sidebar-citation mobile-show"><div class="collection"><h2 tabindex="0" data-test="article-collection" class="h4 green-heading-underline width-fit-content">
                    This paper is in the following
                    <span class="collection__span">e-collection/theme issue:</span></h2> <a href="/themes/1433" data-test="article-collection" aria-label="16 articles belongs to Theme Issue 2023 - 2024 : Responsible Design, Integration, and Use of Generative AI in Mental Health e-collection/theme issue" class="collection__link">
                    Theme Issue 2023 - 2024 : Responsible Design, Integration, and Use of Generative AI in Mental Health (16)
                </a><a href="/themes/64" data-test="article-collection" aria-label="2145 articles belongs to Digital Mental Health Interventions, e-Mental Health and Cyberpsychology e-collection/theme issue" class="collection__link">
                    Digital Mental Health Interventions, e-Mental Health and Cyberpsychology (2145)
                </a><a href="/themes/797" data-test="article-collection" aria-label="2162 articles belongs to Artificial Intelligence e-collection/theme issue" class="collection__link">
                    Artificial Intelligence (2162)
                </a><a href="/themes/624" data-test="article-collection" aria-label="756 articles belongs to Development and Evaluation of Research Methods, Instruments and Tools e-collection/theme issue" class="collection__link">
                    Development and Evaluation of Research Methods, Instruments and Tools (756)
                </a><a href="/themes/227" data-test="article-collection" aria-label="1703 articles belongs to Depression and Mood Disorders; Suicide Prevention e-collection/theme issue" class="collection__link">
                    Depression and Mood Disorders; Suicide Prevention (1703)
                </a><a href="/themes/1437" data-test="article-collection" aria-label="725 articles belongs to Generative Language Models Including ChatGPT e-collection/theme issue" class="collection__link">
                    Generative Language Models Including ChatGPT (725)
                </a><a href="/themes/763" data-test="article-collection" aria-label="748 articles belongs to Chatbots and Conversational Agents e-collection/theme issue" class="collection__link">
                    Chatbots and Conversational Agents (748)
                </a><a href="/themes/50" data-test="article-collection" aria-label="4050 articles belongs to Web-based and Mobile Health Interventions e-collection/theme issue" class="collection__link">
                    Web-based and Mobile Health Interventions (4050)
                </a></div></div> <div class="row"><div class="main col-lg-9 mb-1"><!----> <div data-test="details" class="details"><div><p id="main-content" tabindex="0">
                            Published on
                            <time datetime="02.Jul.2024">02.Jul.2024
                            </time>
                            in
                            <span data-test="issue-info"><a href="/2024/1" class="nuxt-link-active">
                                    Vol 11<!----> (2024)<!----></a></span></p> <!----></div> <div><div class="preprints-version"><span aria-hidden="true" class="icon fas fa-thumbtack"></span> <div><span class="ml-2">
                                    Preprints (earlier versions) of this paper are
                                    available at
                                    <a data-test="preprint-link" aria-label="'Preprints (earlier versions) of this paper are
                                available at preprints.jmir.org/preprint/'56569" href="https://preprints.jmir.org/preprint/56569" target="_blank">https://preprints.jmir.org/preprint/56569</a>, first published
                                    <time datetime="19.Jan.2024">19.Jan.2024</time>.
                                </span></div></div></div> <!----></div> <div class="info mt-3"><div class="info__article-img"><div data-v-10f10a3e><img data-srcset="https://asset.jmir.pub/assets/c5a135a21a23692e7b6cb5f40e6b9dda.png 480w,https://asset.jmir.pub/assets/c5a135a21a23692e7b6cb5f40e6b9dda.png 960w,https://asset.jmir.pub/assets/c5a135a21a23692e7b6cb5f40e6b9dda.png 1920w,https://asset.jmir.pub/assets/c5a135a21a23692e7b6cb5f40e6b9dda.png 2500w" alt="The Role of Humanization and Robustness of Large Language Models in Conversational Artificial Intelligence for Individuals With Depression: A Critical Analysis" title="The Role of Humanization and Robustness of Large Language Models in Conversational Artificial Intelligence for Individuals With Depression: A Critical Analysis" aria-label="Article Thumbnail Image" src="https://asset.jmir.pub/placeholder.svg" data-v-10f10a3e></div> <div data-test="article-img-info" class="info__article-img-info"><span aria-hidden="true" class="icon fas fa-search-plus"></span></div></div> <div class="info__title-authors"><h1 tabindex="0" aria-label="The Role of Humanization and Robustness of Large Language Models in Conversational Artificial Intelligence for Individuals With Depression: A Critical Analysis" class="h3 mb-0 mt-0">The Role of Humanization and Robustness of Large Language Models in Conversational Artificial Intelligence for Individuals With Depression: A Critical Analysis</h1> <h2 class="info__hidden-title">
                            The Role of Humanization and Robustness of Large Language Models in Conversational Artificial Intelligence for Individuals With Depression: A Critical Analysis
                        </h2> <div class="mt-3"><p tabindex="0" class="authors-for-screen-reader">
                                Authors of this article:
                            </p> <span data-test="authors-info" class="info__authors"><span><a href="/search?term=Andrea%20Ferrario&amp;type=author&amp;precise=true&amp;authorlink=true" aria-label="Andrea Ferrario. Search more articles by this author.">
                                        Andrea Ferrario<sup>1, 2</sup> <!----></a></span> <span><a aria-label="Visit this author on ORCID website" data-test="orcid-link" target="_blank" href="https://orcid.org/0000-0001-9968-9474"><img src="https://asset.jmir.pub/assets/static/images/Orcid-ID-Logo-Colour.png" alt="Author Orcid Image" aria-label="Author Orcid Image" class="info__orcid-img"></a></span> <span style="margin-left: -2px;">
                                    ;  
                                </span></span><span data-test="authors-info" class="info__authors"><span><a href="/search?term=Jana%20Sedlakova&amp;type=author&amp;precise=true&amp;authorlink=true" aria-label="Jana Sedlakova. Search more articles by this author.">
                                        Jana Sedlakova<sup>1, 3, 4</sup> <!----></a></span> <span><a aria-label="Visit this author on ORCID website" data-test="orcid-link" target="_blank" href="https://orcid.org/0000-0002-6887-5941"><img src="https://asset.jmir.pub/assets/static/images/Orcid-ID-Logo-Colour.png" alt="Author Orcid Image" aria-label="Author Orcid Image" class="info__orcid-img"></a></span> <span style="margin-left: -2px;">
                                    ;  
                                </span></span><span data-test="authors-info" class="info__authors"><span><a href="/search?term=Manuel%20Trachsel&amp;type=author&amp;precise=true&amp;authorlink=true" aria-label="Manuel Trachsel. Search more articles by this author.">
                                        Manuel Trachsel<sup>5, 6, 7</sup> <!----></a></span> <span><a aria-label="Visit this author on ORCID website" data-test="orcid-link" target="_blank" href="https://orcid.org/0000-0002-2697-3631"><img src="https://asset.jmir.pub/assets/static/images/Orcid-ID-Logo-Colour.png" alt="Author Orcid Image" aria-label="Author Orcid Image" class="info__orcid-img"></a></span> <!----></span></div> <!----></div></div> <div role="tablist" aria-label="Article" class="tabs"><a href="/2024/1/e56569/" aria-current="page" role="tab" aria-label="Article" data-test="tabs" class="nuxt-link-exact-active nuxt-link-active active">
                        Article
                    </a><a href="/2024/1/e56569/authors" role="tab" aria-label="Authors" data-test="tabs">
                        Authors
                    </a><a href="/2024/1/e56569/citations" role="tab" aria-label="Cited by (21)" data-test="tabs">
                        Cited by (21)
                    </a><a href="/2024/1/e56569/tweetations" role="tab" aria-label="Tweetations (1)" data-test="tabs">
                        Tweetations (1)
                    </a><a href="/2024/1/e56569/metrics" role="tab" aria-label="Metrics" data-test="tabs">
                        Metrics
                    </a></div> <div class="container"><div class="row"><div class="col-lg-3 mb-5 sidebar-sections"><div class="sidebar-nav"><div class="sidebar-nav-sticky"><ul></ul></div></div></div> <div data-test="keyword-links" class="col-lg-9 article"><main id="wrapper" class="wrapper ArticleMain clearfix"><section class="inner-wrapper clearfix"><section class="main-article-content clearfix"><article class="ajax-article-content"><h4 class="h4-original-paper"><span class="typcn typcn-document-text"></span></h4><div class="authors-container"><div class="authors clearfix"><ul class="clearfix"><li><a href="/search/searchResult?field%5B%5D=author&amp;criteria%5B%5D=Andrea+Ferrario" class="btn-view-author-options">Andrea Ferrario<sup><small>1,</small></sup><sup><small>2,</small></sup><sup>*</sup>, PhD</a>;&#xA0;</li><li><a href="/search/searchResult?field%5B%5D=author&amp;criteria%5B%5D=Jana+Sedlakova" class="btn-view-author-options">Jana Sedlakova<sup><small>1,</small></sup><sup><small>3,</small></sup><sup><small>4,</small></sup><sup>*</sup>, MA</a>;&#xA0;</li><li><a href="/search/searchResult?field%5B%5D=author&amp;criteria%5B%5D=Manuel+Trachsel" class="btn-view-author-options">Manuel Trachsel<sup><small>5,</small></sup><sup><small>6,</small></sup><sup><small>7</small></sup>, MD, PhD</a></li></ul><div class="author-affiliation-details"><p><sup>1</sup>Institute Biomedical Ethics and History of Medicine, University of Zurich, , Zurich, , Switzerland</p><p><sup>2</sup>Mobiliar Lab for Analytics at ETH, ETH Zurich, , Zurich, , Switzerland</p><p><sup>3</sup>Digital Society Initiative, University of Zurich, , Zurich, , Switzerland</p><p><sup>4</sup>Institute for Implementation Science in Health Care, University of Zurich, , Zurich, , Switzerland</p><p><sup>5</sup>University of Basel, , Basel, , Switzerland</p><p><sup>6</sup>University Hospital Basel, , Basel, , Switzerland</p><p><sup>7</sup>University Psychiatric Clinics Basel, , Basel, , Switzerland</p><p>*these authors contributed equally</p></div></div><div class="corresponding-author-and-affiliations clearfix"><div class="corresponding-author-details"><h3>Corresponding Author:</h3><p>Andrea Ferrario, PhD</p><p></p><br></div></div></div><div class="authors-container"><div class="authors clearfix"></div></div><div class="authors-container"><div class="authors clearfix"></div></div><section class="article-content clearfix"><article class="abstract"><h3 id="Abstract" class="navigation-heading" data-label="Abstract">Abstract</h3><p><p class="abstract-paragraph">Large language model (LLM)&#x2013;powered services are gaining popularity in various applications due to their exceptional performance in many tasks, such as sentiment analysis and answering questions. Recently, research has been exploring their potential use in digital health contexts, particularly in the mental health domain. However, implementing LLM-enhanced conversational artificial intelligence (CAI) presents significant ethical, technical, and clinical challenges. In this viewpoint paper, we discuss 2 challenges that affect the use of LLM-enhanced CAI for individuals with mental health issues, focusing on the use case of patients with depression: the tendency to humanize LLM-enhanced CAI and their lack of contextualized robustness. Our approach is interdisciplinary, relying on considerations from philosophy, psychology, and computer science. We argue that the humanization of LLM-enhanced CAI hinges on the reflection of what it means to simulate &#x201C;human-like&#x201D; features with LLMs and what role these systems should play in interactions with humans. Further, ensuring the contextualization of the robustness of LLMs requires considering the specificities of language production in individuals with depression, as well as its evolution over time. Finally, we provide a series of recommendations to foster the responsible design and deployment of LLM-enhanced CAI for the therapeutic support of individuals with depression.</p></p><strong class="h4-article-volume-issue">JMIR Ment Health 2024;11:e56569</strong><br><br><span class="article-doi"><a href="https://doi.org/10.2196/56569">doi:10.2196/56569</a></span><br><br><h3 class="h3-main-heading" id="Keywords">Keywords</h3><div class="keywords"><span><a href="/search?type=keyword&amp;term=generative%20AI&amp;precise=true">generative AI</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=large%20language%20models&amp;precise=true">large language models</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=large%20language%20model&amp;precise=true">large language model</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=LLM&amp;precise=true">LLM</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=LLMs&amp;precise=true">LLMs</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=machine%20learning&amp;precise=true">machine learning</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=ML&amp;precise=true">ML</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=natural%20language%20processing&amp;precise=true">natural language processing</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=NLP&amp;precise=true">NLP</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=deep%20learning&amp;precise=true">deep learning</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=depression&amp;precise=true">depression</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=mental%20health&amp;precise=true">mental health</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=mental%20illness&amp;precise=true">mental illness</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=mental%20disease&amp;precise=true">mental disease</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=mental%20diseases&amp;precise=true">mental diseases</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=mental%20illnesses&amp;precise=true">mental illnesses</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=artificial%20intelligence&amp;precise=true">artificial intelligence</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=AI&amp;precise=true">AI</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=digital%20health&amp;precise=true">digital health</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=digital%20technology&amp;precise=true">digital technology</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=digital%20intervention&amp;precise=true">digital intervention</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=digital%20interventions&amp;precise=true">digital interventions</a>;&#xA0;</span><span><a href="/search?type=keyword&amp;term=ethics&amp;precise=true">ethics</a>&#xA0;</span></div><div id="trendmd-suggestions"></div></article><br><article class="main-article clearfix"><br><h3 class="navigation-heading h3-main-heading" id="Introduction" data-label="Introduction">Introduction</h3><h4>What Are Large Language Models?</h4><p class="abstract-paragraph">Large language models (LLMs) are a type of generative artificial intelligence (AI) that displays unprecedented performance in different downstream tasks, such as question answering and, in general, context-aware text generation [<span class="footers"><a class="citation-link" href="#ref1" rel="footnote">1</a></span>-<span class="footers"><a class="citation-link" href="#ref4" rel="footnote">4</a></span>]. They produce language using deep neural networks. These models consist of billions of parameters and are trained on huge amounts of data at the expense of notable computational power. LLMs have been recently popularized by services&#x2014;such as OpenAI&#x2019;s ChatGPT-4, Google&#x2019;s BARD (now called &#x201C;Gemini&#x201D;), and Meta&#x2019;s Llama&#x2014;that are currently used by millions of people every day, experts, and laypeople alike. These services are essentially conversational AI (CAI) enhanced with LLMs. They offer a more human-like, natural, and context-relevant interaction than other technological applications such as rule-based conversational agents (ie, traditional &#x201C;chatbots&#x201D;). They hold the potential to transform how we engage in conversations and manage the information therein. Consequently, they are expected to become much more widely adopted in different professional fields, research, and society alike.</p><h4>LLMs in Health Care and Mental Health Applications</h4><p class="abstract-paragraph">In health care, applications of LLMs are manifold, spanning from clinical research and processes to physician-patient relations [<span class="footers"><a class="citation-link" href="#ref5" rel="footnote">5</a></span>-<span class="footers"><a class="citation-link" href="#ref10" rel="footnote">10</a></span>]. For instance, LLMs can improve clinical processes by automating the generation of administrative text [<span class="footers"><a class="citation-link" href="#ref1" rel="footnote">1</a></span>,<span class="footers"><a class="citation-link" href="#ref5" rel="footnote">5</a></span>]. Physician-patient relations could benefit from the use of LLM-enhanced patient decision aids and interventions that could support therapy and improve shared decision-making [<span class="footers"><a class="citation-link" href="#ref1" rel="footnote">1</a></span>]. Context-relevant and personalized conversations with an LLM-enhanced CAI show the potential to promote patients&#x2019; empowerment and individuals&#x2019; reflection around their personal values and preferences for different health care scenarios in a way that is not possible with current methods, for example, filling out legal documents such as advance directives [<span class="footers"><a class="citation-link" href="#ref11" rel="footnote">11</a></span>-<span class="footers"><a class="citation-link" href="#ref13" rel="footnote">13</a></span>].</p><p class="abstract-paragraph">In the mental health domain, the use of CAI is no novelty. The very first chatbot ELIZA, was developed in 1966, and played the role of a digital psychotherapist [<span class="footers"><a class="citation-link" href="#ref14" rel="footnote">14</a></span>]. Six decades later, it is possible to develop and test LLM-enhanced CAI leveraging an ample body of knowledge and use cases. In the mental health domain, CAIs are currently used as patient therapeutic support, for example, a simple psychotherapy, such as cognitive behavioral exercises [<span class="footers"><a class="citation-link" href="#ref15" rel="footnote">15</a></span>]. Given their noteworthy ability to process and produce language, the use of LLMs holds the potential to provide more context-aware and effective psychotherapeutic support to their users than traditional CAI. In fact, once embedded in CAI, designers can instruct LLMs to provide a nonjudgmental, readily available platform for vulnerable individuals to discuss their feelings and mental health struggles as well as practice skills that they learned in a therapeutic session.</p><p class="abstract-paragraph">CAI is also used to collect data of patients with mental health disorders, carry out initial triage processes, and provide treatment recommendations [<span class="footers"><a class="citation-link" href="#ref6" rel="footnote">6</a></span>]. Here, LLM-enhanced CAI could process written or spoken responses of patients with mental health disorders to support therapists in their diagnostics or track mental health changes in patients over time. They could also generate personalized treatment recommendations by taking an individual&#x2019;s mental health history, their symptoms, values, and care preferences as input. By collecting data on the web, such as social media posts or chat logs, LLMs could help detect signs of emotional distress and detect mental health issues promptly. To this end, preliminary results show that ChatGPT-3.5 achieves good performance at detecting stress and depression in written statements on web-based forums [<span class="footers"><a class="citation-link" href="#ref16" rel="footnote">16</a></span>]. These results suggest that ChatGPT-3.5&#x2013;enhanced CAI could be in the future used in psychotherapeutic scenarios, for example, among patients with depression [<span class="footers"><a class="citation-link" href="#ref16" rel="footnote">16</a></span>].</p><h4>Ethical, Technical, and Clinical Risks Posed by LLMs</h4><p class="abstract-paragraph">Emerging technology, including LLMs, are not immune to risks. They stem from conceptual, ethical, technical, and clinical considerations and become especially important in domains such as mental health care. They comprise ethical issues linked to bias, global digital divide, trustworthiness, black-box nature and validation, and the generalizability challenges in training and deploying LLMs [<span class="footers"><a class="citation-link" href="#ref1" rel="footnote">1</a></span>,<span class="footers"><a class="citation-link" href="#ref4" rel="footnote">4</a></span>,<span class="footers"><a class="citation-link" href="#ref17" rel="footnote">17</a></span>].</p><p class="abstract-paragraph">In addition, authors are addressing different ethical problems associated with the use of LLMs in mental health applications. For instance, Cabrera et al [<span class="footers"><a class="citation-link" href="#ref18" rel="footnote">18</a></span>] relate these challenges to the 4 principles of biomedical ethics with emphasis on data privacy, confidentiality, avoiding manipulation, and safety. Similarly, Yang et al [<span class="footers"><a class="citation-link" href="#ref19" rel="footnote">19</a></span>] emphasize the necessity of carefully evaluating LLM-enhanced CAI in mental health applications by advocating the use of explainability methods to make the outcomes of LLMs more transparent. They also suggest complementing the use of LLMs with additional sources of information, such as emotional cues and cause-effect reasoning to enhance the quality of mental health support [<span class="footers"><a class="citation-link" href="#ref19" rel="footnote">19</a></span>]. Further, Thirunavukarasu et al [<span class="footers"><a class="citation-link" href="#ref1" rel="footnote">1</a></span>] emphasized the importance of using domain-specific data to fine-tune LLMs to validate LLM-enhanced applications with real clinical use cases. Finally, research is also investigating these challenges, with a focus on the perspective of end users of these systems, for example, individuals engaged in digitally assisted therapies. To this end, Weidinger et al [<span class="footers"><a class="citation-link" href="#ref4" rel="footnote">4</a></span>] identify 6 areas of risk and potential harm to users of LLMs, including issues such as discrimination, privacy risks, misinformation, and human-computer interaction challenges [<span class="footers"><a class="citation-link" href="#ref4" rel="footnote">4</a></span>]. In particular, they emphasize the risks for the users of LLM-enhanced services, which stem from their &#x201C;human-like&#x201D; design.</p><h4>Mental Health Use Case: LLM-Enhanced CAI to Support Individuals With Depression</h4><p class="abstract-paragraph">In summary, regarding the use of LLMs, research needs to address a mix of familiar and novel conceptual, ethical, technical, and clinical issues. To improve our understanding of these challenges, we need to examine LLMs within specific domains. This approach becomes particularly pertinent in the mental health domain, where the high sensitivity of the use cases underscores the imperative for a responsible and effective implementation of LLMs in CAI systems that provide therapeutic support to vulnerable individuals.</p><p class="abstract-paragraph">In this work, we focus on the scenario where LLM-enhanced CAI systems are used in the mental health domain to promote therapeutic support focusing on individuals with depression. The rationale behind selecting this use case is as follows. First, depression affects over 300 million people and the World Health Organization identifies it as the largest single contributor to global disability [<span class="footers"><a class="citation-link" href="#ref20" rel="footnote">20</a></span>]. From an economic standpoint, for instance, studies have estimated the economic impact of depression to be 1.6% of the US gross domestic product [<span class="footers"><a class="citation-link" href="#ref21" rel="footnote">21</a></span>]. Further, burnout is a major issue among psychiatrists [<span class="footers"><a class="citation-link" href="#ref22" rel="footnote">22</a></span>]. Then, it is imperative to integrate technology-mediated interventions alongside traditional therapy methods to enhance accessibility and effectiveness of mental health services. Here, the use of CAI for patients with depression is widespread and supported by an ample body of scientific evidence [<span class="footers"><a class="citation-link" href="#ref15" rel="footnote">15</a></span>]. More recently, research has also started exploring the use of LLMs for addressing depression [<span class="footers"><a class="citation-link" href="#ref3" rel="footnote">3</a></span>,<span class="footers"><a class="citation-link" href="#ref23" rel="footnote">23</a></span>].</p><p class="abstract-paragraph">This said, it is still an open avenue of research to delineate the perimeter for the responsible use of LLMs in scenarios involving individuals with depression. Therefore, in this work, we contribute to research on the responsible design, integration, and use of generative AI in mental health by focusing on 2 challenges that affect all scenarios where individuals with depression interact with LLM-enhanced CAI. In particular, we address challenges that pertain the (1) humanization of LLM-enhanced CAI (philosophy and psychology) and (2) contextualization of the robustness desideratum (computer science).</p><p class="abstract-paragraph">Our approach is interdisciplinary and relies on theories and methods from philosophy, ethics, psychology, and computer science. Our aim is to conceptually analyze 2 topics that are underexplored in the literature on LLMs and their applications in mental health care despite their importance while highlighting their risks. With our analysis, we provide a critical perspective on the CAI-specific trend of humanizing CAI and the problem of treating the robustness of LLM-based CAI systems as a context-independent challenge. We cross the boundaries of the disciplines to show how our conceptual analysis can be informative for issues in computer science and health research [<span class="footers"><a class="citation-link" href="#ref24" rel="footnote">24</a></span>]. In fact, when properly translated, our conceptual analysis can generate valuable insights in empirical disciplines [<span class="footers"><a class="citation-link" href="#ref25" rel="footnote">25</a></span>]. Finally, we discuss recommendations to promote the responsible use of LLM-enhanced CAI in the mental health domain.</p><br><h3 class="navigation-heading h3-main-heading" id="Use-of-LLM-Enhanced-CAIs-by-Individuals-With-Depression-2-Challenges" data-label="Use-of-LLM-Enhanced-CAIs-by-Individuals-With-Depression-2-Challenges">Use of LLM-Enhanced CAIs by Individuals With Depression: 2 Challenges</h3><h4>Humanizing LLM-Enhanced CAI: a Philosophical and Psychological Perspective</h4><p class="abstract-paragraph">Humanization is intended to develop CAI with the goal of simulating human abilities and traits, such as humor, empathy, and politeness. It is different from anthropomorphism, which refers to users&#x2019; tendency to attribute CAI with human abilities and traits [<span class="footers"><a class="citation-link" href="#ref26" rel="footnote">26</a></span>,<span class="footers"><a class="citation-link" href="#ref27" rel="footnote">27</a></span>], although the CAI does need to be intentionally designed to mimic humans [<span class="footers"><a class="citation-link" href="#ref26" rel="footnote">26</a></span>]. In practice, humanization of CAI is achieved by developing verbal, nonverbal, visual, and relational cues to make the system more human-like [<span class="footers"><a class="citation-link" href="#ref28" rel="footnote">28</a></span>,<span class="footers"><a class="citation-link" href="#ref29" rel="footnote">29</a></span>]. For example, CAI can have a persona (relational cues) that simulates certain human personalities, such as being a friend or therapist. This persona is often implemented in the avatar (visual cues), the informal language (linguistic cues), and emojis (nonverbal cues) used by the CAI. Empirical studies suggest that the humanized abilities and characteristics of CAI, such as reciprocity or giving empathetic responses, has positive outcomes on digital health interactions, such as improved user experience and the formation of relationships with CAI, trust, or better engagement [<span class="footers"><a class="citation-link" href="#ref27" rel="footnote">27</a></span>,<span class="footers"><a class="citation-link" href="#ref30" rel="footnote">30</a></span>-<span class="footers"><a class="citation-link" href="#ref33" rel="footnote">33</a></span>]. These outcomes are particularly relevant in mental health care applications, where therapeutic relationships with the CAI promote therapeutic effectiveness, and high levels of user engagement might limit drop-outs [<span class="footers"><a class="citation-link" href="#ref34" rel="footnote">34</a></span>,<span class="footers"><a class="citation-link" href="#ref35" rel="footnote">35</a></span>]. However, research studies lack consistency in conceptualizing humanization and manipulating different cues [<span class="footers"><a class="citation-link" href="#ref26" rel="footnote">26</a></span>]. In fact, there is no systematic inquiry to understand the extent to which specific cues lead to specific outcomes. More investigations are needed to understand the underlying mechanisms of measured effects (eg, linguistic vs nonlinguistic cues) and assess how these differ on the basis of design choices of humanized CAI.</p><p class="abstract-paragraph">LLMs can simulate context-aware conversations with their users and demonstrate an ability to adopt conversational personas. This allows LLM-enhanced CAI displaying features that strongly resemble human abilities and characteristics to an unprecedented level [<span class="footers"><a class="citation-link" href="#ref36" rel="footnote">36</a></span>]. As noted by Shanahan et al [<span class="footers"><a class="citation-link" href="#ref36" rel="footnote">36</a></span>], LLMs are fundamentally dialogue agents that role-play an ample variety of human-like characters [<span class="footers"><a class="citation-link" href="#ref36" rel="footnote">36</a></span>]. While there is a generally positive view of humanizing CAI in various domains, we argue for a critical view of humanization efforts. Particularly, the effort of humanizing LLM-enhanced CAI in mental health applications presents serious challenges that must be tackled. Research highlights concerns about the safety of vulnerable users interacting with &#x201C;human-like&#x201D; systems [<span class="footers"><a class="citation-link" href="#ref4" rel="footnote">4</a></span>]. This perspective on humanization emphasizes the potential risks and challenges stemming from the interactions between LLM-enhanced CAI and users, such as individuals with depression. However, there appears to be a lack of theoretical perspectives and clarification on humanization although humanizing concepts are fundamentally rooted in describing and developing AI systems [<span class="footers"><a class="citation-link" href="#ref27" rel="footnote">27</a></span>,<span class="footers"><a class="citation-link" href="#ref37" rel="footnote">37</a></span>]. This theoretical clarification could inform the responsible development of these systems, particularly in mental health applications. In what follows, we address this gap by relying on philosophical, ethical, and psychological considerations.</p><h5>Conceptual Considerations</h5><p class="abstract-paragraph">First, a conceptual problem underlies the development of LLM-enhanced and &#x201C;humanized&#x201D; CAI. We argue that it is important to maintain a distinction between the characteristics and traits simulated by these systems and the human qualities that are referred to using the same concepts and terminology. Simulated abilities and characteristics of LLM-based CAI are not the same as the original human abilities and characteristics. There are fundamental differences between humans and AI that further problematize an uncritical adoption of human concepts in the context of CAI. These problems have been addressed in different research domains. For instance, Bender et al [<span class="footers"><a class="citation-link" href="#ref38" rel="footnote">38</a></span>] focus on the difference between synthetic language produced by LLM and human natural language by arguing that LLMs are &#x201C;stochastic parrots&#x201D; producing language, but not understanding it. Felin and Holweg [<span class="footers"><a class="citation-link" href="#ref39" rel="footnote">39</a></span>] similarly argue by reporting differences in human cognition and computation processes of AI. Such arguments are often based on linguistic, philosophical, and psychological knowledge about human cognition, understanding and belief systems that are based on meaning, intentions, theory-based logic, and experience and are embedded in social and normative space [<span class="footers"><a class="citation-link" href="#ref39" rel="footnote">39</a></span>-<span class="footers"><a class="citation-link" href="#ref43" rel="footnote">43</a></span>]. In philosophy, the argumentation can stem from the analysis of such concepts as rational and moral agency that are not present in CAI, but are inherent in humans and their activities such as conversations [<span class="footers"><a class="citation-link" href="#ref43" rel="footnote">43</a></span>]. Another strategy could be to analyze CAI as a different system from humans and by showing the limits of their models that cannot reach the complexity of human intelligence as reported by Landgrebe and Smith [<span class="footers"><a class="citation-link" href="#ref44" rel="footnote">44</a></span>]. All these considerations have in common the fact that they provide a diversity of arguments for the position that CAI&#x2019;s simulated abilities and characteristics differ from humans [<span class="footers"><a class="citation-link" href="#ref45" rel="footnote">45</a></span>,<span class="footers"><a class="citation-link" href="#ref46" rel="footnote">46</a></span>]. In line with this literature, we argue for careful descriptions of CAI when human concepts are used. Such human concepts and terms such as being genuinely &#x201C;empathetic,&#x201D; &#x201C;compassionate,&#x201D; &#x201C;inclusive,&#x201D; &#x201C;polite,&#x201D; or &#x201C;authoritative&#x201D; mean something different when applied to CAI. If possible, CAI should be described more appropriately to avoid misconceptions and conceptual confusion. In the next subsection, we will outline problems and risks that might stem from such misconceptions and conceptual confusion.</p><p class="abstract-paragraph">In mental health literature, we found specific examples criticizing the adoption of human concepts for LLM-enhanced CAI. A good and common example is &#x201C;empathy,&#x201D; which is a key component of psychotherapy [<span class="footers"><a class="citation-link" href="#ref47" rel="footnote">47</a></span>,<span class="footers"><a class="citation-link" href="#ref48" rel="footnote">48</a></span>]. Recently, researchers investigated the simulation of an LLM-based &#x201C;empathetic therapist&#x201D; with individuals with depression [<span class="footers"><a class="citation-link" href="#ref16" rel="footnote">16</a></span>]. The fact that an LLM-enhanced CAI can generate a seemingly empathetic response is substantially different from a human actually expressing empathy [<span class="footers"><a class="citation-link" href="#ref49" rel="footnote">49</a></span>]. This ability is linked with someone&#x2019;s personality and emotional profile, shared social space, and lived experiences [<span class="footers"><a class="citation-link" href="#ref47" rel="footnote">47</a></span>]. To be empathetic means to achieve genuine <i>understanding</i> of what another person is experiencing or attempting to express. Empathy includes active listening, asking targeted questions, and expressing genuine concern effectively addressing emotional needs [<span class="footers"><a class="citation-link" href="#ref47" rel="footnote">47</a></span>]. These activities lie beyond the capabilities of LLMs, which are disembodied statistical processes. Most importantly, LLMs do not understand users&#x2019; inputs and, in particular, do not understand their semantics [<span class="footers"><a class="citation-link" href="#ref50" rel="footnote">50</a></span>,<span class="footers"><a class="citation-link" href="#ref51" rel="footnote">51</a></span>], despite representing a vast body of information in a neural network.</p><p class="abstract-paragraph">Here, understanding (eg, a statement) is a crucial epistemic accomplishment arising from a myriad of complex cognitive activities that result in grasping meaning (eg, of statements and their components) and causal relationships, testing alternative knowledge pathways, on top of providing well-grounded reasons for each of those. Furthermore, understanding emerges as the culmination of intricate processes that are socially and normatively embedded [<span class="footers"><a class="citation-link" href="#ref52" rel="footnote">52</a></span>]. This attainment is fostered by virtues, such as perseverance, precision, and epistemic humility among others. These characterize, in particular, how human experts in a research domain structure knowledge and seek understanding. In contrast, LLMs compute answers through statistical processes that simply do not take into account the meaning of user&#x2019;s prompts [<span class="footers"><a class="citation-link" href="#ref39" rel="footnote">39</a></span>]. As a result, understanding escapes the statistical manipulations that characterize the logic of LLMs [<span class="footers"><a class="citation-link" href="#ref53" rel="footnote">53</a></span>,<span class="footers"><a class="citation-link" href="#ref54" rel="footnote">54</a></span>]. In a nutshell, displaying&#x2014;sometimes successful, as LLMs do hallucinate and generate &#x201C;fake&#x201D; references and justifications&#x2014;ability to manipulate structured information does not guarantee understanding.</p><p class="abstract-paragraph">Vulnerable patients with depression may potentially misinterpret CAI as empathetic and caring, potentially leading to unrealistic expectations such as warmth and acceptance [<span class="footers"><a class="citation-link" href="#ref55" rel="footnote">55</a></span>]. Due to CAI&#x2019;s limitations, such misconceptions could reinforce negative beliefs and worsen emotional states. Since LLMs lack understanding of user inputs, they may respond inappropriately, misunderstanding the nuances of individual situations. This could further reinforce negative feelings or isolation in patients with depression. This point is particularly relevant for designers and therapists who need to test the capabilities of LLMs before promoting their use for digital therapy with vulnerable individuals. Differently from current research [<span class="footers"><a class="citation-link" href="#ref4" rel="footnote">4</a></span>], we emphasize that humanization is at first a challenge for those who design and promote these systems, before becoming a risk for those who use the technology. The key here is to understand that the ability of LLMs to generate empathetic output, as opposed to being apathetic, indifferent, and insensitive in conversations, descends from the computation of empirical probabilities of &#x201C;next words,&#x201D; given the user prompt and their training on a massive amount of documents [<span class="footers"><a class="citation-link" href="#ref36" rel="footnote">36</a></span>]. In fact, under the hood, LLMs perform autocomplete functions of search engines [<span class="footers"><a class="citation-link" href="#ref50" rel="footnote">50</a></span>]. These remarks help in characterizing the limits of the humanization of LLMs and they hold true also for other characteristics and traits that LLMs attempt to simulate. This includes, in particular, the quality of being an &#x201C;expert&#x201D; in a domain, for example, a specialist in the treatment of depression among adolescents, and, in virtue of this, being perceived as a digital therapist, instead of a therapeutic support system [<span class="footers"><a class="citation-link" href="#ref53" rel="footnote">53</a></span>-<span class="footers"><a class="citation-link" href="#ref55" rel="footnote">55</a></span>].</p><p class="abstract-paragraph">In summary, philosophy and psychology guide us in recognizing the substantive differences between humans and humanized LLM-enhanced CAI. This helps to assess the limits of this endeavor, identify the correct roles these systems can play in interactions with humans, and, eventually mitigate misconceptions and overtrust in these systems [<span class="footers"><a class="citation-link" href="#ref4" rel="footnote">4</a></span>]. The issue of humanization needs more in-depth analysis, including the exploration of how the human attributes assigned to LLM-enhanced CAI influence and guide patients in shaping their behavior and responses within a conversation.</p><h5>Normative and Ethical Implications of the Conceptual Problem</h5><p class="abstract-paragraph">The conceptual confusion of ascribing human-like abilities to LLM-enhanced CAI is linked with important normative and ethical risks, which pertain to responsibility, commitments, and rights. Overall, interpersonal conversations are social and normative activities that are embedded in a set of values, norms, and virtues [<span class="footers"><a class="citation-link" href="#ref42" rel="footnote">42</a></span>]. This is particularly true in the case of therapeutic relationships that are guided by sets of values and norms to ensure a safe environment and therapeutic process for patients [<span class="footers"><a class="citation-link" href="#ref56" rel="footnote">56</a></span>-<span class="footers"><a class="citation-link" href="#ref59" rel="footnote">59</a></span>]. Such human abilities as empathy or understanding are part of this normative and professional setting. Psychiatrists and psychotherapists who do not follow professional conduct guidelines when treating individuals with depression risk causing medical emergencies for their patients&#x2014;a situation that could lead to disciplinary actions against them.</p><p class="abstract-paragraph">In the case of humanized LLM-enhanced CAI, there is a gap between what the system appears to be, for example, being compassionate, and what normative criteria this ability should meet and cannot be met by CAI&#x2014;criteria that are fulfilled by human therapists instead. Hence, when CAI simulates abilities such as empathy or understanding, these are not part of the normative setting as they are in the case of human experts. This CAI can lead to risks among individuals with depression. For instance, if an LLM&#x2019;s response lacks compassion during a conversation with a user with depression, this may worsen their condition, even leading to self-harm. An LLM-enhanced CAI may not encode cultural nuances and the uniqueness of individual experiences in its outputs while its biases significantly influence how the system presents and discusses knowledge with patients. This can contribute to &#x201C;epistemic injustice&#x201D; [<span class="footers"><a class="citation-link" href="#ref60" rel="footnote">60</a></span>], making individuals with depression potentially feel more isolated and their perspectives undervalued and misunderstood. In addition, human experts&#x2014;for instance, psychiatrists&#x2014;have epistemic duties, including being truthful and justifying their beliefs [<span class="footers"><a class="citation-link" href="#ref43" rel="footnote">43</a></span>]. In contrast, LLMs lack these commitments [<span class="footers"><a class="citation-link" href="#ref40" rel="footnote">40</a></span>].</p><p class="abstract-paragraph">Further, this &#x201C;normativity gap&#x201D; leads to a problem of assigning responsibility and defining how to approach failures in a conversation with patients. There is a difference between addressing the ethical consequences of technical failures of a computer system, for example, numerical errors and inaccurate predictions, and dealing with the issues that arise from a faulty implementation of humanizing features. On the one hand, technical errors in computer systems are clearly defined, objectively measured, and traced, facilitating the definition of their sanctions. On the other hand, what does it mean that the LLM-enhanced CAI was not empathetic in a given conversation? Was it not empathetic <i>enough</i>? According to which objective measures of empathy? Did the lack of empathy persist in the conversation long enough to consider applying sanctions? The humanization of LLM-enhanced CAI involves complexities that are not fully understood even in interpersonal interactions, where ambiguous, inappropriate or unprofessional questions and answers may occur, and the applicability of sanctions is unclear.</p><p class="abstract-paragraph">In summary, despite the current trend of humanizing LLM-enhanced CAI, it is questionable to what extent such humanization is necessary and helpful as it poses theoretical and ethical challenges. It remains an open question whether there is an ethically acceptable, safe, and beneficial degree of humanization for these systems. Philosophy and psychology can help frame the problem, which highlights a particularly important gap of the responsible design and development of AI in mental health care [<span class="footers"><a class="citation-link" href="#ref61" rel="footnote">61</a></span>].</p><h4>Contextualizing the Robustness of LLMs Used by Individuals With Depression: a Computer Science Perspective</h4><h5>The Robustness of LLMs</h5><p class="abstract-paragraph">Robustness refers to the ability of machine learning models to withstand &#x201C;perturbations&#x201D; that may affect their performance [<span class="footers"><a class="citation-link" href="#ref62" rel="footnote">62</a></span>-<span class="footers"><a class="citation-link" href="#ref64" rel="footnote">64</a></span>]. It is a general model capability that becomes essential for ensuring the reliability of machine learning models in real-world applications. Interestingly, robustness is a multidimensional concept that is currently lacking a one-size-fits-all definition. Rather, research discusses what a robust model <i>should do</i> [<span class="footers"><a class="citation-link" href="#ref62" rel="footnote">62</a></span>,<span class="footers"><a class="citation-link" href="#ref65" rel="footnote">65</a></span>-<span class="footers"><a class="citation-link" href="#ref68" rel="footnote">68</a></span>], investigating how a model should resist different types of perturbations, such as those affecting its input data, data distributions over time, and the model structure. In fact, a robust machine learning model computes predictions that do not vary disproportionately in case of perturbed inputs. Further, it retains accuracy in the presence of distributional shift [<span class="footers"><a class="citation-link" href="#ref69" rel="footnote">69</a></span>] and is not affected by small changes in its constitutive structure. In summary, robustness is a key requirement for trustworthy AI. It can also be extended to comprise algorithms that provide explanations of machine learning models&#x2019; predictions [<span class="footers"><a class="citation-link" href="#ref65" rel="footnote">65</a></span>,<span class="footers"><a class="citation-link" href="#ref66" rel="footnote">66</a></span>,<span class="footers"><a class="citation-link" href="#ref68" rel="footnote">68</a></span>,<span class="footers"><a class="citation-link" href="#ref70" rel="footnote">70</a></span>]. In this case, robust explanations are not altered by the perturbation of data inputs and are stable over time.</p><p class="abstract-paragraph">In the case of LLMs, the high-level desideratum of robustness seems to gain an extra level of complexity [<span class="footers"><a class="citation-link" href="#ref63" rel="footnote">63</a></span>,<span class="footers"><a class="citation-link" href="#ref64" rel="footnote">64</a></span>]. In fact, when discussing what robust LLMs should do, we need to consider the peculiar way these models compute their predictions, namely, using prompt-based queries [<span class="footers"><a class="citation-link" href="#ref71" rel="footnote">71</a></span>]. Here, a prompt is structured information&#x2014;often, a text snippet&#x2014;that users offer as an instruction to the LLM and which is often accompanied by one or more examples to guide the model (&#x201C;in-context learning&#x201D; or &#x201C;few-shot prompting&#x201D; procedure) [<span class="footers"><a class="citation-link" href="#ref71" rel="footnote">71</a></span>,<span class="footers"><a class="citation-link" href="#ref72" rel="footnote">72</a></span>]. For example, a prompt for an LLM used in an application to investigate how patients with depression communicate with CAI may look like this: &#x201C;Classify the following sentence in either normal or alerting: [s].&#x201D; Here, the example [s] is the patient&#x2019;s utterance: &#x201C;Today, I felt more useless than usual and nobody knows it.&#x201D;</p><p class="abstract-paragraph">Broadly speaking, an LLM is robust if its predictions display an appropriate level of sensitivity to the changes that may affect its prompts and examples. With a robust LLM, similar prompts and examples should lead to similar predictions, among others. This said, research has a long way to go before this promise can become reality. An increasing body of literature shows that commonly available LLMs, for example, T5, Vicuna, Llama 2, and ChatGPT-3.5 [<span class="footers"><a class="citation-link" href="#ref73" rel="footnote">73</a></span>], generally display a low level of robustness. These models are highly sensitive to different types of perturbations, named &#x201C;prompt-targeting adversarial attacks&#x201D; [<span class="footers"><a class="citation-link" href="#ref73" rel="footnote">73</a></span>]. These comprise switching the order of few-shot examples and semantic-preserving variations, such as adding a few typographical errors, replacing words by synonyms or back translating the prompt itself and its examples [<span class="footers"><a class="citation-link" href="#ref73" rel="footnote">73</a></span>]. As a result, a few empirical studies show that prompt-targeting adversarial attacks can lead to substantially different LLM predictions, indicating an overall lack of robustness across a variety of downstream tasks, such as text classification and generation [<span class="footers"><a class="citation-link" href="#ref73" rel="footnote">73</a></span>].</p><p class="abstract-paragraph">Finally, from an ethical perspective, the lack of robustness of LLMs is a source of different issues. Nonrobust models lead to unreliable decision-making, that is, they increase the risk of making inconsistent or erroneous decisions that can harm those affected by them. For instance, LLMs could provide misdiagnosis and share information that does not align with clinical practices, show the inability to detect and respond to nuances in language that indicate a mental health crisis (such as expressions of suicidal ideation or severe distress), and offer appropriate and timely crisis intervention resources. Finally, training on large corpora of text may lead LLMs to perpetuate forms of stigmatization against individuals affected by mental health issues (despite fine-tuning on documents from the psychiatry domain).</p><p class="abstract-paragraph">They may also lead to unwanted cases of bias and discrimination and pose serious concern to the privacy of individuals&#x2019; information. Nonrobust models can be tricked to reveal personal information. Finally, erratic or nonrobust model behavior affects their overall transparency levels. These ethical concerns are particularly relevant in high-stakes scenarios, such as those where LLMs are deployed to support the mental health of vulnerable individuals.</p><h5>Contextualizing the Robustness of LLMs</h5><p class="abstract-paragraph">Current approaches to ensuring the robustness of LLMs lack proper contextualization: they are not targeted to any specific scenario of human-LLM interaction. While it is beneficial that LLM predictions remain consistent even when prompted in similar ways or when the order of the LLM examples changed, as suggested by the emerging literature on prompt-targeting adversarial attacks [<span class="footers"><a class="citation-link" href="#ref73" rel="footnote">73</a></span>], this alone is insufficient for the ethically responsible use of LLMs in high-risk applications, such as in scenarios involving mental health support for patients with depression. In these cases, we argue that it is necessary that LLMs&#x2019; robustness is tailored to align with the specific language characteristics&#x2014;and their variations over time&#x2014;of the model users, specifically, patients with depression. In other words, an appropriately robust LLM to be used by individuals with depression should detect their lexical, syntactic, cultural, and content-related language patterns, while retaining the ability of not being affected by more general adversarial attacks [<span class="footers"><a class="citation-link" href="#ref73" rel="footnote">73</a></span>], as suggested by the high-level desideratum of robustness. In summary, the LLM should provide accurate outputs that are (1) not affected by spurious linguistic variations in the prompts and examples provided by its users and (2) tailored to the context in which the interaction takes place. This calls for the design of prompt-targeting <i>contextualized</i> adversarial attacks and the assessment of the <i>contextualized</i> robustness of LLMs, rather than the investigation of general, domain-unspecific robustness constraints.</p><p class="abstract-paragraph">Research on depression has already identified a few linguistic patterns that may help in this regard. On average, patients with depression make more and longer pauses than healthy individuals when they communicate [<span class="footers"><a class="citation-link" href="#ref74" rel="footnote">74</a></span>]. Further, they display a lower pitch, more monotonous speech, and slower utterance production [<span class="footers"><a class="citation-link" href="#ref75" rel="footnote">75</a></span>,<span class="footers"><a class="citation-link" href="#ref76" rel="footnote">76</a></span>] (notably, the importance of slowed speech is emphasized in the Patient Health Questionnaire&#x2013;9 self-assessed depression report [<span class="footers"><a class="citation-link" href="#ref76" rel="footnote">76</a></span>]). Similarly, the analysis of transcripts of utterances of individuals with depression shows that patients with depression use more modifying adverbs, first-person and personal pronouns, and more verbal utterances [<span class="footers"><a class="citation-link" href="#ref76" rel="footnote">76</a></span>-<span class="footers"><a class="citation-link" href="#ref78" rel="footnote">78</a></span>]. Further, individuals with depression and healthy individuals show differences in the use of past tense, causation, achievement, and death words [<span class="footers"><a class="citation-link" href="#ref76" rel="footnote">76</a></span>], using simpler sentence structures and reduced linguistic complexity, as well as exhibiting rumination and self-focus in their language [<span class="footers"><a class="citation-link" href="#ref79" rel="footnote">79</a></span>,<span class="footers"><a class="citation-link" href="#ref80" rel="footnote">80</a></span>]. The instability of words associated with negative emotion predicts depression in textual production on social media as well [<span class="footers"><a class="citation-link" href="#ref81" rel="footnote">81</a></span>]. We also note that these patterns may vary over time, as the patient may go through different stages of depression. In <span class="footers"><a class="citation-link" href="#figure1" rel="footnote">Figure 1</a></span>, we show a few examples of such variations we generated with ChatGPT-4. In summary, robust LLMs to be used for therapy for individuals with depression should be able to correctly identify their linguistic patterns and react to their evolution appropriately. This observation is reinforced by the fact that language is a dynamic process that changes over time. New idioms, metaphors, or shifts in meaning regularly take place, and LLMs need to be aligned with the dynamics of language production. Here, the risk is to promote &#x201C;frozen&#x201D; narratives and linguistic patterns that do not reflect the evolution of patient narratives over time.</p><p class="abstract-paragraph">From a technical perspective, making LLMs contextually robust requires their fine-tuning them with high-quality, curated data. Currently, obtaining such data for patients with depression is challenging, with most available examples coming from social media platforms such as Twitter or Reddit [<span class="footers"><a class="citation-link" href="#ref82" rel="footnote">82</a></span>]. To the best of our knowledge, there exists no publicly available data set of conversations of patients with depression from consultations with therapists, therapeutic CAI, or other agents in everyday life. Additionally, we cannot easily improve proprietary LLMs. This is a serious problem, as a recent study shows that ChatGPT-3.5 is not robust enough for conversations with individuals with symptoms of anxiety or depression, as the LLMs suggested medications to its users; medications should be taken under the guidance of a psychiatrist [<span class="footers"><a class="citation-link" href="#ref83" rel="footnote">83</a></span>].</p><p class="abstract-paragraph">In summary, understanding and achieving the contextualized robustness of LLMs is crucial for the responsible use of LLM-enhanced CAI among individuals with depression. While computer science offers methodologies to formalize, evaluate, and satisfy this requirement, their effectiveness is limited by the availability of necessary resources, primarily therapy-relevant data, which are currently lacking.</p><figure><a name="figure1">&#x200E;</a><a class="fancybox" title="Figure 1. Examples of utterances by patients with mild depression and those with severe depression generated by ChatGPT-4 (prompt and answers from December 2023)." href="https://asset.jmir.pub/assets/97058c61-387f-11ef-81c0-dbce3031f48e.png" id="figure1"><img class="figure-image" src="https://asset.jmir.pub/assets/97058c61-387f-11ef-81c0-dbce3031f48e.png"></a><figcaption><span class="typcn typcn-image"></span><b>Figure 1. </b> Examples of utterances by patients with mild depression and those with severe depression generated by ChatGPT-4 (prompt and answers from December 2023). </figcaption></figure><h4>Toward Responsible Use of LLMs in Therapeutic Settings Involving Individuals With Depression</h4><p class="abstract-paragraph">The complexities of humanization and contextualized robustness appear to temper the initial enthusiasm surrounding LLMs. The problems affecting humanization we discussed in the previous sections seem to be at odds with the very essence of LLMs, namely, to role-play different personas. Meanwhile, we noted that achieving contextualized robustness requires thorough fine-tuning and comprehensive testing. Moreover, this process must be grounded in a deep understanding of how language production and usage evolve over time among the users of these systems.</p><p class="abstract-paragraph">The importance of addressing the risks associated with humanization and the absence of contextual robustness is underscored by real-world incidents involving individuals with depression using LLM-enhanced CAI. There have been several instances, reported in various media, where LLM-enhanced CAI provided support for mental health issues but instead encouraged self-harm or offered detrimental advice [<span class="footers"><a class="citation-link" href="#ref84" rel="footnote">84</a></span>,<span class="footers"><a class="citation-link" href="#ref85" rel="footnote">85</a></span>]. A Belgian man with depression committed suicide following conversations with ChatGPT-3.5 [<span class="footers"><a class="citation-link" href="#ref85" rel="footnote">85</a></span>]. Recently, Kumar et al [<span class="footers"><a class="citation-link" href="#ref86" rel="footnote">86</a></span>] commented on the case of a user with depression, who, during a crisis, was able to insert a sequence of words in their prompt that bypassed the LLM&#x2019;s safety-guards and generated harmful content [<span class="footers"><a class="citation-link" href="#ref86" rel="footnote">86</a></span>]. In fact, the LLM returned detailed instructions on how to commit different types of self-harm [<span class="footers"><a class="citation-link" href="#ref86" rel="footnote">86</a></span>]. Further, authors show that certain prompts result in ChatGPT-3.5 prescribing medications to individuals with anxiety or depression symptoms, despite medications that should be taken under the guidance of a therapist [<span class="footers"><a class="citation-link" href="#ref83" rel="footnote">83</a></span>]. In addition, the vulnerability of LLM-enhanced CAI to attacks and content manipulation can lead to the generation of offensive, inappropriate, or objectionable responses; the provision of incorrect information; and discriminatory recommendations. These events show potential of causing either discomfort, harm, or even acute detriment to users [<span class="footers"><a class="citation-link" href="#ref87" rel="footnote">87</a></span>].</p><p class="abstract-paragraph">Finally, it is argued that humanization may invite and actively nudge patients to react to its cues [<span class="footers"><a class="citation-link" href="#ref4" rel="footnote">4</a></span>]. LLM-enhanced CAI are persuasive to their users and can perform a variety of emotional manipulations. These may lead to inappropriate reliance on these systems or overtrusting them [<span class="footers"><a class="citation-link" href="#ref88" rel="footnote">88</a></span>], reinforcing bias, and overestimating their capabilities, including expecting unrealistic behavioral change [<span class="footers"><a class="citation-link" href="#ref4" rel="footnote">4</a></span>,<span class="footers"><a class="citation-link" href="#ref89" rel="footnote">89</a></span>].</p><p class="abstract-paragraph">Given the challenges discussed in this viewpoint paper, the path toward a responsible development and use of LLM-enhanced CAI in therapeutic settings involving individuals with depression appears to be quite challenging. Here, we agree with Cheng et al [<span class="footers"><a class="citation-link" href="#ref90" rel="footnote">90</a></span>], who promote the idea of using LLM-enhanced CAI as an assistant to mental health professionals in providing patient care [<span class="footers"><a class="citation-link" href="#ref90" rel="footnote">90</a></span>]. Further, they emphasize the need for routine monitoring of patients and the systems to address emerging challenges in a timely manner [<span class="footers"><a class="citation-link" href="#ref90" rel="footnote">90</a></span>]. However, we disagree with the authors when they suggest that, from an ethical standpoint, psychiatrists should take full responsibility for any detriment to patients interacting with the LLM-enhanced CAI [<span class="footers"><a class="citation-link" href="#ref90" rel="footnote">90</a></span>]. In fact, this claim would be justified if psychiatrists could understand these systems in depth. However, it is unlikely that psychiatrists, despite their expertise in mental health, would possess an in-depth understanding of the workings of such advanced technology.</p><p class="abstract-paragraph">In summary, an interdisciplinary approach to the responsible use of LLM-enhanced CAI in therapeutic settings involving users with depression is essential, encompassing both the social and technological aspects of CAI development and application [<span class="footers"><a class="citation-link" href="#ref46" rel="footnote">46</a></span>,<span class="footers"><a class="citation-link" href="#ref91" rel="footnote">91</a></span>]. This approach should integrate theoretical and practical perspectives from psychiatry, ethics, philosophy, computer science, and user experience design, ensuring a balanced and informed development of these technologies. These perspectives could help address the risks posed by the humanization of these systems and the lack of contextualized robustness, by suggesting ways to inform, instruct, and educate developers and users (including therapists) about the conceptual nuances of normative concepts, such as expertise, and the characteristics of language production of individuals with depression.</p><p class="abstract-paragraph">One practical measure to manage the risks stemming from the humanization of LLM-enhanced CAI could be incorporating disclaimers and a short conversation at the start of therapy sessions with the system. The measures would outline the capabilities and theoretical limitations of CAI, helping users in accurately setting their expectations from the interaction with the systems. Revisiting these disclaimers and conversations periodically, especially in long-term use, could reinforce users&#x2019; understanding and help them manage their expectations effectively over time.</p><p class="abstract-paragraph">To contextualize the robustness of LLM-enhanced CAI, researchers could collect data from different cohorts of patients with depression interacting with the system in controlled settings. They could augment these data by other sources, including survey data and clinical information to improve the accuracy of the LLMs. Further, identifying contextual features that help LLMs recognize the patients&#x2019; emotional states, triggers, or history can further improve the accuracy and contextual robustness of the models over time. These features may include over time sentiment analysis, trigger recognition, environmental information, and audio and visual cues. Therapists and patients could review these interactions to correct inaccurate suggestions and address the issues they may have caused in a timely manner. This procedure, which necessitates the active involvement of both clinical experts and patients, is undeniably time-consuming but indispensable. Moreover, it hinges on a controlled setting that may not capture all aspects of the interactions between patients with depression and LLM-enhanced CAI in everyday life. However, this is a first step to assess the risk of deploying &#x201C;brittle&#x201D; LLMs in clinical practice.</p><p class="abstract-paragraph">Finally, to responsibly use LLM-enhanced CAI with patients with depression, it is important to rigorously examine its long-term effects. Developing and adhering to strict standards for the creation and implementation of these systems is necessary, mirroring the evidence-based approach of mental health care, where interventions undergo thorough testing, including randomized controlled trials. A structured framework, akin to those used in the development and assessment of patient decision-making tools [<span class="footers"><a class="citation-link" href="#ref92" rel="footnote">92</a></span>,<span class="footers"><a class="citation-link" href="#ref93" rel="footnote">93</a></span>], could greatly benefit the development and application of LLM-enhanced CAI. Guidelines that address the humanization of these systems and ensure their contextual robustness should be central to this framework.</p><h4>Ethical Considerations</h4><p class="abstract-paragraph">This study was exempt from ethical review as no human participants were involved.</p><br><h3 class="navigation-heading h3-main-heading" id="Conclusions" data-label="Conclusions">Conclusions</h3><p class="abstract-paragraph">The use of LLMs in mental health applications presents numerous conceptual, ethical, technical, and challenges. In this work, we have outlined 2 challenges that impede the responsible use of LLMs in applications involving patients with depression: the accentuation of human-like qualities of LLM-enhanced CAI and the lack of contextualized robustness. These challenges warrant comprehensive consideration and a proactive approach to ensure the responsible and effective integration of LLMs in mental health settings. While human-like qualities may enhance user engagement, it is imperative to strike a balance when a simulation of human characteristics and abilities does not increase ethical risks and their effects are well understood. A responsible approach involves clearly communicating to users that they are interacting with AI-based tools and what this exactly means, enabling them to make informed decisions about the assistance they receive and being aware of their limitations as well as differences from human conversation.</p><p class="abstract-paragraph">Further, LLMs should be adept at understanding and adapting to the specific linguistic, cultural, and emotional nuances of individuals dealing with mental health issues. Robustness, in this context, involves not only maintaining coherence in responses but also sensitively addressing the unique needs of each user. Ethical guidelines should emphasize the development and validation of LLMs with a focus on contextual sensitivity. It is vital to establish a framework that delineates the roles of AI developers, health care providers, and users in ensuring the well-being of those seeking mental health support.</p></article><h4 class="h4-border-top">Authors' Contributions</h4><p><p class="abstract-paragraph">AF conceptualized the research. AF and JS wrote the first draft of the manuscript. MT provided inputs on depression and the use of conversational artificial intelligence in therapy for patients with depression. AF and JS finalized the manuscript. All authors approved the final version of the manuscript.</p></p><h4 class="h4-border-top">Conflicts of Interest</h4><p><p class="abstract-paragraph">None declared.</p></p><div class="footnotes"><h4 id="References" class="h4-border-top navigation-heading" data-label="References">References</h4><ol><li><span id="ref1">Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW. Large language models in medicine. Nat Med.  Aug 2023;29(8):1930-1940. [<a target="_blank" href="https://dx.doi.org/10.1038/s41591-023-02448-8">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37460753&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref2">Ayers JW, Poliak A, Dredze M,  et al. Comparing physician and artificial intelligence chatbot responses to patient questions posted to a public social media forum. JAMA Intern Med.  Jun 1, 2023;183(6):589. [<a target="_blank" href="https://dx.doi.org/10.1001/jamainternmed.2023.1838">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37115527&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref3">Galatzer-Levy IR, McDuff D, Natarajan V, Karthikesalingam A, Malgaroli M. The capability of large language models to measure psychiatric functioning. arXiv.  Preprint posted online on  Aug 3, 2023.  [<a target="_blank" href="https://dx.doi.org/10.48550/arXiv.2308.01834">CrossRef</a>]</span></li><li><span id="ref4">Weidinger L, Uesato J, Rauh M,  et al. Taxonomy of risks posed by language models.  Presented at: FAccT &#x2019;22: 2022 ACM Conference on Fairness, Accountability, and Transparency; Jun 21 to 24, 2022; Seoul, Republic of Korea. [<a target="_blank" href="https://dx.doi.org/10.1145/3531146.3533088">CrossRef</a>]</span></li><li><span id="ref5">Clusmann J, Kolbinger FR, Muti HS,  et al. The future landscape of large language models in medicine. Commun Med.  Oct 10, 2023;3(1):141. [<a target="_blank" href="https://dx.doi.org/10.1038/s43856-023-00370-1">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37816837&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref6">Mesk&#xF3; B, Topol EJ. The imperative for regulatory oversight of large language models (or generative AI) in healthcare. NPJ Digit Med.  Jul 6, 2023;6(1):120. [<a target="_blank" href="https://dx.doi.org/10.1038/s41746-023-00873-0">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37414860&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref7">Peng C, Yang X, Chen A,  et al. A study of generative large language model for medical research and healthcare. NPJ Digit Med.  Nov 16, 2023;6(1):210. [<a target="_blank" href="https://dx.doi.org/10.1038/s41746-023-00958-w">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37973919&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref8">Yang R, Tan TF, Lu W, Thirunavukarasu AJ, Ting DSW, Liu N. Large language models in health care: development, applications, and challenges. Health Care Science.  Aug 2023;2(4):255-263. [<a target="_blank" href="https://dx.doi.org/10.1002/hcs2.61">CrossRef</a>]</span></li><li><span id="ref9">Hua Y, Liu F, Yang K,  et al. Large language models in mental health care: a scoping review. arXiv.  Preprint posted online on  Jan 1, 2024.  [<a target="_blank" href="https://dx.doi.org/10.48550/arXiv.2401.02984">CrossRef</a>]</span></li><li><span id="ref10">Stade EC, Stirman SW, Ungar LH,  et al. Large language models could change the future of behavioral healthcare: a proposal for responsible development and evaluation. Npj Ment Health Res.  Apr 2, 2024;3(1):12. [<a target="_blank" href="https://dx.doi.org/10.1038/s44184-024-00056-z">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=38609507&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref11">Ferrario A, Gloeckler S, Biller-Andorno N. Ethics of the algorithmic prediction of goal of care preferences: from theory to practice. J Med Ethics.  Mar 2023;49(3):165-174. [<a target="_blank" href="https://dx.doi.org/10.1136/jme-2022-108371">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=36347603&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref12">Gloeckler S, Ferrario A, Biller-Andorno N. An ethical framework for incorporating digital technology into advance directives: promoting informed advance decision making in healthcare. Yale J Biol Med.  Sep 2022;95(3):349-353. [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=36187419&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref13">Earp BD, Porsdam Mann S, Allen J,  et al. A personalized patient preference predictor for substituted judgments in healthcare: technically feasible and ethically desirable. Am J Bioeth.  Jul 2024;24(7):13-26. [<a target="_blank" href="https://dx.doi.org/10.1080/15265161.2023.2296402">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=38226965&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref14">Weizenbaum J. ELIZA&#x2014;a computer program for the study of natural language communication between man and machine. Commun ACM.  Jan 1966;9(1):36-45. [<a target="_blank" href="https://dx.doi.org/10.1145/365153.365168">CrossRef</a>]</span></li><li><span id="ref15">He Y, Yang L, Qian C,  et al. Conversational agent interventions for mental health problems: systematic review and meta-analysis of randomized controlled trials. J Med Internet Res.  Apr 28, 2023;25:e43862. [<a target="_blank" href="https://dx.doi.org/10.2196/43862">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37115595&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref16">Chen S, Wu M, Zhu KQ, Lan K, Zhang Z, Cui L. LLM-empowered chatbots for psychiatrist and patient simulation: application and evaluation. arXiv.  Preprint posted online on  May 23, 2023.  [<a target="_blank" href="https://dx.doi.org/10.48550/arXiv.2305.13614">CrossRef</a>]</span></li><li><span id="ref17">Li H, Moon JT, Purkayastha S, Celi LA, Trivedi H, Gichoya JW. Ethics of large language models in medicine and medical research. Lancet Digit Health.  Jun 2023;5(6):e333-e335. [<a target="_blank" href="https://dx.doi.org/10.1016/S2589-7500(23)00083-3">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37120418&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref18">Cabrera J, Loyola MS, Maga&#xF1;a I, Rojas R. Ethical dilemmas, mental health, artificial intelligence, and LLM-based chatbots. In: Rojas I, Valenzuela O, Rojas Ruiz F, Herrera LJ, Ortu&#xF1;o F, editors. Bioinformatics and Biomedical Engineering. Springer Nature Switzerland;  2023:313-326. [<a target="_blank" href="https://dx.doi.org/10.1007/978-3-031-34960-7">CrossRef</a>]</span></li><li><span id="ref19">Yang K, Ji S, Zhang T, Xie Q, Kuang Z, Ananiadou S. Towards interpretable mental health analysis with large language models.  Presented at: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing; Dec 6 to 10, 2023; Singapore. [<a target="_blank" href="https://dx.doi.org/10.18653/v1/2023.emnlp-main.370">CrossRef</a>]</span></li><li><span id="ref20">Ferrari AJ, Charlson FJ, Norman RE,  et al. The epidemiological modelling of major depressive disorder: application for the Global Burden of Disease Study 2010. PLoS One.  Jul 2013;8(7):e69637. [<a target="_blank" href="https://dx.doi.org/10.1371/journal.pone.0069637">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=23922765&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref21">Chodavadia P, Teo I, Poremski D, Fung DSS, Finkelstein EA. Prevalence and economic burden of depression and anxiety symptoms among Singaporean adults: results from a 2022 web panel. BMC Psychiatry.  Feb 14, 2023;23(1):104. [<a target="_blank" href="https://dx.doi.org/10.1186/s12888-023-04581-7">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=36782116&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref22">Bykov KV, Zrazhevskaya IA, Topka EO,  et al. Prevalence of burnout among psychiatrists: a systematic review and meta-analysis. J Affect Disord.  Jul 2022;308:47-64. [<a target="_blank" href="https://dx.doi.org/10.1016/j.jad.2022.04.005">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=35398112&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref23">Xu X, Yao B, Dong Y,  et al. Mental-LLM: leveraging large language models for mental health prediction via online text data. arXiv.  Preprint posted online on  Jul 26, 2023.  [<a target="_blank" href="https://dx.doi.org/10.48550/arXiv.2307.14385">CrossRef</a>]</span></li><li><span id="ref24">Choi BCK, Pak AWP. Multidisciplinarity, interdisciplinarity and transdisciplinarity in health research, services, education and policy: 1. Definitions, objectives, and evidence of effectiveness. Clin Invest Med.  Dec 2006;29(6):351-364. [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=17330451&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref25">Archibald MM, Lawless MT, de Plaza MAP, Kitson AL. How transdisciplinary research teams learn to do knowledge translation (KT), and how KT in turn impacts transdisciplinary research: a realist evaluation and longitudinal case study. Health Res Policy Syst.  Mar 21, 2023;21(1):20. [<a target="_blank" href="https://dx.doi.org/10.1186/s12961-023-00967-x">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=36944997&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref26">Nass C, Moon Y. Machines and mindlessness: social responses to computers. J Soc Issues.  Jan 2000;56(1):81-103. [<a target="_blank" href="https://dx.doi.org/10.1111/0022-4537.00153">CrossRef</a>]</span></li><li><span id="ref27">Li M, Suh A. Machinelike or humanlike? A literature review of anthropomorphism in AI-enabled technology.  Presented at: 54th Hawaii International Conference on System Sciences (HICSS 2021); Jan 5, 2021; Kauai, Hawaii. [<a target="_blank" href="https://dx.doi.org/10.24251/HICSS.2021.493">CrossRef</a>]</span></li><li><span id="ref28">Bickmore TW, Picard RW. Establishing and maintaining long-term human-computer relationships. ACM Trans Comput-Hum Interact.  Jun 2005;12(2):293-327. [<a target="_blank" href="https://dx.doi.org/10.1145/1067860.1067867">CrossRef</a>]</span></li><li><span id="ref29">Ni&#xDF;en M, R&#xFC;egger D, Stieger M,  et al. The effects of health care chatbot personas with different social roles on the client-chatbot bond and usage intentions: development of a design codebook and web-based study. J Med Internet Res.  Apr 27, 2022;24(4):e32630. [<a target="_blank" href="https://dx.doi.org/10.2196/32630">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=35475761&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref30">Araujo T. Living up to the chatbot hype: the influence of anthropomorphic design cues and communicative agency framing on conversational agent and company perceptions. Comput Human Behav.  Aug 2018;85:183-189. [<a target="_blank" href="https://dx.doi.org/10.1016/j.chb.2018.03.051">CrossRef</a>]</span></li><li><span id="ref31">Pereira J, D&#xED;az &#xD3;. Using health chatbots for behavior change: a mapping study. J Med Syst.  Apr 4, 2019;43(5):135. [<a target="_blank" href="https://dx.doi.org/10.1007/s10916-019-1237-1">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=30949846&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref32">Stara V, Vera B, Bolliger D,  et al. Usability and acceptance of the embodied conversational agent Anne by people with dementia and their caregivers: exploratory study in home environment settings. JMIR Mhealth Uhealth.  Jun 25, 2021;9(6):e25891. [<a target="_blank" href="https://dx.doi.org/10.2196/25891">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=34170256&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref33">Beatty C, Malik T, Meheli S, Sinha C. Evaluating the therapeutic alliance with a free-text CBT conversational agent (Wysa): a mixed-methods study. Front Digit Health.  Apr 11, 2022;4:847991. [<a target="_blank" href="https://dx.doi.org/10.3389/fdgth.2022.847991">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=35480848&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref34">Ardito RB, Rabellino D. Therapeutic alliance and outcome of psychotherapy: historical excursus, measurements, and prospects for research. Front Psychol.  Oct 18, 2011;2:270. [<a target="_blank" href="https://dx.doi.org/10.3389/fpsyg.2011.00270">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=22028698&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref35">Norcross JC, Lambert MJ, editors. Psychotherapy Relationships That Work: Volume 1: Evidence-Based Therapist Contributions (3 edn). Oxford University Press;  2019.  [<a target="_blank" href="https://dx.doi.org/10.1093/med-psych/9780190843953.001.0001">CrossRef</a>] ISBN: 978-0-19-084401-1</span></li><li><span id="ref36">Shanahan M, McDonell K, Reynolds L. Role-play with large language models. Nature.  Nov 2023;623(7987):493-498. [<a target="_blank" href="https://dx.doi.org/10.1038/s41586-023-06647-8">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37938776&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref37">Salles A, Evers K, Farisco M. Anthropomorphism in AI. AJOB Neurosci.   2020;11(2):88-95. [<a target="_blank" href="https://dx.doi.org/10.1080/21507740.2020.1740350">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=32228388&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref38">Bendig E, Erb B, Schulze-Thuesing L, Baumeister H. The next generation: chatbots in clinical psychology and psychotherapy to foster mental health &#x2013; a scoping review. Verhaltenstherapie.   2022;32(Suppl. 1):64-76. [<a target="_blank" href="https://dx.doi.org/10.1159/000501812">CrossRef</a>]</span></li><li><span id="ref39">Felin T, Holweg M. Theory is all you need: AI, human cognition, and decision making. SSRN.  Preprint posted online on  Apr 4, 2024.  [<a target="_blank" href="https://dx.doi.org/10.2139/ssrn.4737265">CrossRef</a>]</span></li><li><span id="ref40">Bender EM, Gebru T, McMillan-Major A, Shmitchell S. On the dangers of stochastic parrots: can language models be too big?  Presented at: 2021 ACM Conference on Fairness, Accountability, and Transparency Virtual Event; Mar 3 to 10, 2021; Virtual Event Canada. [<a target="_blank" href="https://dx.doi.org/10.1145/3442188.3445922">CrossRef</a>]</span></li><li><span id="ref41">Emsley R. ChatGPT: these are not hallucinations &#x2013; they&#x2019;re fabrications and falsifications. Schizophrenia (Heidelb).  Aug 19, 2023;9(1):52. [<a target="_blank" href="https://dx.doi.org/10.1038/s41537-023-00379-4">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37598184&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref42">Brandom R, McDowell J. Knowledge and the social articulation of the space of reasons. Philos Phenomen Res.  Dec 1995;55(4):895. [<a target="_blank" href="https://dx.doi.org/10.2307/2108339">CrossRef</a>]</span></li><li><span id="ref43">Sedlakova J, Trachsel M. Conversational artificial intelligence in psychotherapy: a new therapeutic tool or agent? Am J Bioeth.  May 2023;23(5):4-13. [<a target="_blank" href="https://dx.doi.org/10.1080/15265161.2022.2048739">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=35362368&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref44">Landgrebe J, Smith B. Why Machines Will Never Rule the World: Artificial Intelligence Without Fear. Routledge;  2022.  URL: <a target="_blank" href="https://www.taylorfrancis.com/books/9781003310105">https://www.taylorfrancis.com/books/9781003310105</a> [Accessed 2024-06-19]
                         [<a target="_blank" href="https://dx.doi.org/10.4324/9781003310105">CrossRef</a>]</span></li><li><span id="ref45">Boyle A. Disagreement &amp; classification in comparative cognitive science. No&#xFB;s.  Oct 16, 2023. [<a target="_blank" href="https://dx.doi.org/10.1111/nous.12480">CrossRef</a>]</span></li><li><span id="ref46">D&#xED;az-Rodr&#xED;guez N, Del Ser J, Coeckelbergh M, de Prado ML, Herrera-Viedma E, Herrera F. Connecting the dots in trustworthy artificial intelligence: from AI principles, ethics, and key requirements to responsible AI systems and regulation. Information Fusion.  Nov 2023;99:101896. [<a target="_blank" href="https://dx.doi.org/10.1016/j.inffus.2023.101896">CrossRef</a>]</span></li><li><span id="ref47">Elliott R, Bohart AC, Watson JC, Murphy D. Therapist empathy and client outcome: an updated meta-analysis. Psychotherapy (Chic).  Dec 2018;55(4):399-410. [<a target="_blank" href="https://dx.doi.org/10.1037/pst0000175">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=30335453&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref48">Elliott R, Watson JC, Goldman RN, Greenberg LS. Learning Emotion-Focused Therapy: The Process-Experiential Approach to Change. American Psychological Association;  2003. </span></li><li><span id="ref49">Montemayor C, Halpern J, Fairweather A. In principle obstacles for empathic AI: why we can&#x2019;t replace human empathy in healthcare. AI &amp; Soc.  Dec 2022;37(4):1353-1359. [<a target="_blank" href="https://dx.doi.org/10.1007/s00146-021-01230-z">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=34054228&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref50">Floridi L. AI as agency without intelligence: on ChatGPT, large language models, and other generative models. Philos Technol.  Mar 2023;36(1):15. [<a target="_blank" href="https://dx.doi.org/10.1007/s13347-023-00621-y">CrossRef</a>]</span></li><li><span id="ref51">Floridi L, Chiriatti M. GPT-3: its nature, scope, limits, and consequences. Minds Mach.  Dec 2020;30(4):681-694. [<a target="_blank" href="https://dx.doi.org/10.1007/s11023-020-09548-1">CrossRef</a>]</span></li><li><span id="ref52">Brandom RB. Reason in Philosophy: Animating Ideas. Belknap Press of Harvard University Press;  2009.  [<a target="_blank" href="https://dx.doi.org/10.4159/9780674053618">CrossRef</a>]</span></li><li><span id="ref53">Ferrario A, Facchini A, Termine A. Experts or authorities? The strange case of the presumed epistemic superiority of artificial intelligence systems. SSRN.  Preprint posted online on  Sep 18, 2023.  [<a target="_blank" href="https://dx.doi.org/10.2139/ssrn.4561425">CrossRef</a>]</span></li><li><span id="ref54">Ferrario A, Biller-Andorno N. Large language models in medical ethics: useful but not expert. J Med Ethics.  Jan 22, 2024:jme-2023-109770. [<a target="_blank" href="https://dx.doi.org/10.1136/jme-2023-109770">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=38253463&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref55">Ferrario A, Termine A, Facchini A. Addressing social misattributions of large language models: an HCXAI-based approach. arXiv.  Preprint posted online on  Mar 26, 2024.  [<a target="_blank" href="https://dx.doi.org/10.48550/arXiv.2403.17873">CrossRef</a>]</span></li><li><span id="ref56">Norcross JC, Lambert MJ. Psychotherapy relationships that work III. Psychotherapy.  Dec 2018;55(4):303-315. [<a target="_blank" href="https://dx.doi.org/10.1037/pst0000193">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=30335448&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref57">DeAngelis T. Better relationships with patients lead to better outcomes. American Psychological Association.   2019.  URL: <a target="_blank" href="https://www.apa.org/monitor/2019/11/ce-corner-relationships">https://www.apa.org/monitor/2019/11/ce-corner-relationships</a> [Accessed 2024-06-19]
                        </span></li><li><span id="ref58">2014 ACA Code of Ethics. American Counseling Association.   2014.  URL: <a target="_blank" href="https://www.counseling.org/docs/default-source/ethics/2014-aca-code-of-ethics.pdf">https://www.counseling.org/docs/default-source/ethics/2014-aca-code-of-ethics.pdf</a> [Accessed 2024-06-19]
                        </span></li><li><span id="ref59">Ethical principles of psychologists and code of conduct. American Psychological Association.   2017.  URL: <a target="_blank" href="https://www.apa.org/ethics/code/">https://www.apa.org/ethics/code/</a> [Accessed 2024-06-19]
                        </span></li><li><span id="ref60">Laacke S. Bias and epistemic injustice in conversational AI. Am J Bioethics.  May 4, 2023;23(5):46-48. [<a target="_blank" href="https://dx.doi.org/10.1080/15265161.2023.2191055">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37130400&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref61">Lin B, Bouneffouf D, Cecchi G, Varshney KR. Towards healthy AI: large language models need therapists too. arXiv.  Preprint posted online on  Apr 2, 2023.  [<a target="_blank" href="https://dx.doi.org/10.48550/arXiv.2304.00416">CrossRef</a>]</span></li><li><span id="ref62">Freiesleben T, Grote T. Beyond generalization: a theory of robustness in machine learning. Synthese.  Sep 27, 2023;202(4):109. [<a target="_blank" href="https://dx.doi.org/10.1007/s11229-023-04334-9">CrossRef</a>]</span></li><li><span id="ref63">Wang J, Hu X, Hou W,  et al. On the robustness of ChatGPT: an adversarial and out-of-distribution perspective. arXiv.  Preprint posted online on  Feb 22, 2023.  [<a target="_blank" href="https://dx.doi.org/10.48550/arXiv.2302.12095">CrossRef</a>]</span></li><li><span id="ref64">Zhuo TY, Huang Y, Chen C, Xing Z. Red teaming ChatGPT via jailbreaking: bias, robustness, reliability and toxicity. arXiv.  Preprint posted online on  Jan 30, 2023.  [<a target="_blank" href="https://dx.doi.org/10.48550/arXiv.2301.12867">CrossRef</a>]</span></li><li><span id="ref65">Hancox-Li L. Robustness in machine learning explanations: does it matter?  Presented at: FAT* &#x2019;20: Conference on Fairness, Accountability, and Transparency; Jan 27 to 30, 2020; Barcelona, Spain. [<a target="_blank" href="https://dx.doi.org/10.1145/3351095.3372836">CrossRef</a>]</span></li><li><span id="ref66">Ferrario A, Loi M. The robustness of counterfactual explanations over time. IEEE Access.  Aug 2022;10:82736-82750. [<a target="_blank" href="https://dx.doi.org/10.1109/ACCESS.2022.3196917">CrossRef</a>]</span></li><li><span id="ref67">Athalye A, Engstrom L, Ilyas A, Kwok K. Synthetizing robust adversarial examples.  Presented at: 35th International Conference on Machine Learning; Jul 10 to 15, 2018; Stockholm, Sweden.</span></li><li><span id="ref68">Sharma S, Henderson J, Ghosh J. CERTIFAI: counterfactual explanations for robustness, transparency, interpretability, and fairness of artificial intelligence models. arXiv.  Preprint posted online on  May 20, 2019.  [<a target="_blank" href="https://dx.doi.org/10.48550/arXiv.1905.07857">CrossRef</a>]</span></li><li><span id="ref69">&#x17D;liobait&#x117; I, Pechenizkiy M, Gama J. An overview of concept drift applications. In: Japkowicz N, Stefanowski J, editors. Big Data Analysis: New Algorithms for a New Society. Springer International Publishing;  2016:91-114. [<a target="_blank" href="https://dx.doi.org/10.1007/978-3-319-26989-4">CrossRef</a>]</span></li><li><span id="ref70">Alvarez-Melis D, Jaakkola TS. On the robustness of interpretability methods. arXiv.  Preprint posted online on  Jun 21, 2018.  [<a target="_blank" href="https://dx.doi.org/10.48550/arXiv.1806.08049">CrossRef</a>]</span></li><li><span id="ref71">Liu P, Yuan W, Fu J, Jiang Z, Hayashi H, Neubig G. Pre-train, prompt, and predict: a systematic survey of prompting methods in natural language processing. ACM Comput Surv.  Sep 30, 2023;55(9):1-35. [<a target="_blank" href="https://dx.doi.org/10.1145/3560815">CrossRef</a>]</span></li><li><span id="ref72">Wei J, Tay Y, Bommasani R,  et al. Emergent abilities of large language models. arXiv.  Preprint posted online on  Jun 15, 2022.  [<a target="_blank" href="https://dx.doi.org/10.48550/arXiv.2206.07682">CrossRef</a>]</span></li><li><span id="ref73">Zhu K, Wang J, Zhou J,  et al. PromptBench: towards evaluating the robustness of large language models on adversarial prompts. arXiv.  Preprint posted online on  Jun 7, 2023.  [<a target="_blank" href="https://dx.doi.org/10.48550/arXiv.2306.04528">CrossRef</a>]</span></li><li><span id="ref74">Tan EJ, Neill E, Kleiner JL, Rossell SL. Depressive symptoms are specifically related to speech pauses in schizophrenia spectrum disorders. Psychiatry Res.  Mar 2023;321:115079. [<a target="_blank" href="https://dx.doi.org/10.1016/j.psychres.2023.115079">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=36716551&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref75">Yang C, Zhang X, Chen Y,  et al. Emotion-dependent language featuring depression. J Behav Ther Exp Psychiatry.  Dec 2023;81:101883. [<a target="_blank" href="https://dx.doi.org/10.1016/j.jbtep.2023.101883">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37290350&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref76">DeSouza DD, Robin J, Gumus M, Yeung A. Natural language processing as an emerging tool to detect late-life depression. Front Psychiatry.  Sep 2021;12:719125. [<a target="_blank" href="https://dx.doi.org/10.3389/fpsyt.2021.719125">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=34552519&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref77">Brockmeyer T, Zimmermann J, Kulessa D,  et al. Me, myself, and I: self-referent word use as an indicator of self-focused attention in relation to depression and anxiety. Front Psychol.  Oct 2015;6:1564. [<a target="_blank" href="https://dx.doi.org/10.3389/fpsyg.2015.01564">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=26500601&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref78">Himmelstein P, Barb S, Finlayson MA, Young KD. Linguistic analysis of the autobiographical memories of individuals with major depressive disorder. PLoS One.  Nov 2018;13(11):e0207814. [<a target="_blank" href="https://dx.doi.org/10.1371/journal.pone.0207814">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=30475918&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref79">Vahia IV, Jeste DV, Reynolds CF. Older adults and the mental health effects of COVID-19. JAMA.  Dec 8, 2020;324(22):2253. [<a target="_blank" href="https://dx.doi.org/10.1001/jama.2020.21753">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=33216114&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref80">Nolen-Hoeksema S. The role of rumination in depressive disorders and mixed anxiety/depressive symptoms. J Abnorm Psychol.   2000;109(3):504-511. [<a target="_blank" href="https://dx.doi.org/10.1037//0021-843X.109.3.504">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=11016119&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref81">Seabrook EM, Kern ML, Fulcher BD, Rickard NS. Predicting depression from language-based emotion dynamics: longitudinal analysis of Facebook and Twitter status updates. J Med Internet Res.  May 8, 2018;20(5):e168. [<a target="_blank" href="https://dx.doi.org/10.2196/jmir.9267">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=29739736&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref82">Zhang T, Schoene AM, Ji S, Ananiadou S. Natural language processing applied to mental illness detection: a narrative review. NPJ Digit Med.  Apr 8, 2022;5(1):46. [<a target="_blank" href="https://dx.doi.org/10.1038/s41746-022-00589-7">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=35396451&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref83">Farhat F. ChatGPT as a complementary mental health resource: a boon or a bane. Ann Biomed Eng.  May 2024;52(5):1111-1114. [<a target="_blank" href="https://dx.doi.org/10.1007/s10439-023-03326-7">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37477707&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref84">NEDA suspends AI chatbot for giving harmful eating disorder advice. Psychiatrist.com.  URL: <a target="_blank" href="https://www.psychiatrist.com/news/neda-suspends-ai-chatbot-for-giving-harmful-eating-disorder-advice/">https:/&#x200B;/www.&#x200B;psychiatrist.com/&#x200B;news/&#x200B;neda-suspends-ai-chatbot-for-giving-harmful-eating-disorder-advice/&#x200B;</a> [Accessed 2023-12-23]
                        </span></li><li><span id="ref85">Walker L. Belgian man dies by suicide following exchanges with chatbot. The Brussels Times.  URL: <a target="_blank" href="https://www.brusselstimes.com/430098/belgian-man-commits-suicide-following-exchanges-with-chatgpt">https://www.brusselstimes.com/430098/belgian-man-commits-suicide-following-exchanges-with-chatgpt</a> [Accessed 2023-12-23]
                        </span></li><li><span id="ref86">Kumar A, Agarwal C, Srinivas S, Li AJ, Feizi S, Lakkaraju H. Certifying LLM safety against adversarial prompting. arXiv.  Preprint posted online on  Sep 6, 2023.  [<a target="_blank" href="https://dx.doi.org/10.48550/arXiv.2309.02705">CrossRef</a>]</span></li><li><span id="ref87">Ploug T, Holm S. The right to refuse diagnostics and treatment planning by artificial intelligence. Med Health Care and Philos.  Mar 2020;23(1):107-114. [<a target="_blank" href="https://dx.doi.org/10.1007/s11019-019-09912-8">CrossRef</a>]</span></li><li><span id="ref88">Loi M, Ferrario A, Vigan&#xF2; E. How much do you trust me? A logico-mathematical analysis of the concept of the intensity of trust. Synthese.  May 23, 2023;201. [<a target="_blank" href="https://dx.doi.org/10.1007/s11229-023-04169-4">CrossRef</a>]</span></li><li><span id="ref89">Wang Q, Madaio M, Kane S, Kapania S, Terry M, Wilcox L. Designing responsible AI: adaptations of UX practice to meet responsible AI challenges.  Presented at: CHI &#x2019;23: 2023 CHI Conference on Human Factors in Computing Systems; Apr 23 to 29, 2023; Hamburg, Germany. URL: <a target="_blank" href="https://dl.acm.org/doi/proceedings/10.1145/3544548">https://dl.acm.org/doi/proceedings/10.1145/3544548</a> [Accessed 2023-11-18]
                         [<a target="_blank" href="https://dx.doi.org/10.1145/3544548.3581278">CrossRef</a>]</span></li><li><span id="ref90">Cheng SW, Chang CW, Chang WJ. The now and future of ChatGPT and GPT in psychiatry. Psychiatry Clin Neurosci.  Nov 2023;77(11):592-596. [<a target="_blank" href="https://dx.doi.org/10.1111/pcn.13588">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37612880&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref91">Janjeva A, Harris A, Mercer S, Kasprzyk A, Gausen A. The rapid rise of generative AI. Centre for Emerging Technology and Security.   2023.  URL: <a target="_blank" href="https://cetas.turing.ac.uk/publications/rapid-rise-generative-ai">https://cetas.turing.ac.uk/publications/rapid-rise-generative-ai</a> [Accessed 2024-06-19]
                        </span></li><li><span id="ref92">Sedlakova J, Westermair AL, Biller-Andorno N, Meier CA, Trachsel M. Comparison of analog and digital patient decision aids for the treatment of depression: a scoping review. Front Digit Health.   2023;5:1208889. [<a target="_blank" href="https://dx.doi.org/10.3389/fdgth.2023.1208889">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37744684&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li><li><span id="ref93">Elwyn G, O&#x2019;Connor A, Stacey D,  et al. Developing a quality criteria framework for patient decision aids: online international Delphi consensus process. BMJ.  Aug 26, 2006;333(7565):417. [<a target="_blank" href="https://dx.doi.org/10.1136/bmj.38926.629329.AE">CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=16908462&amp;dopt=Abstract" target="_blank">Medline</a>]</span></li></ol></div><br><hr><a name="Abbreviations">&#x200E;</a><h4 class="navigation-heading" id="Abbreviations" data-label="Abbreviations">Abbreviations</h4><table width="80%" border="0" align="center"><tr><td><b>AI:</b> artificial intelligence</td></tr><tr><td><b>CAI:</b> conversational artificial intelligence</td></tr><tr><td><b>LLM:</b> large language model</td></tr></table><br><hr><p style="font-style: italic">Edited by  Amir Tal; submitted 19.01.24; peer-reviewed by Ahmed Hassan,  Hannah Burkhardt,  Matteo Malgaroli,  Thomas Hull; final revised version received 27.04.24; accepted 27.04.24; published 02.07.24.</p><a href="https://support.jmir.org/hc/en-us/articles/115002955531" id="Copyright" target="_blank" class="navigation-heading h4 d-block" aria-label="Copyright - what is a Creative Commons License?" data-label="Copyright">Copyright <span class="fas fa-question-circle"></span></a><p class="article-copyright">&#xA9; Andrea Ferrario, Jana Sedlakova, Manuel Trachsel. Originally published in JMIR Mental Health (https://mental.jmir.org), 2.7.2024. </p><small class="article-license"><p class="abstract-paragraph">This is an open-access article distributed under the terms of the Creative Commons Attribution License (<a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">https://creativecommons.org/licenses/by/4.0/</a>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR Mental Health, is properly cited. The complete bibliographic information, a link to the original publication on <a href="https://mental.jmir.org/" target="_blank">https://mental.jmir.org/</a>, as well as this copyright and license information must be included.</p></small><br></section></article></section></section></main>
</div></div></div></div> <aside data-test="sidebar-exists" class="sidebar-citation col-lg-3 mb-5"><!----> <div><h2 class="h4 green-heading-underline width-fit-content">
                        Citation
                    </h2> <p class="fw-bold">
                        Please cite as:
                    </p> <p><span>
                            Ferrario A<span>,</span></span><span>
                            Sedlakova J<span>,</span></span><span>
                            Trachsel M<!----></span> <br> <span>The Role of Humanization and Robustness of Large Language Models in Conversational Artificial Intelligence for Individuals With Depression: A Critical Analysis</span> <br> <span>JMIR Ment Health 2024;11:e56569</span> <br> <span>doi:
                            <span><a aria-label="DOI number 10.2196/56569" data-test="article-doi" target="_blank" href="https://doi.org/10.2196/56569">
                                    10.2196/56569
                                </a></span></span> <span style="display: block">
                            PMID:
                            <span><a data-test="article-pmid" aria-label="PMID 38958218" target="_blank" href="https://www.ncbi.nlm.nih.gov/pubmed/38958218">38958218</a></span></span> <span style="display: block">
                            PMCID:
                            <span><a data-test="article-pmcid" aria-label="PMCID 11231450" target="_blank" href="https://www.ncbi.nlm.nih.gov/pmc/articles/11231450">11231450</a></span></span></p> <button title="Copy Citation" data-test="copy-to-clipboard-button" class="btn btn-small btn-grey"><span aria-hidden="true" class="icon fas fa-paste"></span> Copy Citation to
                        Clipboard
                    </button> <!----></div> <div class="export-metadata"><h2 class="h4 green-heading-underline width-fit-content">
                        Export Metadata
                    </h2> <div><a aria-label="Export metadata in END" target="_blank" data-test="test-end-link" href="https://mental.jmir.org/article/export/end/mental_v11i1e56569" rel="noreferrer">
                            END
                        </a><span> for: Endnote</span></div> <div><a aria-label="Export metadata in BibTeX" target="_blank" data-test="test-bib-link" href="https://mental.jmir.org/article/export/bib/mental_v11i1e56569" rel="noreferrer">
                            BibTeX
                        </a><span> for: BibDesk, LaTeX</span></div> <div><a aria-label="Export metadata in RIS" target="_blank" data-test="test-ris-link" href="https://mental.jmir.org/article/export/ris/mental_v11i1e56569" rel="noreferrer">
                            RIS
                        </a><span>
                            for: RefMan, Procite, Endnote, RefWorks</span></div> <div><a target="_blank" data-test="doi-link" href="http://www.mendeley.com/import/?doi=10.2196/56569">
                            Add this article to your Mendeley library
                        </a></div></div> <div class="collection desktop-show"><h2 tabindex="0" data-test="article-collection" class="h4 green-heading-underline width-fit-content">
                        This paper is in the following
                        <span class="collection__span">e-collection/theme issue:</span></h2> <a href="/themes/1433" data-test="article-collection" aria-label="16 articles belongs to Theme Issue 2023 - 2024 : Responsible Design, Integration, and Use of Generative AI in Mental Health e-collection/theme issue" class="collection__link">
                        Theme Issue 2023 - 2024 : Responsible Design, Integration, and Use of Generative AI in Mental Health (16)
                    </a><a href="/themes/64" data-test="article-collection" aria-label="2145 articles belongs to Digital Mental Health Interventions, e-Mental Health and Cyberpsychology e-collection/theme issue" class="collection__link">
                        Digital Mental Health Interventions, e-Mental Health and Cyberpsychology (2145)
                    </a><a href="/themes/797" data-test="article-collection" aria-label="2162 articles belongs to Artificial Intelligence e-collection/theme issue" class="collection__link">
                        Artificial Intelligence (2162)
                    </a><a href="/themes/624" data-test="article-collection" aria-label="756 articles belongs to Development and Evaluation of Research Methods, Instruments and Tools e-collection/theme issue" class="collection__link">
                        Development and Evaluation of Research Methods, Instruments and Tools (756)
                    </a><a href="/themes/227" data-test="article-collection" aria-label="1703 articles belongs to Depression and Mood Disorders; Suicide Prevention e-collection/theme issue" class="collection__link">
                        Depression and Mood Disorders; Suicide Prevention (1703)
                    </a><a href="/themes/1437" data-test="article-collection" aria-label="725 articles belongs to Generative Language Models Including ChatGPT e-collection/theme issue" class="collection__link">
                        Generative Language Models Including ChatGPT (725)
                    </a><a href="/themes/763" data-test="article-collection" aria-label="748 articles belongs to Chatbots and Conversational Agents e-collection/theme issue" class="collection__link">
                        Chatbots and Conversational Agents (748)
                    </a><a href="/themes/50" data-test="article-collection" aria-label="4050 articles belongs to Web-based and Mobile Health Interventions e-collection/theme issue" class="collection__link">
                        Web-based and Mobile Health Interventions (4050)
                    </a></div> <div><h2 class="h4 green-heading-underline width-fit-content">
                        Download
                    </h2> <div class="download-btns"><a target="_blank" href="https://mental.jmir.org/2024/1/e56569/PDF" aria-label="Download PDF" data-test="pdf-button" class="btn btn-small btn-grey mt-1"><span aria-hidden="true" class="icon fas fa-download"></span> Download PDF</a> <a target="_blank" href="https://mental.jmir.org/2024/1/e56569/XML" aria-label="Download XML" data-test="xml-button" class="btn btn-small btn-grey mt-1"><span aria-hidden="true" class="icon fas fa-download"></span> Download XML</a></div></div> <div><h2 class="h4 green-heading-underline width-fit-content">
                        Share Article
                    </h2> <span class="sm-icons"><a title="share-on-Bluesky" href="https://bsky.app/intent/compose?text=Check%20out%20this%20fascinating%20article%20https%3A%2F%2Fmental.jmir.org%2F2024%2F1%2Fe56569" aria-label="Share this item on Bluesky" data-test="bluesky-button" rel="noreferrer" target="_blank" class="bluesky small"></a> <a title="share-on-Twitter" href="https://twitter.com/intent/tweet?url=Check%20out%20this%20fascinating%20article%20https%3A%2F%2Fmental.jmir.org%2F2024%2F1%2Fe56569" aria-label="Share this item on Twitter" data-test="twitter-button" rel="noreferrer" target="_blank" class="twitter small"></a> <a title="share-on-Facebook" href="https://www.facebook.com/sharer.php?s=100&amp;u=https://mental.jmir.org/2024/1/e56569&amp;quote=Check%20out%20this%20fascinating%20article" aria-label="Share this item on Facebook" data-test="facebook-button" rel="noreferrer" target="_blank" class="facebook small"></a> <a title="Linkedin" href="https://www.linkedin.com/feed?shareActive=true&amp;text=Check%20out%20this%20fascinating%20article%20https%3A%2F%2Fmental.jmir.org%2F2024%2F1%2Fe56569" aria-label="Share this item on Linkedin" data-test="linkedin-button" rel="noreferrer" target="_blank" class="linkedin small"></a></span></div> <div class="ads-sidebar-container"><!----> <!----> <!----></div></aside></div> <!----></div></div></div></div> <div><section data-test="footer" class="footer"><footer id="footer"><div class="container-fluid footer-journal-name"><div class="col-12"><h2 data-test="journal-name">
                        JMIR Mental Health
                        <span>
                            ISSN 2368-7959
                        </span></h2></div></div> <div class="container"><div class="row"><div class="col-lg-3 col-6"><h3 tabindex="0" class="footer-title">
                            Resource Centre
                        </h3> <ul><li data-test="resource-links"><a href="/resource-centre/author-hub">
                                    Author Hub
                                </a></li><li data-test="resource-links"><a href="/resource-centre/editor-hub">
                                    Editor Hub
                                </a></li><li data-test="resource-links"><a href="/resource-centre/reviewer-hub">
                                    Reviewer Hub
                                </a></li><li data-test="resource-links"><a href="/resource-centre/librarian-hub">
                                    Librarian Hub
                                </a></li></ul></div> <div class="col-lg-3 col-6"><h3 tabindex="0" class="footer-title">
                            Browse Journal
                        </h3> <ul><li data-test="journal-links"><a href="/announcements">
                                    Latest Announcements
                                </a></li><li data-test="journal-links"><a href="/search/authors">
                                    Authors
                                </a></li> <li data-test="journal-links"><a href="/themes">
                                    Themes
                                </a></li><li data-test="journal-links"><a href="/issues">
                                    Issues
                                </a></li> <li data-test="journal-links"><a href="https://blog.jmir.org ">
                                    Blog
                                </a></li></ul></div> <div class="col-lg-3 col-6"><h3 tabindex="0" class="footer-title">
                            About
                        </h3> <ul><li data-test="about-links"><a href="/privacy-statement">
                                    Privacy Statement
                                </a></li><li data-test="about-links"><a href="/contact-us">
                                    Contact Us
                                </a></li> <li><a href="/sitemap.xml" target="_blank">
                                    Sitemap
                                </a></li></ul></div> <div class="col-lg-3 col-6"><h3 tabindex="0" class="footer-title">
                            Connect With Us
                        </h3> <span class="sm-icons"><a aria-label="JMIR Publications Bluesky account" title="Bluesky" href="https://bsky.app/profile/jmirpub.bsky.social " target="_blank" rel="noreferrer" data-test="social-links" class="bluesky mr-1"></a><a aria-label="JMIR Publications Tweeter account" title="Twitter" href="https://twitter.com/jmirpub" target="_blank" rel="noreferrer" data-test="social-links" class="twitter mr-1"></a><a aria-label="JMIR Publications Facebook account" title="Facebook" href="https://www.facebook.com/JMedInternetRes" target="_blank" rel="noreferrer" data-test="social-links" class="facebook mr-1"></a><a aria-label="JMIR Publications Linkedin account" title="Linkedin" href="https://www.linkedin.com/company/jmir-publications" target="_blank" rel="noreferrer" data-test="social-links" class="linkedin mr-1"></a><a aria-label="JMIR Publications YouTube account" title="YouTube" href="https://www.youtube.com/c/JMIRPublications" target="_blank" rel="noreferrer" data-test="social-links" class="youtube mr-1"></a><a aria-label="JMIR Publications Instagram account" title="Instagram" href="https://www.instagram.com/jmirpub" target="_blank" rel="noreferrer" data-test="social-links" class="instagram"></a> <a target="_blank" rel="noreferrer" aria-label="RSS Subscription" title="RSS Subscription" href="https://mental.jmir.org/feed/atom" class="rss"></a></span></div> <div class="email-subscribtion-button col-lg-3 col-md-6 col-sm-6 col-12"><h3 tabindex="0" class="footer-title">
                            Get Table of Contents Alerts
                        </h3> <a target="_blank" rel="noopener noreferrer" aria-label="Newsletter Subscription" title="Newsletter Subscription" href="https://landingpage.jmirpublications.com/journal-preference-selection"><span>Get Alerts</span> <span class="icon fas fa-paper-plane"></span></a></div> <div class="col-12 text-center mt-5"><p class="footer-copyright">
                            Copyright ©
                            <time datetime="2025">
                                2025
                            </time>
                            JMIR Publications
                        </p></div></div></div></footer></section></div></div> <div><a tabindex="0" href="javascript:;" title="Scroll to the top of the page" role="button" class="scroll-to-very-top"><span aria-hidden="true" class="icon fas fa-chevron-up"></span></a></div> <!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div></div></div><script>window.__NUXT__=(function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,_,$,aa,ab,ac,ad,ae,af,ag,ah,ai,aj,ak,al,am,an,ao,ap,aq,ar,as,at,au,av,aw,ax,ay,az,aA,aB,aC,aD,aE,aF,aG,aH,aI,aJ,aK,aL,aM,aN,aO,aP,aQ,aR,aS,aT,aU,aV,aW,aX,aY,aZ,a_,a$,ba,bb,bc,bd,be,bf,bg,bh,bi,bj,bk,bl,bm,bn,bo,bp,bq,br,bs,bt,bu,bv){return {layout:"front",data:[{tabs:{html:{name:"Article",route:c,path:"articleHtml"},authors:{name:"Authors",route:"authors",path:"articleAuthors"},citations:{name:"Cited by (21)",route:"citations",path:"articleCitations"},tweetations:{name:"Tweetations (1)",route:"tweetations",path:"articleTweetations"},metrics:{name:"Metrics",route:"metrics",path:"articleMetrics"}},registeredReport:m},{html:"\u003Cmain id=\"wrapper\" class=\"wrapper ArticleMain clearfix\"\u003E\u003Csection class=\"inner-wrapper clearfix\"\u003E\u003Csection class=\"main-article-content clearfix\"\u003E\u003Carticle class=\"ajax-article-content\"\u003E\u003Ch4 class=\"h4-original-paper\"\u003E\u003Cspan class=\"typcn typcn-document-text\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fh4\u003E\u003Cdiv class=\"authors-container\"\u003E\u003Cdiv class=\"authors clearfix\"\u003E\u003Cul class=\"clearfix\"\u003E\u003Cli\u003E\u003Ca href=\"\u002Fsearch\u002FsearchResult?field%5B%5D=author&amp;criteria%5B%5D=Andrea+Ferrario\" class=\"btn-view-author-options\"\u003EAndrea Ferrario\u003Csup\u003E\u003Csmall\u003E1,\u003C\u002Fsmall\u003E\u003C\u002Fsup\u003E\u003Csup\u003E\u003Csmall\u003E2,\u003C\u002Fsmall\u003E\u003C\u002Fsup\u003E\u003Csup\u003E*\u003C\u002Fsup\u003E, PhD\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fli\u003E\u003Cli\u003E\u003Ca href=\"\u002Fsearch\u002FsearchResult?field%5B%5D=author&amp;criteria%5B%5D=Jana+Sedlakova\" class=\"btn-view-author-options\"\u003EJana Sedlakova\u003Csup\u003E\u003Csmall\u003E1,\u003C\u002Fsmall\u003E\u003C\u002Fsup\u003E\u003Csup\u003E\u003Csmall\u003E3,\u003C\u002Fsmall\u003E\u003C\u002Fsup\u003E\u003Csup\u003E\u003Csmall\u003E4,\u003C\u002Fsmall\u003E\u003C\u002Fsup\u003E\u003Csup\u003E*\u003C\u002Fsup\u003E, MA\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fli\u003E\u003Cli\u003E\u003Ca href=\"\u002Fsearch\u002FsearchResult?field%5B%5D=author&amp;criteria%5B%5D=Manuel+Trachsel\" class=\"btn-view-author-options\"\u003EManuel Trachsel\u003Csup\u003E\u003Csmall\u003E5,\u003C\u002Fsmall\u003E\u003C\u002Fsup\u003E\u003Csup\u003E\u003Csmall\u003E6,\u003C\u002Fsmall\u003E\u003C\u002Fsup\u003E\u003Csup\u003E\u003Csmall\u003E7\u003C\u002Fsmall\u003E\u003C\u002Fsup\u003E, MD, PhD\u003C\u002Fa\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cdiv class=\"author-affiliation-details\"\u003E\u003Cp\u003E\u003Csup\u003E1\u003C\u002Fsup\u003EInstitute Biomedical Ethics and History of Medicine, University of Zurich, , Zurich, , Switzerland\u003C\u002Fp\u003E\u003Cp\u003E\u003Csup\u003E2\u003C\u002Fsup\u003EMobiliar Lab for Analytics at ETH, ETH Zurich, , Zurich, , Switzerland\u003C\u002Fp\u003E\u003Cp\u003E\u003Csup\u003E3\u003C\u002Fsup\u003EDigital Society Initiative, University of Zurich, , Zurich, , Switzerland\u003C\u002Fp\u003E\u003Cp\u003E\u003Csup\u003E4\u003C\u002Fsup\u003EInstitute for Implementation Science in Health Care, University of Zurich, , Zurich, , Switzerland\u003C\u002Fp\u003E\u003Cp\u003E\u003Csup\u003E5\u003C\u002Fsup\u003EUniversity of Basel, , Basel, , Switzerland\u003C\u002Fp\u003E\u003Cp\u003E\u003Csup\u003E6\u003C\u002Fsup\u003EUniversity Hospital Basel, , Basel, , Switzerland\u003C\u002Fp\u003E\u003Cp\u003E\u003Csup\u003E7\u003C\u002Fsup\u003EUniversity Psychiatric Clinics Basel, , Basel, , Switzerland\u003C\u002Fp\u003E\u003Cp\u003E*these authors contributed equally\u003C\u002Fp\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003Cdiv class=\"corresponding-author-and-affiliations clearfix\"\u003E\u003Cdiv class=\"corresponding-author-details\"\u003E\u003Ch3\u003ECorresponding Author:\u003C\u002Fh3\u003E\u003Cp\u003EAndrea Ferrario, PhD\u003C\u002Fp\u003E\u003Cp\u003E\u003C\u002Fp\u003E\u003Cbr\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003Cdiv class=\"authors-container\"\u003E\u003Cdiv class=\"authors clearfix\"\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003Cdiv class=\"authors-container\"\u003E\u003Cdiv class=\"authors clearfix\"\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003Csection class=\"article-content clearfix\"\u003E\u003Carticle class=\"abstract\"\u003E\u003Ch3 id=\"Abstract\" class=\"navigation-heading\" data-label=\"Abstract\"\u003EAbstract\u003C\u002Fh3\u003E\u003Cp\u003E\u003Cp class=\"abstract-paragraph\"\u003ELarge language model (LLM)&#x2013;powered services are gaining popularity in various applications due to their exceptional performance in many tasks, such as sentiment analysis and answering questions. Recently, research has been exploring their potential use in digital health contexts, particularly in the mental health domain. However, implementing LLM-enhanced conversational artificial intelligence (CAI) presents significant ethical, technical, and clinical challenges. In this viewpoint paper, we discuss 2 challenges that affect the use of LLM-enhanced CAI for individuals with mental health issues, focusing on the use case of patients with depression: the tendency to humanize LLM-enhanced CAI and their lack of contextualized robustness. Our approach is interdisciplinary, relying on considerations from philosophy, psychology, and computer science. We argue that the humanization of LLM-enhanced CAI hinges on the reflection of what it means to simulate &#x201C;human-like&#x201D; features with LLMs and what role these systems should play in interactions with humans. Further, ensuring the contextualization of the robustness of LLMs requires considering the specificities of language production in individuals with depression, as well as its evolution over time. Finally, we provide a series of recommendations to foster the responsible design and deployment of LLM-enhanced CAI for the therapeutic support of individuals with depression.\u003C\u002Fp\u003E\u003C\u002Fp\u003E\u003Cstrong class=\"h4-article-volume-issue\"\u003EJMIR Ment Health 2024;11:e56569\u003C\u002Fstrong\u003E\u003Cbr\u003E\u003Cbr\u003E\u003Cspan class=\"article-doi\"\u003E\u003Ca href=\"https:\u002F\u002Fdoi.org\u002F10.2196\u002F56569\"\u003Edoi:10.2196\u002F56569\u003C\u002Fa\u003E\u003C\u002Fspan\u003E\u003Cbr\u003E\u003Cbr\u003E\u003Ch3 class=\"h3-main-heading\" id=\"Keywords\"\u003EKeywords\u003C\u002Fh3\u003E\u003Cdiv class=\"keywords\"\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=generative%20AI&amp;precise=true\"\u003Egenerative AI\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=large%20language%20models&amp;precise=true\"\u003Elarge language models\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=large%20language%20model&amp;precise=true\"\u003Elarge language model\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=LLM&amp;precise=true\"\u003ELLM\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=LLMs&amp;precise=true\"\u003ELLMs\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=machine%20learning&amp;precise=true\"\u003Emachine learning\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=ML&amp;precise=true\"\u003EML\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=natural%20language%20processing&amp;precise=true\"\u003Enatural language processing\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=NLP&amp;precise=true\"\u003ENLP\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=deep%20learning&amp;precise=true\"\u003Edeep learning\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=depression&amp;precise=true\"\u003Edepression\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=mental%20health&amp;precise=true\"\u003Emental health\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=mental%20illness&amp;precise=true\"\u003Emental illness\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=mental%20disease&amp;precise=true\"\u003Emental disease\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=mental%20diseases&amp;precise=true\"\u003Emental diseases\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=mental%20illnesses&amp;precise=true\"\u003Emental illnesses\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=artificial%20intelligence&amp;precise=true\"\u003Eartificial intelligence\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=AI&amp;precise=true\"\u003EAI\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=digital%20health&amp;precise=true\"\u003Edigital health\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=digital%20technology&amp;precise=true\"\u003Edigital technology\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=digital%20intervention&amp;precise=true\"\u003Edigital intervention\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=digital%20interventions&amp;precise=true\"\u003Edigital interventions\u003C\u002Fa\u003E;&#xA0;\u003C\u002Fspan\u003E\u003Cspan\u003E\u003Ca href=\"\u002Fsearch?type=keyword&amp;term=ethics&amp;precise=true\"\u003Eethics\u003C\u002Fa\u003E&#xA0;\u003C\u002Fspan\u003E\u003C\u002Fdiv\u003E\u003Cdiv id=\"trendmd-suggestions\"\u003E\u003C\u002Fdiv\u003E\u003C\u002Farticle\u003E\u003Cbr\u003E\u003Carticle class=\"main-article clearfix\"\u003E\u003Cbr\u003E\u003Ch3 class=\"navigation-heading h3-main-heading\" id=\"Introduction\" data-label=\"Introduction\"\u003EIntroduction\u003C\u002Fh3\u003E\u003Ch4\u003EWhat Are Large Language Models?\u003C\u002Fh4\u003E\u003Cp class=\"abstract-paragraph\"\u003ELarge language models (LLMs) are a type of generative artificial intelligence (AI) that displays unprecedented performance in different downstream tasks, such as question answering and, in general, context-aware text generation [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref1\" rel=\"footnote\"\u003E1\u003C\u002Fa\u003E\u003C\u002Fspan\u003E-\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref4\" rel=\"footnote\"\u003E4\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. They produce language using deep neural networks. These models consist of billions of parameters and are trained on huge amounts of data at the expense of notable computational power. LLMs have been recently popularized by services&#x2014;such as OpenAI&#x2019;s ChatGPT-4, Google&#x2019;s BARD (now called &#x201C;Gemini&#x201D;), and Meta&#x2019;s Llama&#x2014;that are currently used by millions of people every day, experts, and laypeople alike. These services are essentially conversational AI (CAI) enhanced with LLMs. They offer a more human-like, natural, and context-relevant interaction than other technological applications such as rule-based conversational agents (ie, traditional &#x201C;chatbots&#x201D;). They hold the potential to transform how we engage in conversations and manage the information therein. Consequently, they are expected to become much more widely adopted in different professional fields, research, and society alike.\u003C\u002Fp\u003E\u003Ch4\u003ELLMs in Health Care and Mental Health Applications\u003C\u002Fh4\u003E\u003Cp class=\"abstract-paragraph\"\u003EIn health care, applications of LLMs are manifold, spanning from clinical research and processes to physician-patient relations [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref5\" rel=\"footnote\"\u003E5\u003C\u002Fa\u003E\u003C\u002Fspan\u003E-\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref10\" rel=\"footnote\"\u003E10\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. For instance, LLMs can improve clinical processes by automating the generation of administrative text [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref1\" rel=\"footnote\"\u003E1\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref5\" rel=\"footnote\"\u003E5\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Physician-patient relations could benefit from the use of LLM-enhanced patient decision aids and interventions that could support therapy and improve shared decision-making [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref1\" rel=\"footnote\"\u003E1\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Context-relevant and personalized conversations with an LLM-enhanced CAI show the potential to promote patients&#x2019; empowerment and individuals&#x2019; reflection around their personal values and preferences for different health care scenarios in a way that is not possible with current methods, for example, filling out legal documents such as advance directives [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref11\" rel=\"footnote\"\u003E11\u003C\u002Fa\u003E\u003C\u002Fspan\u003E-\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref13\" rel=\"footnote\"\u003E13\u003C\u002Fa\u003E\u003C\u002Fspan\u003E].\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EIn the mental health domain, the use of CAI is no novelty. The very first chatbot ELIZA, was developed in 1966, and played the role of a digital psychotherapist [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref14\" rel=\"footnote\"\u003E14\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Six decades later, it is possible to develop and test LLM-enhanced CAI leveraging an ample body of knowledge and use cases. In the mental health domain, CAIs are currently used as patient therapeutic support, for example, a simple psychotherapy, such as cognitive behavioral exercises [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref15\" rel=\"footnote\"\u003E15\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Given their noteworthy ability to process and produce language, the use of LLMs holds the potential to provide more context-aware and effective psychotherapeutic support to their users than traditional CAI. In fact, once embedded in CAI, designers can instruct LLMs to provide a nonjudgmental, readily available platform for vulnerable individuals to discuss their feelings and mental health struggles as well as practice skills that they learned in a therapeutic session.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003ECAI is also used to collect data of patients with mental health disorders, carry out initial triage processes, and provide treatment recommendations [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref6\" rel=\"footnote\"\u003E6\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Here, LLM-enhanced CAI could process written or spoken responses of patients with mental health disorders to support therapists in their diagnostics or track mental health changes in patients over time. They could also generate personalized treatment recommendations by taking an individual&#x2019;s mental health history, their symptoms, values, and care preferences as input. By collecting data on the web, such as social media posts or chat logs, LLMs could help detect signs of emotional distress and detect mental health issues promptly. To this end, preliminary results show that ChatGPT-3.5 achieves good performance at detecting stress and depression in written statements on web-based forums [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref16\" rel=\"footnote\"\u003E16\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. These results suggest that ChatGPT-3.5&#x2013;enhanced CAI could be in the future used in psychotherapeutic scenarios, for example, among patients with depression [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref16\" rel=\"footnote\"\u003E16\u003C\u002Fa\u003E\u003C\u002Fspan\u003E].\u003C\u002Fp\u003E\u003Ch4\u003EEthical, Technical, and Clinical Risks Posed by LLMs\u003C\u002Fh4\u003E\u003Cp class=\"abstract-paragraph\"\u003EEmerging technology, including LLMs, are not immune to risks. They stem from conceptual, ethical, technical, and clinical considerations and become especially important in domains such as mental health care. They comprise ethical issues linked to bias, global digital divide, trustworthiness, black-box nature and validation, and the generalizability challenges in training and deploying LLMs [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref1\" rel=\"footnote\"\u003E1\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref4\" rel=\"footnote\"\u003E4\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref17\" rel=\"footnote\"\u003E17\u003C\u002Fa\u003E\u003C\u002Fspan\u003E].\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EIn addition, authors are addressing different ethical problems associated with the use of LLMs in mental health applications. For instance, Cabrera et al [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref18\" rel=\"footnote\"\u003E18\u003C\u002Fa\u003E\u003C\u002Fspan\u003E] relate these challenges to the 4 principles of biomedical ethics with emphasis on data privacy, confidentiality, avoiding manipulation, and safety. Similarly, Yang et al [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref19\" rel=\"footnote\"\u003E19\u003C\u002Fa\u003E\u003C\u002Fspan\u003E] emphasize the necessity of carefully evaluating LLM-enhanced CAI in mental health applications by advocating the use of explainability methods to make the outcomes of LLMs more transparent. They also suggest complementing the use of LLMs with additional sources of information, such as emotional cues and cause-effect reasoning to enhance the quality of mental health support [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref19\" rel=\"footnote\"\u003E19\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Further, Thirunavukarasu et al [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref1\" rel=\"footnote\"\u003E1\u003C\u002Fa\u003E\u003C\u002Fspan\u003E] emphasized the importance of using domain-specific data to fine-tune LLMs to validate LLM-enhanced applications with real clinical use cases. Finally, research is also investigating these challenges, with a focus on the perspective of end users of these systems, for example, individuals engaged in digitally assisted therapies. To this end, Weidinger et al [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref4\" rel=\"footnote\"\u003E4\u003C\u002Fa\u003E\u003C\u002Fspan\u003E] identify 6 areas of risk and potential harm to users of LLMs, including issues such as discrimination, privacy risks, misinformation, and human-computer interaction challenges [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref4\" rel=\"footnote\"\u003E4\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. In particular, they emphasize the risks for the users of LLM-enhanced services, which stem from their &#x201C;human-like&#x201D; design.\u003C\u002Fp\u003E\u003Ch4\u003EMental Health Use Case: LLM-Enhanced CAI to Support Individuals With Depression\u003C\u002Fh4\u003E\u003Cp class=\"abstract-paragraph\"\u003EIn summary, regarding the use of LLMs, research needs to address a mix of familiar and novel conceptual, ethical, technical, and clinical issues. To improve our understanding of these challenges, we need to examine LLMs within specific domains. This approach becomes particularly pertinent in the mental health domain, where the high sensitivity of the use cases underscores the imperative for a responsible and effective implementation of LLMs in CAI systems that provide therapeutic support to vulnerable individuals.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EIn this work, we focus on the scenario where LLM-enhanced CAI systems are used in the mental health domain to promote therapeutic support focusing on individuals with depression. The rationale behind selecting this use case is as follows. First, depression affects over 300 million people and the World Health Organization identifies it as the largest single contributor to global disability [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref20\" rel=\"footnote\"\u003E20\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. From an economic standpoint, for instance, studies have estimated the economic impact of depression to be 1.6% of the US gross domestic product [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref21\" rel=\"footnote\"\u003E21\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Further, burnout is a major issue among psychiatrists [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref22\" rel=\"footnote\"\u003E22\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Then, it is imperative to integrate technology-mediated interventions alongside traditional therapy methods to enhance accessibility and effectiveness of mental health services. Here, the use of CAI for patients with depression is widespread and supported by an ample body of scientific evidence [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref15\" rel=\"footnote\"\u003E15\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. More recently, research has also started exploring the use of LLMs for addressing depression [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref3\" rel=\"footnote\"\u003E3\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref23\" rel=\"footnote\"\u003E23\u003C\u002Fa\u003E\u003C\u002Fspan\u003E].\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EThis said, it is still an open avenue of research to delineate the perimeter for the responsible use of LLMs in scenarios involving individuals with depression. Therefore, in this work, we contribute to research on the responsible design, integration, and use of generative AI in mental health by focusing on 2 challenges that affect all scenarios where individuals with depression interact with LLM-enhanced CAI. In particular, we address challenges that pertain the (1) humanization of LLM-enhanced CAI (philosophy and psychology) and (2) contextualization of the robustness desideratum (computer science).\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EOur approach is interdisciplinary and relies on theories and methods from philosophy, ethics, psychology, and computer science. Our aim is to conceptually analyze 2 topics that are underexplored in the literature on LLMs and their applications in mental health care despite their importance while highlighting their risks. With our analysis, we provide a critical perspective on the CAI-specific trend of humanizing CAI and the problem of treating the robustness of LLM-based CAI systems as a context-independent challenge. We cross the boundaries of the disciplines to show how our conceptual analysis can be informative for issues in computer science and health research [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref24\" rel=\"footnote\"\u003E24\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. In fact, when properly translated, our conceptual analysis can generate valuable insights in empirical disciplines [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref25\" rel=\"footnote\"\u003E25\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Finally, we discuss recommendations to promote the responsible use of LLM-enhanced CAI in the mental health domain.\u003C\u002Fp\u003E\u003Cbr\u003E\u003Ch3 class=\"navigation-heading h3-main-heading\" id=\"Use-of-LLM-Enhanced-CAIs-by-Individuals-With-Depression-2-Challenges\" data-label=\"Use-of-LLM-Enhanced-CAIs-by-Individuals-With-Depression-2-Challenges\"\u003EUse of LLM-Enhanced CAIs by Individuals With Depression: 2 Challenges\u003C\u002Fh3\u003E\u003Ch4\u003EHumanizing LLM-Enhanced CAI: a Philosophical and Psychological Perspective\u003C\u002Fh4\u003E\u003Cp class=\"abstract-paragraph\"\u003EHumanization is intended to develop CAI with the goal of simulating human abilities and traits, such as humor, empathy, and politeness. It is different from anthropomorphism, which refers to users&#x2019; tendency to attribute CAI with human abilities and traits [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref26\" rel=\"footnote\"\u003E26\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref27\" rel=\"footnote\"\u003E27\u003C\u002Fa\u003E\u003C\u002Fspan\u003E], although the CAI does need to be intentionally designed to mimic humans [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref26\" rel=\"footnote\"\u003E26\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. In practice, humanization of CAI is achieved by developing verbal, nonverbal, visual, and relational cues to make the system more human-like [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref28\" rel=\"footnote\"\u003E28\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref29\" rel=\"footnote\"\u003E29\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. For example, CAI can have a persona (relational cues) that simulates certain human personalities, such as being a friend or therapist. This persona is often implemented in the avatar (visual cues), the informal language (linguistic cues), and emojis (nonverbal cues) used by the CAI. Empirical studies suggest that the humanized abilities and characteristics of CAI, such as reciprocity or giving empathetic responses, has positive outcomes on digital health interactions, such as improved user experience and the formation of relationships with CAI, trust, or better engagement [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref27\" rel=\"footnote\"\u003E27\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref30\" rel=\"footnote\"\u003E30\u003C\u002Fa\u003E\u003C\u002Fspan\u003E-\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref33\" rel=\"footnote\"\u003E33\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. These outcomes are particularly relevant in mental health care applications, where therapeutic relationships with the CAI promote therapeutic effectiveness, and high levels of user engagement might limit drop-outs [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref34\" rel=\"footnote\"\u003E34\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref35\" rel=\"footnote\"\u003E35\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. However, research studies lack consistency in conceptualizing humanization and manipulating different cues [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref26\" rel=\"footnote\"\u003E26\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. In fact, there is no systematic inquiry to understand the extent to which specific cues lead to specific outcomes. More investigations are needed to understand the underlying mechanisms of measured effects (eg, linguistic vs nonlinguistic cues) and assess how these differ on the basis of design choices of humanized CAI.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003ELLMs can simulate context-aware conversations with their users and demonstrate an ability to adopt conversational personas. This allows LLM-enhanced CAI displaying features that strongly resemble human abilities and characteristics to an unprecedented level [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref36\" rel=\"footnote\"\u003E36\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. As noted by Shanahan et al [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref36\" rel=\"footnote\"\u003E36\u003C\u002Fa\u003E\u003C\u002Fspan\u003E], LLMs are fundamentally dialogue agents that role-play an ample variety of human-like characters [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref36\" rel=\"footnote\"\u003E36\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. While there is a generally positive view of humanizing CAI in various domains, we argue for a critical view of humanization efforts. Particularly, the effort of humanizing LLM-enhanced CAI in mental health applications presents serious challenges that must be tackled. Research highlights concerns about the safety of vulnerable users interacting with &#x201C;human-like&#x201D; systems [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref4\" rel=\"footnote\"\u003E4\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. This perspective on humanization emphasizes the potential risks and challenges stemming from the interactions between LLM-enhanced CAI and users, such as individuals with depression. However, there appears to be a lack of theoretical perspectives and clarification on humanization although humanizing concepts are fundamentally rooted in describing and developing AI systems [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref27\" rel=\"footnote\"\u003E27\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref37\" rel=\"footnote\"\u003E37\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. This theoretical clarification could inform the responsible development of these systems, particularly in mental health applications. In what follows, we address this gap by relying on philosophical, ethical, and psychological considerations.\u003C\u002Fp\u003E\u003Ch5\u003EConceptual Considerations\u003C\u002Fh5\u003E\u003Cp class=\"abstract-paragraph\"\u003EFirst, a conceptual problem underlies the development of LLM-enhanced and &#x201C;humanized&#x201D; CAI. We argue that it is important to maintain a distinction between the characteristics and traits simulated by these systems and the human qualities that are referred to using the same concepts and terminology. Simulated abilities and characteristics of LLM-based CAI are not the same as the original human abilities and characteristics. There are fundamental differences between humans and AI that further problematize an uncritical adoption of human concepts in the context of CAI. These problems have been addressed in different research domains. For instance, Bender et al [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref38\" rel=\"footnote\"\u003E38\u003C\u002Fa\u003E\u003C\u002Fspan\u003E] focus on the difference between synthetic language produced by LLM and human natural language by arguing that LLMs are &#x201C;stochastic parrots&#x201D; producing language, but not understanding it. Felin and Holweg [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref39\" rel=\"footnote\"\u003E39\u003C\u002Fa\u003E\u003C\u002Fspan\u003E] similarly argue by reporting differences in human cognition and computation processes of AI. Such arguments are often based on linguistic, philosophical, and psychological knowledge about human cognition, understanding and belief systems that are based on meaning, intentions, theory-based logic, and experience and are embedded in social and normative space [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref39\" rel=\"footnote\"\u003E39\u003C\u002Fa\u003E\u003C\u002Fspan\u003E-\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref43\" rel=\"footnote\"\u003E43\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. In philosophy, the argumentation can stem from the analysis of such concepts as rational and moral agency that are not present in CAI, but are inherent in humans and their activities such as conversations [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref43\" rel=\"footnote\"\u003E43\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Another strategy could be to analyze CAI as a different system from humans and by showing the limits of their models that cannot reach the complexity of human intelligence as reported by Landgrebe and Smith [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref44\" rel=\"footnote\"\u003E44\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. All these considerations have in common the fact that they provide a diversity of arguments for the position that CAI&#x2019;s simulated abilities and characteristics differ from humans [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref45\" rel=\"footnote\"\u003E45\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref46\" rel=\"footnote\"\u003E46\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. In line with this literature, we argue for careful descriptions of CAI when human concepts are used. Such human concepts and terms such as being genuinely &#x201C;empathetic,&#x201D; &#x201C;compassionate,&#x201D; &#x201C;inclusive,&#x201D; &#x201C;polite,&#x201D; or &#x201C;authoritative&#x201D; mean something different when applied to CAI. If possible, CAI should be described more appropriately to avoid misconceptions and conceptual confusion. In the next subsection, we will outline problems and risks that might stem from such misconceptions and conceptual confusion.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EIn mental health literature, we found specific examples criticizing the adoption of human concepts for LLM-enhanced CAI. A good and common example is &#x201C;empathy,&#x201D; which is a key component of psychotherapy [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref47\" rel=\"footnote\"\u003E47\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref48\" rel=\"footnote\"\u003E48\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Recently, researchers investigated the simulation of an LLM-based &#x201C;empathetic therapist&#x201D; with individuals with depression [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref16\" rel=\"footnote\"\u003E16\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. The fact that an LLM-enhanced CAI can generate a seemingly empathetic response is substantially different from a human actually expressing empathy [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref49\" rel=\"footnote\"\u003E49\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. This ability is linked with someone&#x2019;s personality and emotional profile, shared social space, and lived experiences [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref47\" rel=\"footnote\"\u003E47\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. To be empathetic means to achieve genuine \u003Ci\u003Eunderstanding\u003C\u002Fi\u003E of what another person is experiencing or attempting to express. Empathy includes active listening, asking targeted questions, and expressing genuine concern effectively addressing emotional needs [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref47\" rel=\"footnote\"\u003E47\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. These activities lie beyond the capabilities of LLMs, which are disembodied statistical processes. Most importantly, LLMs do not understand users&#x2019; inputs and, in particular, do not understand their semantics [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref50\" rel=\"footnote\"\u003E50\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref51\" rel=\"footnote\"\u003E51\u003C\u002Fa\u003E\u003C\u002Fspan\u003E], despite representing a vast body of information in a neural network.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EHere, understanding (eg, a statement) is a crucial epistemic accomplishment arising from a myriad of complex cognitive activities that result in grasping meaning (eg, of statements and their components) and causal relationships, testing alternative knowledge pathways, on top of providing well-grounded reasons for each of those. Furthermore, understanding emerges as the culmination of intricate processes that are socially and normatively embedded [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref52\" rel=\"footnote\"\u003E52\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. This attainment is fostered by virtues, such as perseverance, precision, and epistemic humility among others. These characterize, in particular, how human experts in a research domain structure knowledge and seek understanding. In contrast, LLMs compute answers through statistical processes that simply do not take into account the meaning of user&#x2019;s prompts [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref39\" rel=\"footnote\"\u003E39\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. As a result, understanding escapes the statistical manipulations that characterize the logic of LLMs [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref53\" rel=\"footnote\"\u003E53\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref54\" rel=\"footnote\"\u003E54\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. In a nutshell, displaying&#x2014;sometimes successful, as LLMs do hallucinate and generate &#x201C;fake&#x201D; references and justifications&#x2014;ability to manipulate structured information does not guarantee understanding.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EVulnerable patients with depression may potentially misinterpret CAI as empathetic and caring, potentially leading to unrealistic expectations such as warmth and acceptance [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref55\" rel=\"footnote\"\u003E55\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Due to CAI&#x2019;s limitations, such misconceptions could reinforce negative beliefs and worsen emotional states. Since LLMs lack understanding of user inputs, they may respond inappropriately, misunderstanding the nuances of individual situations. This could further reinforce negative feelings or isolation in patients with depression. This point is particularly relevant for designers and therapists who need to test the capabilities of LLMs before promoting their use for digital therapy with vulnerable individuals. Differently from current research [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref4\" rel=\"footnote\"\u003E4\u003C\u002Fa\u003E\u003C\u002Fspan\u003E], we emphasize that humanization is at first a challenge for those who design and promote these systems, before becoming a risk for those who use the technology. The key here is to understand that the ability of LLMs to generate empathetic output, as opposed to being apathetic, indifferent, and insensitive in conversations, descends from the computation of empirical probabilities of &#x201C;next words,&#x201D; given the user prompt and their training on a massive amount of documents [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref36\" rel=\"footnote\"\u003E36\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. In fact, under the hood, LLMs perform autocomplete functions of search engines [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref50\" rel=\"footnote\"\u003E50\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. These remarks help in characterizing the limits of the humanization of LLMs and they hold true also for other characteristics and traits that LLMs attempt to simulate. This includes, in particular, the quality of being an &#x201C;expert&#x201D; in a domain, for example, a specialist in the treatment of depression among adolescents, and, in virtue of this, being perceived as a digital therapist, instead of a therapeutic support system [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref53\" rel=\"footnote\"\u003E53\u003C\u002Fa\u003E\u003C\u002Fspan\u003E-\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref55\" rel=\"footnote\"\u003E55\u003C\u002Fa\u003E\u003C\u002Fspan\u003E].\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EIn summary, philosophy and psychology guide us in recognizing the substantive differences between humans and humanized LLM-enhanced CAI. This helps to assess the limits of this endeavor, identify the correct roles these systems can play in interactions with humans, and, eventually mitigate misconceptions and overtrust in these systems [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref4\" rel=\"footnote\"\u003E4\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. The issue of humanization needs more in-depth analysis, including the exploration of how the human attributes assigned to LLM-enhanced CAI influence and guide patients in shaping their behavior and responses within a conversation.\u003C\u002Fp\u003E\u003Ch5\u003ENormative and Ethical Implications of the Conceptual Problem\u003C\u002Fh5\u003E\u003Cp class=\"abstract-paragraph\"\u003EThe conceptual confusion of ascribing human-like abilities to LLM-enhanced CAI is linked with important normative and ethical risks, which pertain to responsibility, commitments, and rights. Overall, interpersonal conversations are social and normative activities that are embedded in a set of values, norms, and virtues [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref42\" rel=\"footnote\"\u003E42\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. This is particularly true in the case of therapeutic relationships that are guided by sets of values and norms to ensure a safe environment and therapeutic process for patients [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref56\" rel=\"footnote\"\u003E56\u003C\u002Fa\u003E\u003C\u002Fspan\u003E-\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref59\" rel=\"footnote\"\u003E59\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Such human abilities as empathy or understanding are part of this normative and professional setting. Psychiatrists and psychotherapists who do not follow professional conduct guidelines when treating individuals with depression risk causing medical emergencies for their patients&#x2014;a situation that could lead to disciplinary actions against them.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EIn the case of humanized LLM-enhanced CAI, there is a gap between what the system appears to be, for example, being compassionate, and what normative criteria this ability should meet and cannot be met by CAI&#x2014;criteria that are fulfilled by human therapists instead. Hence, when CAI simulates abilities such as empathy or understanding, these are not part of the normative setting as they are in the case of human experts. This CAI can lead to risks among individuals with depression. For instance, if an LLM&#x2019;s response lacks compassion during a conversation with a user with depression, this may worsen their condition, even leading to self-harm. An LLM-enhanced CAI may not encode cultural nuances and the uniqueness of individual experiences in its outputs while its biases significantly influence how the system presents and discusses knowledge with patients. This can contribute to &#x201C;epistemic injustice&#x201D; [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref60\" rel=\"footnote\"\u003E60\u003C\u002Fa\u003E\u003C\u002Fspan\u003E], making individuals with depression potentially feel more isolated and their perspectives undervalued and misunderstood. In addition, human experts&#x2014;for instance, psychiatrists&#x2014;have epistemic duties, including being truthful and justifying their beliefs [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref43\" rel=\"footnote\"\u003E43\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. In contrast, LLMs lack these commitments [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref40\" rel=\"footnote\"\u003E40\u003C\u002Fa\u003E\u003C\u002Fspan\u003E].\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EFurther, this &#x201C;normativity gap&#x201D; leads to a problem of assigning responsibility and defining how to approach failures in a conversation with patients. There is a difference between addressing the ethical consequences of technical failures of a computer system, for example, numerical errors and inaccurate predictions, and dealing with the issues that arise from a faulty implementation of humanizing features. On the one hand, technical errors in computer systems are clearly defined, objectively measured, and traced, facilitating the definition of their sanctions. On the other hand, what does it mean that the LLM-enhanced CAI was not empathetic in a given conversation? Was it not empathetic \u003Ci\u003Eenough\u003C\u002Fi\u003E? According to which objective measures of empathy? Did the lack of empathy persist in the conversation long enough to consider applying sanctions? The humanization of LLM-enhanced CAI involves complexities that are not fully understood even in interpersonal interactions, where ambiguous, inappropriate or unprofessional questions and answers may occur, and the applicability of sanctions is unclear.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EIn summary, despite the current trend of humanizing LLM-enhanced CAI, it is questionable to what extent such humanization is necessary and helpful as it poses theoretical and ethical challenges. It remains an open question whether there is an ethically acceptable, safe, and beneficial degree of humanization for these systems. Philosophy and psychology can help frame the problem, which highlights a particularly important gap of the responsible design and development of AI in mental health care [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref61\" rel=\"footnote\"\u003E61\u003C\u002Fa\u003E\u003C\u002Fspan\u003E].\u003C\u002Fp\u003E\u003Ch4\u003EContextualizing the Robustness of LLMs Used by Individuals With Depression: a Computer Science Perspective\u003C\u002Fh4\u003E\u003Ch5\u003EThe Robustness of LLMs\u003C\u002Fh5\u003E\u003Cp class=\"abstract-paragraph\"\u003ERobustness refers to the ability of machine learning models to withstand &#x201C;perturbations&#x201D; that may affect their performance [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref62\" rel=\"footnote\"\u003E62\u003C\u002Fa\u003E\u003C\u002Fspan\u003E-\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref64\" rel=\"footnote\"\u003E64\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. It is a general model capability that becomes essential for ensuring the reliability of machine learning models in real-world applications. Interestingly, robustness is a multidimensional concept that is currently lacking a one-size-fits-all definition. Rather, research discusses what a robust model \u003Ci\u003Eshould do\u003C\u002Fi\u003E [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref62\" rel=\"footnote\"\u003E62\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref65\" rel=\"footnote\"\u003E65\u003C\u002Fa\u003E\u003C\u002Fspan\u003E-\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref68\" rel=\"footnote\"\u003E68\u003C\u002Fa\u003E\u003C\u002Fspan\u003E], investigating how a model should resist different types of perturbations, such as those affecting its input data, data distributions over time, and the model structure. In fact, a robust machine learning model computes predictions that do not vary disproportionately in case of perturbed inputs. Further, it retains accuracy in the presence of distributional shift [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref69\" rel=\"footnote\"\u003E69\u003C\u002Fa\u003E\u003C\u002Fspan\u003E] and is not affected by small changes in its constitutive structure. In summary, robustness is a key requirement for trustworthy AI. It can also be extended to comprise algorithms that provide explanations of machine learning models&#x2019; predictions [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref65\" rel=\"footnote\"\u003E65\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref66\" rel=\"footnote\"\u003E66\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref68\" rel=\"footnote\"\u003E68\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref70\" rel=\"footnote\"\u003E70\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. In this case, robust explanations are not altered by the perturbation of data inputs and are stable over time.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EIn the case of LLMs, the high-level desideratum of robustness seems to gain an extra level of complexity [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref63\" rel=\"footnote\"\u003E63\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref64\" rel=\"footnote\"\u003E64\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. In fact, when discussing what robust LLMs should do, we need to consider the peculiar way these models compute their predictions, namely, using prompt-based queries [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref71\" rel=\"footnote\"\u003E71\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Here, a prompt is structured information&#x2014;often, a text snippet&#x2014;that users offer as an instruction to the LLM and which is often accompanied by one or more examples to guide the model (&#x201C;in-context learning&#x201D; or &#x201C;few-shot prompting&#x201D; procedure) [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref71\" rel=\"footnote\"\u003E71\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref72\" rel=\"footnote\"\u003E72\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. For example, a prompt for an LLM used in an application to investigate how patients with depression communicate with CAI may look like this: &#x201C;Classify the following sentence in either normal or alerting: [s].&#x201D; Here, the example [s] is the patient&#x2019;s utterance: &#x201C;Today, I felt more useless than usual and nobody knows it.&#x201D;\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EBroadly speaking, an LLM is robust if its predictions display an appropriate level of sensitivity to the changes that may affect its prompts and examples. With a robust LLM, similar prompts and examples should lead to similar predictions, among others. This said, research has a long way to go before this promise can become reality. An increasing body of literature shows that commonly available LLMs, for example, T5, Vicuna, Llama 2, and ChatGPT-3.5 [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref73\" rel=\"footnote\"\u003E73\u003C\u002Fa\u003E\u003C\u002Fspan\u003E], generally display a low level of robustness. These models are highly sensitive to different types of perturbations, named &#x201C;prompt-targeting adversarial attacks&#x201D; [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref73\" rel=\"footnote\"\u003E73\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. These comprise switching the order of few-shot examples and semantic-preserving variations, such as adding a few typographical errors, replacing words by synonyms or back translating the prompt itself and its examples [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref73\" rel=\"footnote\"\u003E73\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. As a result, a few empirical studies show that prompt-targeting adversarial attacks can lead to substantially different LLM predictions, indicating an overall lack of robustness across a variety of downstream tasks, such as text classification and generation [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref73\" rel=\"footnote\"\u003E73\u003C\u002Fa\u003E\u003C\u002Fspan\u003E].\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EFinally, from an ethical perspective, the lack of robustness of LLMs is a source of different issues. Nonrobust models lead to unreliable decision-making, that is, they increase the risk of making inconsistent or erroneous decisions that can harm those affected by them. For instance, LLMs could provide misdiagnosis and share information that does not align with clinical practices, show the inability to detect and respond to nuances in language that indicate a mental health crisis (such as expressions of suicidal ideation or severe distress), and offer appropriate and timely crisis intervention resources. Finally, training on large corpora of text may lead LLMs to perpetuate forms of stigmatization against individuals affected by mental health issues (despite fine-tuning on documents from the psychiatry domain).\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EThey may also lead to unwanted cases of bias and discrimination and pose serious concern to the privacy of individuals&#x2019; information. Nonrobust models can be tricked to reveal personal information. Finally, erratic or nonrobust model behavior affects their overall transparency levels. These ethical concerns are particularly relevant in high-stakes scenarios, such as those where LLMs are deployed to support the mental health of vulnerable individuals.\u003C\u002Fp\u003E\u003Ch5\u003EContextualizing the Robustness of LLMs\u003C\u002Fh5\u003E\u003Cp class=\"abstract-paragraph\"\u003ECurrent approaches to ensuring the robustness of LLMs lack proper contextualization: they are not targeted to any specific scenario of human-LLM interaction. While it is beneficial that LLM predictions remain consistent even when prompted in similar ways or when the order of the LLM examples changed, as suggested by the emerging literature on prompt-targeting adversarial attacks [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref73\" rel=\"footnote\"\u003E73\u003C\u002Fa\u003E\u003C\u002Fspan\u003E], this alone is insufficient for the ethically responsible use of LLMs in high-risk applications, such as in scenarios involving mental health support for patients with depression. In these cases, we argue that it is necessary that LLMs&#x2019; robustness is tailored to align with the specific language characteristics&#x2014;and their variations over time&#x2014;of the model users, specifically, patients with depression. In other words, an appropriately robust LLM to be used by individuals with depression should detect their lexical, syntactic, cultural, and content-related language patterns, while retaining the ability of not being affected by more general adversarial attacks [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref73\" rel=\"footnote\"\u003E73\u003C\u002Fa\u003E\u003C\u002Fspan\u003E], as suggested by the high-level desideratum of robustness. In summary, the LLM should provide accurate outputs that are (1) not affected by spurious linguistic variations in the prompts and examples provided by its users and (2) tailored to the context in which the interaction takes place. This calls for the design of prompt-targeting \u003Ci\u003Econtextualized\u003C\u002Fi\u003E adversarial attacks and the assessment of the \u003Ci\u003Econtextualized\u003C\u002Fi\u003E robustness of LLMs, rather than the investigation of general, domain-unspecific robustness constraints.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EResearch on depression has already identified a few linguistic patterns that may help in this regard. On average, patients with depression make more and longer pauses than healthy individuals when they communicate [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref74\" rel=\"footnote\"\u003E74\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Further, they display a lower pitch, more monotonous speech, and slower utterance production [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref75\" rel=\"footnote\"\u003E75\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref76\" rel=\"footnote\"\u003E76\u003C\u002Fa\u003E\u003C\u002Fspan\u003E] (notably, the importance of slowed speech is emphasized in the Patient Health Questionnaire&#x2013;9 self-assessed depression report [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref76\" rel=\"footnote\"\u003E76\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]). Similarly, the analysis of transcripts of utterances of individuals with depression shows that patients with depression use more modifying adverbs, first-person and personal pronouns, and more verbal utterances [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref76\" rel=\"footnote\"\u003E76\u003C\u002Fa\u003E\u003C\u002Fspan\u003E-\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref78\" rel=\"footnote\"\u003E78\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Further, individuals with depression and healthy individuals show differences in the use of past tense, causation, achievement, and death words [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref76\" rel=\"footnote\"\u003E76\u003C\u002Fa\u003E\u003C\u002Fspan\u003E], using simpler sentence structures and reduced linguistic complexity, as well as exhibiting rumination and self-focus in their language [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref79\" rel=\"footnote\"\u003E79\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref80\" rel=\"footnote\"\u003E80\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. The instability of words associated with negative emotion predicts depression in textual production on social media as well [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref81\" rel=\"footnote\"\u003E81\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. We also note that these patterns may vary over time, as the patient may go through different stages of depression. In \u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#figure1\" rel=\"footnote\"\u003EFigure 1\u003C\u002Fa\u003E\u003C\u002Fspan\u003E, we show a few examples of such variations we generated with ChatGPT-4. In summary, robust LLMs to be used for therapy for individuals with depression should be able to correctly identify their linguistic patterns and react to their evolution appropriately. This observation is reinforced by the fact that language is a dynamic process that changes over time. New idioms, metaphors, or shifts in meaning regularly take place, and LLMs need to be aligned with the dynamics of language production. Here, the risk is to promote &#x201C;frozen&#x201D; narratives and linguistic patterns that do not reflect the evolution of patient narratives over time.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EFrom a technical perspective, making LLMs contextually robust requires their fine-tuning them with high-quality, curated data. Currently, obtaining such data for patients with depression is challenging, with most available examples coming from social media platforms such as Twitter or Reddit [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref82\" rel=\"footnote\"\u003E82\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. To the best of our knowledge, there exists no publicly available data set of conversations of patients with depression from consultations with therapists, therapeutic CAI, or other agents in everyday life. Additionally, we cannot easily improve proprietary LLMs. This is a serious problem, as a recent study shows that ChatGPT-3.5 is not robust enough for conversations with individuals with symptoms of anxiety or depression, as the LLMs suggested medications to its users; medications should be taken under the guidance of a psychiatrist [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref83\" rel=\"footnote\"\u003E83\u003C\u002Fa\u003E\u003C\u002Fspan\u003E].\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EIn summary, understanding and achieving the contextualized robustness of LLMs is crucial for the responsible use of LLM-enhanced CAI among individuals with depression. While computer science offers methodologies to formalize, evaluate, and satisfy this requirement, their effectiveness is limited by the availability of necessary resources, primarily therapy-relevant data, which are currently lacking.\u003C\u002Fp\u003E\u003Cfigure\u003E\u003Ca name=\"figure1\"\u003E&#x200E;\u003C\u002Fa\u003E\u003Ca class=\"fancybox\" title=\"Figure 1. Examples of utterances by patients with mild depression and those with severe depression generated by ChatGPT-4 (prompt and answers from December 2023).\" href=\"https:\u002F\u002Fasset.jmir.pub\u002Fassets\u002F97058c61-387f-11ef-81c0-dbce3031f48e.png\" id=\"figure1\"\u003E\u003Cimg class=\"figure-image\" src=\"https:\u002F\u002Fasset.jmir.pub\u002Fassets\u002F97058c61-387f-11ef-81c0-dbce3031f48e.png\"\u003E\u003C\u002Fa\u003E\u003Cfigcaption\u003E\u003Cspan class=\"typcn typcn-image\"\u003E\u003C\u002Fspan\u003E\u003Cb\u003EFigure 1. \u003C\u002Fb\u003E Examples of utterances by patients with mild depression and those with severe depression generated by ChatGPT-4 (prompt and answers from December 2023). \u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003EToward Responsible Use of LLMs in Therapeutic Settings Involving Individuals With Depression\u003C\u002Fh4\u003E\u003Cp class=\"abstract-paragraph\"\u003EThe complexities of humanization and contextualized robustness appear to temper the initial enthusiasm surrounding LLMs. The problems affecting humanization we discussed in the previous sections seem to be at odds with the very essence of LLMs, namely, to role-play different personas. Meanwhile, we noted that achieving contextualized robustness requires thorough fine-tuning and comprehensive testing. Moreover, this process must be grounded in a deep understanding of how language production and usage evolve over time among the users of these systems.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EThe importance of addressing the risks associated with humanization and the absence of contextual robustness is underscored by real-world incidents involving individuals with depression using LLM-enhanced CAI. There have been several instances, reported in various media, where LLM-enhanced CAI provided support for mental health issues but instead encouraged self-harm or offered detrimental advice [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref84\" rel=\"footnote\"\u003E84\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref85\" rel=\"footnote\"\u003E85\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. A Belgian man with depression committed suicide following conversations with ChatGPT-3.5 [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref85\" rel=\"footnote\"\u003E85\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Recently, Kumar et al [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref86\" rel=\"footnote\"\u003E86\u003C\u002Fa\u003E\u003C\u002Fspan\u003E] commented on the case of a user with depression, who, during a crisis, was able to insert a sequence of words in their prompt that bypassed the LLM&#x2019;s safety-guards and generated harmful content [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref86\" rel=\"footnote\"\u003E86\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. In fact, the LLM returned detailed instructions on how to commit different types of self-harm [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref86\" rel=\"footnote\"\u003E86\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Further, authors show that certain prompts result in ChatGPT-3.5 prescribing medications to individuals with anxiety or depression symptoms, despite medications that should be taken under the guidance of a therapist [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref83\" rel=\"footnote\"\u003E83\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. In addition, the vulnerability of LLM-enhanced CAI to attacks and content manipulation can lead to the generation of offensive, inappropriate, or objectionable responses; the provision of incorrect information; and discriminatory recommendations. These events show potential of causing either discomfort, harm, or even acute detriment to users [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref87\" rel=\"footnote\"\u003E87\u003C\u002Fa\u003E\u003C\u002Fspan\u003E].\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EFinally, it is argued that humanization may invite and actively nudge patients to react to its cues [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref4\" rel=\"footnote\"\u003E4\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. LLM-enhanced CAI are persuasive to their users and can perform a variety of emotional manipulations. These may lead to inappropriate reliance on these systems or overtrusting them [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref88\" rel=\"footnote\"\u003E88\u003C\u002Fa\u003E\u003C\u002Fspan\u003E], reinforcing bias, and overestimating their capabilities, including expecting unrealistic behavioral change [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref4\" rel=\"footnote\"\u003E4\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref89\" rel=\"footnote\"\u003E89\u003C\u002Fa\u003E\u003C\u002Fspan\u003E].\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EGiven the challenges discussed in this viewpoint paper, the path toward a responsible development and use of LLM-enhanced CAI in therapeutic settings involving individuals with depression appears to be quite challenging. Here, we agree with Cheng et al [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref90\" rel=\"footnote\"\u003E90\u003C\u002Fa\u003E\u003C\u002Fspan\u003E], who promote the idea of using LLM-enhanced CAI as an assistant to mental health professionals in providing patient care [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref90\" rel=\"footnote\"\u003E90\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. Further, they emphasize the need for routine monitoring of patients and the systems to address emerging challenges in a timely manner [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref90\" rel=\"footnote\"\u003E90\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. However, we disagree with the authors when they suggest that, from an ethical standpoint, psychiatrists should take full responsibility for any detriment to patients interacting with the LLM-enhanced CAI [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref90\" rel=\"footnote\"\u003E90\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. In fact, this claim would be justified if psychiatrists could understand these systems in depth. However, it is unlikely that psychiatrists, despite their expertise in mental health, would possess an in-depth understanding of the workings of such advanced technology.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EIn summary, an interdisciplinary approach to the responsible use of LLM-enhanced CAI in therapeutic settings involving users with depression is essential, encompassing both the social and technological aspects of CAI development and application [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref46\" rel=\"footnote\"\u003E46\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref91\" rel=\"footnote\"\u003E91\u003C\u002Fa\u003E\u003C\u002Fspan\u003E]. This approach should integrate theoretical and practical perspectives from psychiatry, ethics, philosophy, computer science, and user experience design, ensuring a balanced and informed development of these technologies. These perspectives could help address the risks posed by the humanization of these systems and the lack of contextualized robustness, by suggesting ways to inform, instruct, and educate developers and users (including therapists) about the conceptual nuances of normative concepts, such as expertise, and the characteristics of language production of individuals with depression.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EOne practical measure to manage the risks stemming from the humanization of LLM-enhanced CAI could be incorporating disclaimers and a short conversation at the start of therapy sessions with the system. The measures would outline the capabilities and theoretical limitations of CAI, helping users in accurately setting their expectations from the interaction with the systems. Revisiting these disclaimers and conversations periodically, especially in long-term use, could reinforce users&#x2019; understanding and help them manage their expectations effectively over time.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003ETo contextualize the robustness of LLM-enhanced CAI, researchers could collect data from different cohorts of patients with depression interacting with the system in controlled settings. They could augment these data by other sources, including survey data and clinical information to improve the accuracy of the LLMs. Further, identifying contextual features that help LLMs recognize the patients&#x2019; emotional states, triggers, or history can further improve the accuracy and contextual robustness of the models over time. These features may include over time sentiment analysis, trigger recognition, environmental information, and audio and visual cues. Therapists and patients could review these interactions to correct inaccurate suggestions and address the issues they may have caused in a timely manner. This procedure, which necessitates the active involvement of both clinical experts and patients, is undeniably time-consuming but indispensable. Moreover, it hinges on a controlled setting that may not capture all aspects of the interactions between patients with depression and LLM-enhanced CAI in everyday life. However, this is a first step to assess the risk of deploying &#x201C;brittle&#x201D; LLMs in clinical practice.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EFinally, to responsibly use LLM-enhanced CAI with patients with depression, it is important to rigorously examine its long-term effects. Developing and adhering to strict standards for the creation and implementation of these systems is necessary, mirroring the evidence-based approach of mental health care, where interventions undergo thorough testing, including randomized controlled trials. A structured framework, akin to those used in the development and assessment of patient decision-making tools [\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref92\" rel=\"footnote\"\u003E92\u003C\u002Fa\u003E\u003C\u002Fspan\u003E,\u003Cspan class=\"footers\"\u003E\u003Ca class=\"citation-link\" href=\"#ref93\" rel=\"footnote\"\u003E93\u003C\u002Fa\u003E\u003C\u002Fspan\u003E], could greatly benefit the development and application of LLM-enhanced CAI. Guidelines that address the humanization of these systems and ensure their contextual robustness should be central to this framework.\u003C\u002Fp\u003E\u003Ch4\u003EEthical Considerations\u003C\u002Fh4\u003E\u003Cp class=\"abstract-paragraph\"\u003EThis study was exempt from ethical review as no human participants were involved.\u003C\u002Fp\u003E\u003Cbr\u003E\u003Ch3 class=\"navigation-heading h3-main-heading\" id=\"Conclusions\" data-label=\"Conclusions\"\u003EConclusions\u003C\u002Fh3\u003E\u003Cp class=\"abstract-paragraph\"\u003EThe use of LLMs in mental health applications presents numerous conceptual, ethical, technical, and challenges. In this work, we have outlined 2 challenges that impede the responsible use of LLMs in applications involving patients with depression: the accentuation of human-like qualities of LLM-enhanced CAI and the lack of contextualized robustness. These challenges warrant comprehensive consideration and a proactive approach to ensure the responsible and effective integration of LLMs in mental health settings. While human-like qualities may enhance user engagement, it is imperative to strike a balance when a simulation of human characteristics and abilities does not increase ethical risks and their effects are well understood. A responsible approach involves clearly communicating to users that they are interacting with AI-based tools and what this exactly means, enabling them to make informed decisions about the assistance they receive and being aware of their limitations as well as differences from human conversation.\u003C\u002Fp\u003E\u003Cp class=\"abstract-paragraph\"\u003EFurther, LLMs should be adept at understanding and adapting to the specific linguistic, cultural, and emotional nuances of individuals dealing with mental health issues. Robustness, in this context, involves not only maintaining coherence in responses but also sensitively addressing the unique needs of each user. Ethical guidelines should emphasize the development and validation of LLMs with a focus on contextual sensitivity. It is vital to establish a framework that delineates the roles of AI developers, health care providers, and users in ensuring the well-being of those seeking mental health support.\u003C\u002Fp\u003E\u003C\u002Farticle\u003E\u003Ch4 class=\"h4-border-top\"\u003EAuthors' Contributions\u003C\u002Fh4\u003E\u003Cp\u003E\u003Cp class=\"abstract-paragraph\"\u003EAF conceptualized the research. AF and JS wrote the first draft of the manuscript. MT provided inputs on depression and the use of conversational artificial intelligence in therapy for patients with depression. AF and JS finalized the manuscript. All authors approved the final version of the manuscript.\u003C\u002Fp\u003E\u003C\u002Fp\u003E\u003Ch4 class=\"h4-border-top\"\u003EConflicts of Interest\u003C\u002Fh4\u003E\u003Cp\u003E\u003Cp class=\"abstract-paragraph\"\u003ENone declared.\u003C\u002Fp\u003E\u003C\u002Fp\u003E\u003Cdiv class=\"footnotes\"\u003E\u003Ch4 id=\"References\" class=\"h4-border-top navigation-heading\" data-label=\"References\"\u003EReferences\u003C\u002Fh4\u003E\u003Col\u003E\u003Cli\u003E\u003Cspan id=\"ref1\"\u003EThirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW. Large language models in medicine. Nat Med.  Aug 2023;29(8):1930-1940. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1038\u002Fs41591-023-02448-8\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37460753&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref2\"\u003EAyers JW, Poliak A, Dredze M,  et al. Comparing physician and artificial intelligence chatbot responses to patient questions posted to a public social media forum. JAMA Intern Med.  Jun 1, 2023;183(6):589. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1001\u002Fjamainternmed.2023.1838\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37115527&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref3\"\u003EGalatzer-Levy IR, McDuff D, Natarajan V, Karthikesalingam A, Malgaroli M. The capability of large language models to measure psychiatric functioning. arXiv.  Preprint posted online on  Aug 3, 2023.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.48550\u002FarXiv.2308.01834\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref4\"\u003EWeidinger L, Uesato J, Rauh M,  et al. Taxonomy of risks posed by language models.  Presented at: FAccT &#x2019;22: 2022 ACM Conference on Fairness, Accountability, and Transparency; Jun 21 to 24, 2022; Seoul, Republic of Korea. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1145\u002F3531146.3533088\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref5\"\u003EClusmann J, Kolbinger FR, Muti HS,  et al. The future landscape of large language models in medicine. Commun Med.  Oct 10, 2023;3(1):141. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1038\u002Fs43856-023-00370-1\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37816837&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref6\"\u003EMesk&#xF3; B, Topol EJ. The imperative for regulatory oversight of large language models (or generative AI) in healthcare. NPJ Digit Med.  Jul 6, 2023;6(1):120. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1038\u002Fs41746-023-00873-0\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37414860&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref7\"\u003EPeng C, Yang X, Chen A,  et al. A study of generative large language model for medical research and healthcare. NPJ Digit Med.  Nov 16, 2023;6(1):210. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1038\u002Fs41746-023-00958-w\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37973919&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref8\"\u003EYang R, Tan TF, Lu W, Thirunavukarasu AJ, Ting DSW, Liu N. Large language models in health care: development, applications, and challenges. Health Care Science.  Aug 2023;2(4):255-263. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1002\u002Fhcs2.61\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref9\"\u003EHua Y, Liu F, Yang K,  et al. Large language models in mental health care: a scoping review. arXiv.  Preprint posted online on  Jan 1, 2024.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.48550\u002FarXiv.2401.02984\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref10\"\u003EStade EC, Stirman SW, Ungar LH,  et al. Large language models could change the future of behavioral healthcare: a proposal for responsible development and evaluation. Npj Ment Health Res.  Apr 2, 2024;3(1):12. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1038\u002Fs44184-024-00056-z\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=38609507&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref11\"\u003EFerrario A, Gloeckler S, Biller-Andorno N. Ethics of the algorithmic prediction of goal of care preferences: from theory to practice. J Med Ethics.  Mar 2023;49(3):165-174. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1136\u002Fjme-2022-108371\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=36347603&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref12\"\u003EGloeckler S, Ferrario A, Biller-Andorno N. An ethical framework for incorporating digital technology into advance directives: promoting informed advance decision making in healthcare. Yale J Biol Med.  Sep 2022;95(3):349-353. [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=36187419&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref13\"\u003EEarp BD, Porsdam Mann S, Allen J,  et al. A personalized patient preference predictor for substituted judgments in healthcare: technically feasible and ethically desirable. Am J Bioeth.  Jul 2024;24(7):13-26. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1080\u002F15265161.2023.2296402\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=38226965&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref14\"\u003EWeizenbaum J. ELIZA&#x2014;a computer program for the study of natural language communication between man and machine. Commun ACM.  Jan 1966;9(1):36-45. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1145\u002F365153.365168\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref15\"\u003EHe Y, Yang L, Qian C,  et al. Conversational agent interventions for mental health problems: systematic review and meta-analysis of randomized controlled trials. J Med Internet Res.  Apr 28, 2023;25:e43862. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.2196\u002F43862\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37115595&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref16\"\u003EChen S, Wu M, Zhu KQ, Lan K, Zhang Z, Cui L. LLM-empowered chatbots for psychiatrist and patient simulation: application and evaluation. arXiv.  Preprint posted online on  May 23, 2023.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.48550\u002FarXiv.2305.13614\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref17\"\u003ELi H, Moon JT, Purkayastha S, Celi LA, Trivedi H, Gichoya JW. Ethics of large language models in medicine and medical research. Lancet Digit Health.  Jun 2023;5(6):e333-e335. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1016\u002FS2589-7500(23)00083-3\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37120418&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref18\"\u003ECabrera J, Loyola MS, Maga&#xF1;a I, Rojas R. Ethical dilemmas, mental health, artificial intelligence, and LLM-based chatbots. In: Rojas I, Valenzuela O, Rojas Ruiz F, Herrera LJ, Ortu&#xF1;o F, editors. Bioinformatics and Biomedical Engineering. Springer Nature Switzerland;  2023:313-326. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1007\u002F978-3-031-34960-7\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref19\"\u003EYang K, Ji S, Zhang T, Xie Q, Kuang Z, Ananiadou S. Towards interpretable mental health analysis with large language models.  Presented at: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing; Dec 6 to 10, 2023; Singapore. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.18653\u002Fv1\u002F2023.emnlp-main.370\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref20\"\u003EFerrari AJ, Charlson FJ, Norman RE,  et al. The epidemiological modelling of major depressive disorder: application for the Global Burden of Disease Study 2010. PLoS One.  Jul 2013;8(7):e69637. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1371\u002Fjournal.pone.0069637\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=23922765&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref21\"\u003EChodavadia P, Teo I, Poremski D, Fung DSS, Finkelstein EA. Prevalence and economic burden of depression and anxiety symptoms among Singaporean adults: results from a 2022 web panel. BMC Psychiatry.  Feb 14, 2023;23(1):104. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1186\u002Fs12888-023-04581-7\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=36782116&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref22\"\u003EBykov KV, Zrazhevskaya IA, Topka EO,  et al. Prevalence of burnout among psychiatrists: a systematic review and meta-analysis. J Affect Disord.  Jul 2022;308:47-64. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1016\u002Fj.jad.2022.04.005\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=35398112&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref23\"\u003EXu X, Yao B, Dong Y,  et al. Mental-LLM: leveraging large language models for mental health prediction via online text data. arXiv.  Preprint posted online on  Jul 26, 2023.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.48550\u002FarXiv.2307.14385\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref24\"\u003EChoi BCK, Pak AWP. Multidisciplinarity, interdisciplinarity and transdisciplinarity in health research, services, education and policy: 1. Definitions, objectives, and evidence of effectiveness. Clin Invest Med.  Dec 2006;29(6):351-364. [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=17330451&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref25\"\u003EArchibald MM, Lawless MT, de Plaza MAP, Kitson AL. How transdisciplinary research teams learn to do knowledge translation (KT), and how KT in turn impacts transdisciplinary research: a realist evaluation and longitudinal case study. Health Res Policy Syst.  Mar 21, 2023;21(1):20. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1186\u002Fs12961-023-00967-x\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=36944997&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref26\"\u003ENass C, Moon Y. Machines and mindlessness: social responses to computers. J Soc Issues.  Jan 2000;56(1):81-103. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1111\u002F0022-4537.00153\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref27\"\u003ELi M, Suh A. Machinelike or humanlike? A literature review of anthropomorphism in AI-enabled technology.  Presented at: 54th Hawaii International Conference on System Sciences (HICSS 2021); Jan 5, 2021; Kauai, Hawaii. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.24251\u002FHICSS.2021.493\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref28\"\u003EBickmore TW, Picard RW. Establishing and maintaining long-term human-computer relationships. ACM Trans Comput-Hum Interact.  Jun 2005;12(2):293-327. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1145\u002F1067860.1067867\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref29\"\u003ENi&#xDF;en M, R&#xFC;egger D, Stieger M,  et al. The effects of health care chatbot personas with different social roles on the client-chatbot bond and usage intentions: development of a design codebook and web-based study. J Med Internet Res.  Apr 27, 2022;24(4):e32630. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.2196\u002F32630\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=35475761&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref30\"\u003EAraujo T. Living up to the chatbot hype: the influence of anthropomorphic design cues and communicative agency framing on conversational agent and company perceptions. Comput Human Behav.  Aug 2018;85:183-189. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1016\u002Fj.chb.2018.03.051\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref31\"\u003EPereira J, D&#xED;az &#xD3;. Using health chatbots for behavior change: a mapping study. J Med Syst.  Apr 4, 2019;43(5):135. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1007\u002Fs10916-019-1237-1\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=30949846&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref32\"\u003EStara V, Vera B, Bolliger D,  et al. Usability and acceptance of the embodied conversational agent Anne by people with dementia and their caregivers: exploratory study in home environment settings. JMIR Mhealth Uhealth.  Jun 25, 2021;9(6):e25891. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.2196\u002F25891\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=34170256&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref33\"\u003EBeatty C, Malik T, Meheli S, Sinha C. Evaluating the therapeutic alliance with a free-text CBT conversational agent (Wysa): a mixed-methods study. Front Digit Health.  Apr 11, 2022;4:847991. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.3389\u002Ffdgth.2022.847991\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=35480848&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref34\"\u003EArdito RB, Rabellino D. Therapeutic alliance and outcome of psychotherapy: historical excursus, measurements, and prospects for research. Front Psychol.  Oct 18, 2011;2:270. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.3389\u002Ffpsyg.2011.00270\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=22028698&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref35\"\u003ENorcross JC, Lambert MJ, editors. Psychotherapy Relationships That Work: Volume 1: Evidence-Based Therapist Contributions (3 edn). Oxford University Press;  2019.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1093\u002Fmed-psych\u002F9780190843953.001.0001\"\u003ECrossRef\u003C\u002Fa\u003E] ISBN: 978-0-19-084401-1\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref36\"\u003EShanahan M, McDonell K, Reynolds L. Role-play with large language models. Nature.  Nov 2023;623(7987):493-498. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1038\u002Fs41586-023-06647-8\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37938776&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref37\"\u003ESalles A, Evers K, Farisco M. Anthropomorphism in AI. AJOB Neurosci.   2020;11(2):88-95. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1080\u002F21507740.2020.1740350\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=32228388&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref38\"\u003EBendig E, Erb B, Schulze-Thuesing L, Baumeister H. The next generation: chatbots in clinical psychology and psychotherapy to foster mental health &#x2013; a scoping review. Verhaltenstherapie.   2022;32(Suppl. 1):64-76. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1159\u002F000501812\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref39\"\u003EFelin T, Holweg M. Theory is all you need: AI, human cognition, and decision making. SSRN.  Preprint posted online on  Apr 4, 2024.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.2139\u002Fssrn.4737265\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref40\"\u003EBender EM, Gebru T, McMillan-Major A, Shmitchell S. On the dangers of stochastic parrots: can language models be too big?  Presented at: 2021 ACM Conference on Fairness, Accountability, and Transparency Virtual Event; Mar 3 to 10, 2021; Virtual Event Canada. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1145\u002F3442188.3445922\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref41\"\u003EEmsley R. ChatGPT: these are not hallucinations &#x2013; they&#x2019;re fabrications and falsifications. Schizophrenia (Heidelb).  Aug 19, 2023;9(1):52. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1038\u002Fs41537-023-00379-4\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37598184&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref42\"\u003EBrandom R, McDowell J. Knowledge and the social articulation of the space of reasons. Philos Phenomen Res.  Dec 1995;55(4):895. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.2307\u002F2108339\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref43\"\u003ESedlakova J, Trachsel M. Conversational artificial intelligence in psychotherapy: a new therapeutic tool or agent? Am J Bioeth.  May 2023;23(5):4-13. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1080\u002F15265161.2022.2048739\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=35362368&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref44\"\u003ELandgrebe J, Smith B. Why Machines Will Never Rule the World: Artificial Intelligence Without Fear. Routledge;  2022.  URL: \u003Ca target=\"_blank\" href=\"https:\u002F\u002Fwww.taylorfrancis.com\u002Fbooks\u002F9781003310105\"\u003Ehttps:\u002F\u002Fwww.taylorfrancis.com\u002Fbooks\u002F9781003310105\u003C\u002Fa\u003E [Accessed 2024-06-19]\n                         [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.4324\u002F9781003310105\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref45\"\u003EBoyle A. Disagreement &amp; classification in comparative cognitive science. No&#xFB;s.  Oct 16, 2023. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1111\u002Fnous.12480\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref46\"\u003ED&#xED;az-Rodr&#xED;guez N, Del Ser J, Coeckelbergh M, de Prado ML, Herrera-Viedma E, Herrera F. Connecting the dots in trustworthy artificial intelligence: from AI principles, ethics, and key requirements to responsible AI systems and regulation. Information Fusion.  Nov 2023;99:101896. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1016\u002Fj.inffus.2023.101896\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref47\"\u003EElliott R, Bohart AC, Watson JC, Murphy D. Therapist empathy and client outcome: an updated meta-analysis. Psychotherapy (Chic).  Dec 2018;55(4):399-410. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1037\u002Fpst0000175\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=30335453&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref48\"\u003EElliott R, Watson JC, Goldman RN, Greenberg LS. Learning Emotion-Focused Therapy: The Process-Experiential Approach to Change. American Psychological Association;  2003. \u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref49\"\u003EMontemayor C, Halpern J, Fairweather A. In principle obstacles for empathic AI: why we can&#x2019;t replace human empathy in healthcare. AI &amp; Soc.  Dec 2022;37(4):1353-1359. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1007\u002Fs00146-021-01230-z\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=34054228&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref50\"\u003EFloridi L. AI as agency without intelligence: on ChatGPT, large language models, and other generative models. Philos Technol.  Mar 2023;36(1):15. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1007\u002Fs13347-023-00621-y\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref51\"\u003EFloridi L, Chiriatti M. GPT-3: its nature, scope, limits, and consequences. Minds Mach.  Dec 2020;30(4):681-694. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1007\u002Fs11023-020-09548-1\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref52\"\u003EBrandom RB. Reason in Philosophy: Animating Ideas. Belknap Press of Harvard University Press;  2009.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.4159\u002F9780674053618\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref53\"\u003EFerrario A, Facchini A, Termine A. Experts or authorities? The strange case of the presumed epistemic superiority of artificial intelligence systems. SSRN.  Preprint posted online on  Sep 18, 2023.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.2139\u002Fssrn.4561425\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref54\"\u003EFerrario A, Biller-Andorno N. Large language models in medical ethics: useful but not expert. J Med Ethics.  Jan 22, 2024:jme-2023-109770. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1136\u002Fjme-2023-109770\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=38253463&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref55\"\u003EFerrario A, Termine A, Facchini A. Addressing social misattributions of large language models: an HCXAI-based approach. arXiv.  Preprint posted online on  Mar 26, 2024.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.48550\u002FarXiv.2403.17873\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref56\"\u003ENorcross JC, Lambert MJ. Psychotherapy relationships that work III. Psychotherapy.  Dec 2018;55(4):303-315. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1037\u002Fpst0000193\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=30335448&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref57\"\u003EDeAngelis T. Better relationships with patients lead to better outcomes. American Psychological Association.   2019.  URL: \u003Ca target=\"_blank\" href=\"https:\u002F\u002Fwww.apa.org\u002Fmonitor\u002F2019\u002F11\u002Fce-corner-relationships\"\u003Ehttps:\u002F\u002Fwww.apa.org\u002Fmonitor\u002F2019\u002F11\u002Fce-corner-relationships\u003C\u002Fa\u003E [Accessed 2024-06-19]\n                        \u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref58\"\u003E2014 ACA Code of Ethics. American Counseling Association.   2014.  URL: \u003Ca target=\"_blank\" href=\"https:\u002F\u002Fwww.counseling.org\u002Fdocs\u002Fdefault-source\u002Fethics\u002F2014-aca-code-of-ethics.pdf\"\u003Ehttps:\u002F\u002Fwww.counseling.org\u002Fdocs\u002Fdefault-source\u002Fethics\u002F2014-aca-code-of-ethics.pdf\u003C\u002Fa\u003E [Accessed 2024-06-19]\n                        \u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref59\"\u003EEthical principles of psychologists and code of conduct. American Psychological Association.   2017.  URL: \u003Ca target=\"_blank\" href=\"https:\u002F\u002Fwww.apa.org\u002Fethics\u002Fcode\u002F\"\u003Ehttps:\u002F\u002Fwww.apa.org\u002Fethics\u002Fcode\u002F\u003C\u002Fa\u003E [Accessed 2024-06-19]\n                        \u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref60\"\u003ELaacke S. Bias and epistemic injustice in conversational AI. Am J Bioethics.  May 4, 2023;23(5):46-48. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1080\u002F15265161.2023.2191055\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37130400&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref61\"\u003ELin B, Bouneffouf D, Cecchi G, Varshney KR. Towards healthy AI: large language models need therapists too. arXiv.  Preprint posted online on  Apr 2, 2023.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.48550\u002FarXiv.2304.00416\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref62\"\u003EFreiesleben T, Grote T. Beyond generalization: a theory of robustness in machine learning. Synthese.  Sep 27, 2023;202(4):109. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1007\u002Fs11229-023-04334-9\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref63\"\u003EWang J, Hu X, Hou W,  et al. On the robustness of ChatGPT: an adversarial and out-of-distribution perspective. arXiv.  Preprint posted online on  Feb 22, 2023.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.48550\u002FarXiv.2302.12095\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref64\"\u003EZhuo TY, Huang Y, Chen C, Xing Z. Red teaming ChatGPT via jailbreaking: bias, robustness, reliability and toxicity. arXiv.  Preprint posted online on  Jan 30, 2023.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.48550\u002FarXiv.2301.12867\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref65\"\u003EHancox-Li L. Robustness in machine learning explanations: does it matter?  Presented at: FAT* &#x2019;20: Conference on Fairness, Accountability, and Transparency; Jan 27 to 30, 2020; Barcelona, Spain. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1145\u002F3351095.3372836\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref66\"\u003EFerrario A, Loi M. The robustness of counterfactual explanations over time. IEEE Access.  Aug 2022;10:82736-82750. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1109\u002FACCESS.2022.3196917\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref67\"\u003EAthalye A, Engstrom L, Ilyas A, Kwok K. Synthetizing robust adversarial examples.  Presented at: 35th International Conference on Machine Learning; Jul 10 to 15, 2018; Stockholm, Sweden.\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref68\"\u003ESharma S, Henderson J, Ghosh J. CERTIFAI: counterfactual explanations for robustness, transparency, interpretability, and fairness of artificial intelligence models. arXiv.  Preprint posted online on  May 20, 2019.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.48550\u002FarXiv.1905.07857\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref69\"\u003E&#x17D;liobait&#x117; I, Pechenizkiy M, Gama J. An overview of concept drift applications. In: Japkowicz N, Stefanowski J, editors. Big Data Analysis: New Algorithms for a New Society. Springer International Publishing;  2016:91-114. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1007\u002F978-3-319-26989-4\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref70\"\u003EAlvarez-Melis D, Jaakkola TS. On the robustness of interpretability methods. arXiv.  Preprint posted online on  Jun 21, 2018.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.48550\u002FarXiv.1806.08049\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref71\"\u003ELiu P, Yuan W, Fu J, Jiang Z, Hayashi H, Neubig G. Pre-train, prompt, and predict: a systematic survey of prompting methods in natural language processing. ACM Comput Surv.  Sep 30, 2023;55(9):1-35. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1145\u002F3560815\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref72\"\u003EWei J, Tay Y, Bommasani R,  et al. Emergent abilities of large language models. arXiv.  Preprint posted online on  Jun 15, 2022.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.48550\u002FarXiv.2206.07682\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref73\"\u003EZhu K, Wang J, Zhou J,  et al. PromptBench: towards evaluating the robustness of large language models on adversarial prompts. arXiv.  Preprint posted online on  Jun 7, 2023.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.48550\u002FarXiv.2306.04528\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref74\"\u003ETan EJ, Neill E, Kleiner JL, Rossell SL. Depressive symptoms are specifically related to speech pauses in schizophrenia spectrum disorders. Psychiatry Res.  Mar 2023;321:115079. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1016\u002Fj.psychres.2023.115079\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=36716551&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref75\"\u003EYang C, Zhang X, Chen Y,  et al. Emotion-dependent language featuring depression. J Behav Ther Exp Psychiatry.  Dec 2023;81:101883. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1016\u002Fj.jbtep.2023.101883\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37290350&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref76\"\u003EDeSouza DD, Robin J, Gumus M, Yeung A. Natural language processing as an emerging tool to detect late-life depression. Front Psychiatry.  Sep 2021;12:719125. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.3389\u002Ffpsyt.2021.719125\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=34552519&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref77\"\u003EBrockmeyer T, Zimmermann J, Kulessa D,  et al. Me, myself, and I: self-referent word use as an indicator of self-focused attention in relation to depression and anxiety. Front Psychol.  Oct 2015;6:1564. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.3389\u002Ffpsyg.2015.01564\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=26500601&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref78\"\u003EHimmelstein P, Barb S, Finlayson MA, Young KD. Linguistic analysis of the autobiographical memories of individuals with major depressive disorder. PLoS One.  Nov 2018;13(11):e0207814. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1371\u002Fjournal.pone.0207814\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=30475918&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref79\"\u003EVahia IV, Jeste DV, Reynolds CF. Older adults and the mental health effects of COVID-19. JAMA.  Dec 8, 2020;324(22):2253. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1001\u002Fjama.2020.21753\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=33216114&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref80\"\u003ENolen-Hoeksema S. The role of rumination in depressive disorders and mixed anxiety\u002Fdepressive symptoms. J Abnorm Psychol.   2000;109(3):504-511. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1037\u002F\u002F0021-843X.109.3.504\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=11016119&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref81\"\u003ESeabrook EM, Kern ML, Fulcher BD, Rickard NS. Predicting depression from language-based emotion dynamics: longitudinal analysis of Facebook and Twitter status updates. J Med Internet Res.  May 8, 2018;20(5):e168. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.2196\u002Fjmir.9267\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=29739736&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref82\"\u003EZhang T, Schoene AM, Ji S, Ananiadou S. Natural language processing applied to mental illness detection: a narrative review. NPJ Digit Med.  Apr 8, 2022;5(1):46. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1038\u002Fs41746-022-00589-7\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=35396451&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref83\"\u003EFarhat F. ChatGPT as a complementary mental health resource: a boon or a bane. Ann Biomed Eng.  May 2024;52(5):1111-1114. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1007\u002Fs10439-023-03326-7\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37477707&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref84\"\u003ENEDA suspends AI chatbot for giving harmful eating disorder advice. Psychiatrist.com.  URL: \u003Ca target=\"_blank\" href=\"https:\u002F\u002Fwww.psychiatrist.com\u002Fnews\u002Fneda-suspends-ai-chatbot-for-giving-harmful-eating-disorder-advice\u002F\"\u003Ehttps:\u002F&#x200B;\u002Fwww.&#x200B;psychiatrist.com\u002F&#x200B;news\u002F&#x200B;neda-suspends-ai-chatbot-for-giving-harmful-eating-disorder-advice\u002F&#x200B;\u003C\u002Fa\u003E [Accessed 2023-12-23]\n                        \u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref85\"\u003EWalker L. Belgian man dies by suicide following exchanges with chatbot. The Brussels Times.  URL: \u003Ca target=\"_blank\" href=\"https:\u002F\u002Fwww.brusselstimes.com\u002F430098\u002Fbelgian-man-commits-suicide-following-exchanges-with-chatgpt\"\u003Ehttps:\u002F\u002Fwww.brusselstimes.com\u002F430098\u002Fbelgian-man-commits-suicide-following-exchanges-with-chatgpt\u003C\u002Fa\u003E [Accessed 2023-12-23]\n                        \u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref86\"\u003EKumar A, Agarwal C, Srinivas S, Li AJ, Feizi S, Lakkaraju H. Certifying LLM safety against adversarial prompting. arXiv.  Preprint posted online on  Sep 6, 2023.  [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.48550\u002FarXiv.2309.02705\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref87\"\u003EPloug T, Holm S. The right to refuse diagnostics and treatment planning by artificial intelligence. Med Health Care and Philos.  Mar 2020;23(1):107-114. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1007\u002Fs11019-019-09912-8\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref88\"\u003ELoi M, Ferrario A, Vigan&#xF2; E. How much do you trust me? A logico-mathematical analysis of the concept of the intensity of trust. Synthese.  May 23, 2023;201. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1007\u002Fs11229-023-04169-4\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref89\"\u003EWang Q, Madaio M, Kane S, Kapania S, Terry M, Wilcox L. Designing responsible AI: adaptations of UX practice to meet responsible AI challenges.  Presented at: CHI &#x2019;23: 2023 CHI Conference on Human Factors in Computing Systems; Apr 23 to 29, 2023; Hamburg, Germany. URL: \u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002Fproceedings\u002F10.1145\u002F3544548\"\u003Ehttps:\u002F\u002Fdl.acm.org\u002Fdoi\u002Fproceedings\u002F10.1145\u002F3544548\u003C\u002Fa\u003E [Accessed 2023-11-18]\n                         [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1145\u002F3544548.3581278\"\u003ECrossRef\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref90\"\u003ECheng SW, Chang CW, Chang WJ. The now and future of ChatGPT and GPT in psychiatry. Psychiatry Clin Neurosci.  Nov 2023;77(11):592-596. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1111\u002Fpcn.13588\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37612880&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref91\"\u003EJanjeva A, Harris A, Mercer S, Kasprzyk A, Gausen A. The rapid rise of generative AI. Centre for Emerging Technology and Security.   2023.  URL: \u003Ca target=\"_blank\" href=\"https:\u002F\u002Fcetas.turing.ac.uk\u002Fpublications\u002Frapid-rise-generative-ai\"\u003Ehttps:\u002F\u002Fcetas.turing.ac.uk\u002Fpublications\u002Frapid-rise-generative-ai\u003C\u002Fa\u003E [Accessed 2024-06-19]\n                        \u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref92\"\u003ESedlakova J, Westermair AL, Biller-Andorno N, Meier CA, Trachsel M. Comparison of analog and digital patient decision aids for the treatment of depression: a scoping review. Front Digit Health.   2023;5:1208889. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.3389\u002Ffdgth.2023.1208889\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=37744684&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cspan id=\"ref93\"\u003EElwyn G, O&#x2019;Connor A, Stacey D,  et al. Developing a quality criteria framework for patient decision aids: online international Delphi consensus process. BMJ.  Aug 26, 2006;333(7565):417. [\u003Ca target=\"_blank\" href=\"https:\u002F\u002Fdx.doi.org\u002F10.1136\u002Fbmj.38926.629329.AE\"\u003ECrossRef\u003C\u002Fa\u003E] [\u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fentrez\u002Fquery.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=16908462&amp;dopt=Abstract\" target=\"_blank\"\u003EMedline\u003C\u002Fa\u003E]\u003C\u002Fspan\u003E\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003C\u002Fdiv\u003E\u003Cbr\u003E\u003Chr\u003E\u003Ca name=\"Abbreviations\"\u003E&#x200E;\u003C\u002Fa\u003E\u003Ch4 class=\"navigation-heading\" id=\"Abbreviations\" data-label=\"Abbreviations\"\u003EAbbreviations\u003C\u002Fh4\u003E\u003Ctable width=\"80%\" border=\"0\" align=\"center\"\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cb\u003EAI:\u003C\u002Fb\u003E artificial intelligence\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cb\u003ECAI:\u003C\u002Fb\u003E conversational artificial intelligence\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd\u003E\u003Cb\u003ELLM:\u003C\u002Fb\u003E large language model\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003C\u002Ftable\u003E\u003Cbr\u003E\u003Chr\u003E\u003Cp style=\"font-style: italic\"\u003EEdited by  Amir Tal; submitted 19.01.24; peer-reviewed by Ahmed Hassan,  Hannah Burkhardt,  Matteo Malgaroli,  Thomas Hull; final revised version received 27.04.24; accepted 27.04.24; published 02.07.24.\u003C\u002Fp\u003E\u003Ca href=\"https:\u002F\u002Fsupport.jmir.org\u002Fhc\u002Fen-us\u002Farticles\u002F115002955531\" id=\"Copyright\" target=\"_blank\" class=\"navigation-heading h4 d-block\" aria-label=\"Copyright - what is a Creative Commons License?\" data-label=\"Copyright\"\u003ECopyright \u003Cspan class=\"fas fa-question-circle\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cp class=\"article-copyright\"\u003E&#xA9; Andrea Ferrario, Jana Sedlakova, Manuel Trachsel. Originally published in JMIR Mental Health (https:\u002F\u002Fmental.jmir.org), 2.7.2024. \u003C\u002Fp\u003E\u003Csmall class=\"article-license\"\u003E\u003Cp class=\"abstract-paragraph\"\u003EThis is an open-access article distributed under the terms of the Creative Commons Attribution License (\u003Ca href=\"https:\u002F\u002Fcreativecommons.org\u002Flicenses\u002Fby\u002F4.0\u002F\" target=\"_blank\"\u003Ehttps:\u002F\u002Fcreativecommons.org\u002Flicenses\u002Fby\u002F4.0\u002F\u003C\u002Fa\u003E), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR Mental Health, is properly cited. The complete bibliographic information, a link to the original publication on \u003Ca href=\"https:\u002F\u002Fmental.jmir.org\u002F\" target=\"_blank\"\u003Ehttps:\u002F\u002Fmental.jmir.org\u002F\u003C\u002Fa\u003E, as well as this copyright and license information must be included.\u003C\u002Fp\u003E\u003C\u002Fsmall\u003E\u003Cbr\u003E\u003C\u002Fsection\u003E\u003C\u002Farticle\u003E\u003C\u002Fsection\u003E\u003C\u002Fsection\u003E\u003C\u002Fmain\u003E\n"}],fetch:{},error:a,state:{host:a,environment:d,journalPath:n,keys:{},domains:{},screensize:"desktop",currentCookieScriptId:"aa022ba6-b337-11ef-b288-3fb59f57942d",accessibility:{filter:"none","font-weight":"inherit","font-size":.625,"text-align":"initial"},announcements:{data:[{announcement_id:628,title:"Webinar - Enhancing Therapy Engagement Through Digital Tools for Clinicians and Clients",description_short:"\u003Cp\u003EThe Society of Digital Psychiatry, in collaboration with \u003Cem\u003EJMIR Mental Health\u003C\u002Fem\u003E—an open-access, peer-reviewed journal published by JMIR Publications—invites you to a webinar titled “Enhancing Therapy Engagement Through Digital Tools for Clinicians and Clients.”\u003C\u002Fp\u003E",date_posted:"2025-11-11T16:44:02.000Z",journal_id:f},{announcement_id:626,title:"2025 Society of Digital Psychiatry Symposium: Advancing Digital Mental Health Through AI",description_short:"\u003Cp style=\"text-align: left;\"\u003EWe are excited to announce the annual virtual Society of Digital Psychiatry (SODP) Symposium, taking place on December 12, 2025, at 1 PM ET! Join us for an online event dedicated to \"Advancing Digital Mental Health Through AI.\"\u003C\u002Fp\u003E",date_posted:"2025-11-11T11:59:15.000Z",journal_id:f},{announcement_id:618,title:"Webinar - Co-Designing Digital Mental Health with Youth: From Global Principles to Local Platforms",description_short:"\u003Cp\u003EThe Society of Digital Psychiatry in collaboration with \u003Cem\u003EJMIR Mental Health\u003C\u002Fem\u003E, an open access, peer-reviewed journal published by JMIR Publications, invites you to a webinar titled ‘Co-Designing Digital Mental Health with Youth: From Global Principles to Local Platforms’\u003C\u002Fp\u003E\u003Cp\u003E\u003Cbr\u003E\u003C\u002Fp\u003E",date_posted:"2025-10-15T08:40:58.000Z",journal_id:f},{announcement_id:610,title:"SODP Symposium: Live Virtually From Australia Advancing Digital Mental Health: AI, Youth Engagement, and Suicide Prevention",description_short:"\u003Cp\u003EThe \u003Ca href=\"https:\u002F\u002Fwww.sodpsych.com\u002F\" target=\"_blank\"\u003ESociety of Digital Psychiatry\u003C\u002Fa\u003E, in collaboration with \u003Cem\u003EJMIR Mental Health\u003C\u002Fem\u003E, an open access, peer-reviewed journal published by JMIR Publications, invites you to an exclusive symposium-style webinar spotlighting innovative research from leading digital mental health scholars across Australia.\u003C\u002Fp\u003E",date_posted:"2025-08-27T09:56:07.000Z",journal_id:f},{announcement_id:609,title:"Webinar - From Signals to Solutions: Making Digital Phenotyping Clinically Meaningful",description_short:"\u003Cp\u003EThe \u003Ca href=\"https:\u002F\u002Fwww.sodpsych.com\u002F\" target=\"_blank\"\u003ESociety of Digital Psychiatry\u003C\u002Fa\u003E in collaboration with \u003Cem\u003EJMIR Mental Health\u003C\u002Fem\u003E, an open access, peer-reviewed journal published by JMIR Publications, invites you to a webinar titled ‘\u003Ca href=\"https:\u002F\u002Flandingpage.jmirpublications.com\u002Ffrom-signals-to-solutions-making-digital-phenotyping-clinically-meaningful\" target=\"_blank\"\u003EFrom Signals to Solutions: Making Digital Phenotyping Clinically Meaningful\u003C\u002Fa\u003E’.\u003C\u002Fp\u003E",date_posted:"2025-08-13T09:58:51.000Z",journal_id:f},{announcement_id:604,title:"Webinar - Bringing Digital Mental Health to County Services: Challenges and Opportunities",description_short:"\u003Cp\u003EThe \u003Ca href=\"https:\u002F\u002Fwww.sodpsych.com\u002F\" target=\"_blank\"\u003ESociety of Digital Psychiatry\u003C\u002Fa\u003E in collaboration with \u003Cem\u003EJMIR Mental Health\u003C\u002Fem\u003E, an open access, peer-reviewed journal published by JMIR Publications, invites you to a webinar titled ‘\u003Ca href=\"https:\u002F\u002Flandingpage.jmirpublications.com\u002Fbringing-digital-mental-health-to-county-services\" target=\"_blank\"\u003EBringing Digital Mental Health to County Services: Challenges and Opportunities\u003C\u002Fa\u003E’\u003C\u002Fp\u003E",date_posted:"2025-07-15T15:41:13.000Z",journal_id:f},{announcement_id:596,title:"JMIR Mental Health Sees a Rise in Journal Impact Factor in 2025",description_short:"\u003Cp\u003E\u003Cstrong\u003E(Toronto, ON, June 19, 2025)&nbsp;\u003C\u002Fstrong\u003EJMIR Publications is pleased to announce that&nbsp;\u003Cem\u003EJMIR Mental Health\u003C\u002Fem\u003E&nbsp;has received a\u003Cstrong\u003E&nbsp;Journal Impact Factor of 5.8\u003C\u002Fstrong\u003E, as published in Journal Citation Reports 2025 from Clarivate. This represents an increase over last year.&nbsp;\u003Cem\u003EJMIR Mental Health\u003C\u002Fem\u003E&nbsp;ranks in the first quartile (Q1) within the “Psychiatry” category, continuing to rise in rank year-over-year (ranked #25 of 288, 91st percentile).\u003C\u002Fp\u003E",date_posted:"2025-06-18T17:06:04.000Z",journal_id:f},{announcement_id:576,title:"Webinar - From Apps to AI: Rethinking Clinical Tools in Patient Care",description_short:"\u003Cp\u003EThe Society of Digital Psychiatry in collaboration with JMIR Mental Health, an open access, peer-reviewed journal published by JMIR Publications, invites you to a webinar titled ‘\u003Ca href=\"https:\u002F\u002Flandingpage.jmirpublications.com\u002Fsodp-from-apps-to-ai\" target=\"_blank\"\u003EFrom Apps to AI: Rethinking Clinical Tools in Patient Care\u003C\u002Fa\u003E’\u003C\u002Fp\u003E",date_posted:"2025-06-12T09:19:05.000Z",journal_id:f},{announcement_id:568,title:"Webinar - Technology in Eating Disorders Care: Where We Are and What Lies Ahead",description_short:"\u003Cp\u003EThe Society of Digital Psychiatry in collaboration with \u003Cem\u003EJMIR Mental Health\u003C\u002Fem\u003E, an open access, peer-reviewed journal published by JMIR Publications, invites you to a webinar titled ‘\u003Ca href=\"https:\u002F\u002Flandingpage.jmirpublications.com\u002Ftechnology-in-eating-disorders-care-where-we-are-and-what-lies-ahead\" target=\"_blank\"\u003ETechnology in Eating Disorders Care: Where We Are and What Lies Ahead\u003C\u002Fa\u003E’\u003C\u002Fp\u003E",date_posted:"2025-05-15T10:27:30.000Z",journal_id:f},{announcement_id:567,title:"Call for Papers: AI-Powered Therapy Bots and Virtual Companions in Digital Mental Health",description_short:"\u003Cp\u003E\u003Cem\u003EJMIR Mental Health\u003C\u002Fem\u003E invites submissions for a theme issue on \u003Cstrong\u003EAI-Powered Therapy Bots and Virtual Companions\u003C\u002Fstrong\u003E, with a focus on next-generation research that moves beyond proof of concept and addresses the real-world challenges, risks, and opportunities these technologies present in the context of digital psychiatry and mental health.\u003C\u002Fp\u003E",date_posted:"2025-05-08T11:13:51.000Z",journal_id:f}],pagination:{from:b,to:t,total:52,perPage:t,firstPage:b,lastPage:i}},article:{data:{article_id:56569,published_at:"2024-07-02T14:30:11.000Z",submitted_at:ac,section_id:ad,journal_id:f,year:ae,issue:af,volume:B,identifier:"56569",url:ag,pdf_url:"https:\u002F\u002Fmental.jmir.org\u002F2024\u002F1\u002Fe56569\u002FPDF",html_url:"https:\u002F\u002Fmental.jmir.org\u002F2024\u002F1\u002Fe56569",xml_url:"https:\u002F\u002Fmental.jmir.org\u002F2024\u002F1\u002Fe56569\u002FXML",title:ah,public_id:"JMIR Ment Health 2024;11:e56569",thumbnail:"https:\u002F\u002Fasset.jmir.pub\u002Fassets\u002Fc5a135a21a23692e7b6cb5f40e6b9dda.png",doi:"10.2196\u002F56569",pmid:38958218,pmcid:"11231450",issue_title:"Jan-Dec",pages:[],transfer:a,authors:[{first_name:ai,last_name:aj,full_name:ak,degrees:al,deceased:a,orcid:"0000-0001-9968-9474",equal_contrib:b,matchedAffiliations:[b,e]},{first_name:"Jana",last_name:"Sedlakova",full_name:"Jana Sedlakova",degrees:"MA",deceased:a,orcid:"0000-0002-6887-5941",equal_contrib:b,matchedAffiliations:[b,j,o]},{first_name:"Manuel",last_name:"Trachsel",full_name:"Manuel Trachsel",degrees:"MD, PhD",deceased:a,orcid:"0000-0002-2697-3631",equal_contrib:-128,matchedAffiliations:[i,u,p]}],affiliations:[{aff_id:11172037,author_id:am,phone:an,fax:c,corresp_aff:b,aff_type:a,seq:b,article_id:a,institution_line_1:ao,institution_line_2:v,institution_line_3:c,address_line_1:ap,address_line_2:c,city:q,prov_state:a,postal_code:aq,country:h},{aff_id:11191468,author_id:am,phone:a,fax:c,corresp_aff:k,aff_type:a,seq:e,article_id:a,institution_line_1:"Mobiliar Lab for Analytics at ETH",institution_line_2:"ETH Zurich",institution_line_3:c,address_line_1:a,address_line_2:a,city:q,prov_state:a,postal_code:a,country:h},{aff_id:11200920,author_id:ar,phone:a,fax:c,corresp_aff:k,aff_type:a,seq:e,article_id:a,institution_line_1:"Digital Society Initiative",institution_line_2:v,institution_line_3:c,address_line_1:a,address_line_2:a,city:q,prov_state:a,postal_code:a,country:h},{aff_id:11200921,author_id:ar,phone:a,fax:c,corresp_aff:k,aff_type:a,seq:j,article_id:a,institution_line_1:"Institute for Implementation Science in Health Care",institution_line_2:v,institution_line_3:c,address_line_1:a,address_line_2:a,city:q,prov_state:a,postal_code:a,country:h},{aff_id:11172050,author_id:C,phone:a,fax:c,corresp_aff:k,aff_type:a,seq:b,article_id:a,institution_line_1:"University of Basel",institution_line_2:c,institution_line_3:c,address_line_1:a,address_line_2:a,city:D,prov_state:a,postal_code:a,country:h},{aff_id:11172051,author_id:C,phone:a,fax:c,corresp_aff:k,aff_type:a,seq:e,article_id:a,institution_line_1:"University Hospital Basel",institution_line_2:c,institution_line_3:c,address_line_1:a,address_line_2:a,city:D,prov_state:a,postal_code:a,country:h},{aff_id:11172052,author_id:C,phone:a,fax:c,corresp_aff:k,aff_type:a,seq:j,article_id:a,institution_line_1:"University Psychiatric Clinics Basel",institution_line_2:c,institution_line_3:c,address_line_1:a,address_line_2:a,city:D,prov_state:a,postal_code:a,country:h}],primaryAuthor:{first_name:ai,last_name:aj,full_name:ak,email:"andrea.ferrario@ibme.uzh.ch",degrees:al,primaryAffiliation:{fax:c,phone:an,country:h,postal_code:aq,prov_state:a,city:q,address_line_1:ap,address_line_2:c,institution_line_1:ao,institution_line_2:v,institution_line_3:c}},abstract:"Large language model (LLM)-powered services are gaining popularity in various applications due to their exceptional performance in many tasks, such as sentiment analysis and question answering. Recently, research has been exploring their potential use in digital health contexts, particularly in the mental health domain. However, implementing LLM-enhanced conversational artificial intelligence (CAI) presents significant ethical, technical, and clinical challenges. In this work, we discuss two challenges that affect the utilization of LLM-enhanced CAI for individuals with mental health issues, focusing on the use case of depressed patients: the tendency to humanize LLM-enhanced CAI and their lack of contextualized robustness. Our approach is interdisciplinary, relying on considerations from philosophy, psychology, and computer science. We argue that the humanization of LLM-enhanced CAI hinges on the reflection of what it means to simulate “human-like” features with LLMs and what role these systems should have in interactions with humans. Further, to ensure contextualizing robustness of LLMs requires considering the specificities of language production in depressed individuals, as well as its evolution over time. Finally, we provide a series of recommendations to foster the responsible design and deployment of LLM-enhanced CAI for the therapeutic support of individuals with depression.",keywords:"mental health; depression; ethics; digital health; artificial intelligence; machine learning; digital interventions; deep learning; natural language processing; digital technology; mental illness; digital intervention; mental illnesses; large language model; large language models; generative ai; nlp; ai; ml; llm; llms; mental disease; mental diseases",date_submitted:ac,title_html:ah,sections:[{title:"Theme Issue 2023 - 2024 : Responsible Design, Integration, and Use of Generative AI in Mental Health",section_id:ad,journal_id:f,colour:w,count:f},{title:"Digital Mental Health Interventions, e-Mental Health and Cyberpsychology",section_id:64,journal_id:b,colour:l,count:2145},{title:"Artificial Intelligence",section_id:797,journal_id:b,colour:l,count:2162},{title:"Development and Evaluation of Research Methods, Instruments and Tools",section_id:624,journal_id:E,colour:as,count:756},{title:"Depression and Mood Disorders; Suicide Prevention",section_id:at,journal_id:f,colour:w,count:1703},{title:"Generative Language Models Including ChatGPT",section_id:1437,journal_id:b,colour:l,count:725},{title:"Chatbots and Conversational Agents",section_id:763,journal_id:b,colour:l,count:748},{title:"Web-based and Mobile Health Interventions",section_id:50,journal_id:b,colour:l,count:4050}],preprint:g,articleKD:g,isOldOjphiMigrated:m,isNewsArticle:m,isEocArticle:m,articleType:a}},articles:{recent:[],openReview:[]},articleTypes:{},authentication:{data:a,jwt:a},countries:{data:[]},departments:{data:[]},help:{data:{}},journal:{data:{journal_id:f,title:au,tag:av,description:c,path:n,slug:n,seq:p,enabled:b,environment:d,url:aw,batch:b,year:x,colour:w,impact:F,order:o,published:ax,transfers:a,cite_score:ay,settings:{aboutJournal:"\u003Cp style=\"text-align: justify;\"\u003E\u003Cem\u003EJMIR Mental Health \u003C\u002Fem\u003E(JMH, ISSN&nbsp;2368-7959\u003Cem\u003E,&nbsp;\u003C\u002Fem\u003E\u003Ca href=\"..\u002F..\u002F..\u002F..\u002F..\u002Fannouncements\u002F596\" target=\"_blank\"\u003EJournal Impact Factor 5.8,\u003C\u002Fa\u003E&nbsp;Journal Citation Reports 2025 from Clarivate)&nbsp;is a premier, open-access, peer-reviewed journal with a unique focus on digital health and Internet\u002Fmobile interventions, technologies, and electronic innovations (software and hardware) for mental health, addictions, online counseling, and behavior change. The journal publishes research on system descriptions, theoretical frameworks, review papers, viewpoint\u002Fvision papers, and rigorous evaluations that advance evidence-based care, improve accessibility, and enhance the effectiveness of digital mental health solutions. It also explores innovations in digital psychiatry, e-mental health, and clinical informatics in psychiatry and psychology, with an emphasis on improving patient outcomes and expanding access to care.\u003C\u002Fp\u003E\r\n\u003Cp style=\"text-align: justify;\"\u003E\u003Cspan\u003EThe journal is indexed in PubMed Central and PubMed,&nbsp;\u003C\u002Fspan\u003E\u003Ca href=\"..\u002F..\u002F..\u002F..\u002F..\u002Fannouncements\u002F430\"\u003EMEDLINE\u003C\u002Fa\u003E\u003Cspan\u003E,&nbsp;\u003C\u002Fspan\u003E\u003Ca href=\"..\u002F..\u002F..\u002F..\u002F..\u002Fannouncements\u002F201\"\u003EScopus\u003C\u002Fa\u003E\u003Cspan\u003E, Sherpa\u002FRomeo,&nbsp;\u003C\u002Fspan\u003E\u003Ca href=\"..\u002F..\u002F..\u002F..\u002F..\u002Fannouncements\u002F253\"\u003EDOAJ\u003C\u002Fa\u003E\u003Cspan\u003E, EBSCO\u002FEBSCO Essentials, SCIE,&nbsp;\u003C\u002Fspan\u003E\u003Ca href=\"..\u002F..\u002F..\u002F..\u002F..\u002Fannouncements\u002F239\"\u003EPsycINFO\u003C\u002Fa\u003E\u003Cspan\u003E&nbsp;and&nbsp;\u003C\u002Fspan\u003E\u003Ca href=\"..\u002F..\u002F..\u002F..\u002F..\u002Fannouncements\u002F289\"\u003ECABI\u003C\u002Fa\u003E\u003Cspan\u003E.\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\r\n\u003Cp style=\"text-align: justify;\" data-pm-slice=\"1 1 []\"\u003E\u003Cem\u003EJMIR Mental Health&nbsp;\u003C\u002Fem\u003Ereceived a \u003Ca href=\"..\u002F..\u002F..\u002F..\u002F..\u002Fannouncements\u002F596\" target=\"_blank\"\u003EJournal Impact Factor of 5.8&nbsp;\u003C\u002Fa\u003E(\u003Cspan\u003Eranked&nbsp;\u003C\u002Fspan\u003E\u003Cspan\u003EQ1&nbsp;\u003C\u002Fspan\u003E\u003Cspan\u003E#25\u002F288 journals in the category Psychiatry,&nbsp;\u003C\u002Fspan\u003EJournal Citation Reports 2025 from Clarivate).\u003C\u002Fp\u003E\r\n\u003Cp style=\"text-align: justify;\" data-pm-slice=\"1 1 []\"\u003E\u003Cem\u003EJMIR Mental Health&nbsp;\u003C\u002Fem\u003Ereceived a Scopus&nbsp;CiteScore of \u003Ca href=\"https:\u002F\u002Fwww.jmir.org\u002Fannouncements\u002F572\"\u003E10.2\u003C\u002Fa\u003E&nbsp;(2024), placing it in the 93rd percentile (#35 of 580) as a Q1 journal in the field of Psychiatry and Mental Health.\u003C\u002Fp\u003E",announcementLink:"https:\u002F\u002Fmental.jmir.org\u002Fannouncements\u002F596",copyrightNotice:"Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http:\u002F\u002Fcreativecommons.org\u002Flicenses\u002Fby\u002F2.0\u002F), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work (\"first published in the Journal of Medical Internet Research...\") is properly cited with original URL and bibliographic citation information. The complete bibliographic information, a link to the original publication on http:\u002F\u002Fwww.jmir.org\u002F, as well as this copyright and license information must be included.",focusScopeDesc:"\u003Cp style=\"text-align: justify;\"\u003E\u003Cem\u003EJMIR Mental Health (\u003C\u002Fem\u003E\u003Ca href=\"..\u002F..\u002Fannouncements\u002F478\"\u003EImpact Factor 4.8\u003C\u002Fa\u003E, Editor-in-Chief: John Torous, MD, MBI) is a premier, open-access, peer-reviewed journal indexed in PubMed Central and PubMed, \u003Ca href=\"..\u002F..\u002Fannouncements\u002F430\"\u003EMEDLINE\u003C\u002Fa\u003E, \u003Ca href=\"..\u002F..\u002Fannouncements\u002F201\"\u003EScopus\u003C\u002Fa\u003E, Sherpa\u002FRomeo, \u003Ca href=\"..\u002F..\u002Fannouncements\u002F253\"\u003EDOAJ\u003C\u002Fa\u003E, EBSCO\u002FEBSCO Essentials, SCIE, \u003Ca href=\"..\u002F..\u002Fannouncements\u002F239\"\u003EPsycINFO\u003C\u002Fa\u003E and \u003Ca href=\"..\u002F..\u002Fannouncements\u002F289\"\u003ECABI\u003C\u002Fa\u003E. \u003Cem\u003E\u003C\u002Fem\u003E\u003C\u002Fp\u003E\r\n\u003Cp style=\"text-align: justify;\"\u003EJMIR Mental Health has a unique focus on digital health and internet\u002Fmobile interventions, technologies, and electronic innovations (software and hardware) for mental health, addictions, online counseling, and behavior change. The journal publishes research on system descriptions, theoretical frameworks, review papers, viewpoint\u002Fvision papers, and rigorous evaluations that advance evidence-based care, improve accessibility, and enhance the effectiveness of digital mental health solutions. It also explores innovations in digital psychiatry, e-mental health, and clinical informatics in psychiatry and psychology, with an emphasis on improving patient outcomes and expanding access to care.\u003C\u002Fp\u003E\r\n\u003Cp style=\"text-align: justify;\"\u003E\u003Ca href=\"..\u002F..\u002Fthemes\" target=\"_blank\" rel=\"noopener\"\u003EThe main themes\u002Ftopics covered by this journal can be found here.\u003C\u002Fa\u003E\u003C\u002Fp\u003E\r\n\u003Cp style=\"text-align: justify;\"\u003E\u003Ci\u003EJMIR Mental Health&nbsp;\u003C\u002Fi\u003Ehas an international author and readership and welcomes submissions from around the world.\u003C\u002Fp\u003E\r\n\u003Cp style=\"text-align: justify;\"\u003E\u003C\u002Fp\u003E",googleAnalyticsId:"UA-186918-17",impactFactor:F,journalDescription:"\u003Cp\u003EInternet interventions, technologies, and digital innovations for mental health and behavior change.\u003C\u002Fp\u003E\r\n\u003Cp\u003E\u003Cem\u003EJMIR Mental Health\u003C\u002Fem\u003E is the \u003Ca href=\"..\u002F..\u002Fannouncements\u002F366\"\u003Eofficial journal\u003C\u002Fa\u003E of the \u003Cem\u003E\u003Ca href=\"https:\u002F\u002Fwww.sodpsych.org\u002F\"\u003ESociety of Digital Psychiatry\u003C\u002Fa\u003E.&nbsp;\u003C\u002Fem\u003E\u003C\u002Fp\u003E",journalInitials:"JMH",footer:"\u003Cdiv\u003E\r\n\u003Cul style=\"display: flex; flex-wrap: wrap; list-style: none; justify-content: center;\"\u003E\r\n\u003Cli style=\"margin: 10px;\"\u003E\u003Ca href=\"http:\u002F\u002Fsearch.crossref.org\u002F?q=2368-7959\" target=\"_blank\" rel=\"noopener\"\u003E\u003Cimg src=\"https:\u002F\u002Fasset.jmir.pub\u002Fresources\u002Fimages\u002Fpartners\u002Fcrossref.jpg\" alt=\"Crossref\" \u002F\u003E\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli style=\"margin: 10px;\"\u003E\u003Cimg src=\"https:\u002F\u002Fasset.jmir.pub\u002Fresources\u002Fimages\u002Fpartners\u002Fopen-access.jpg\" alt=\"Open Access\" \u002F\u003E\u003C\u002Fli\u003E\r\n\u003Cli style=\"margin: 10px;\"\u003E\u003Ca href=\"https:\u002F\u002Foaspa.org\u002Fmember-record-jmir-publications-inc\" target=\"_blank\" rel=\"noopener\"\u003E\u003Cimg src=\"https:\u002F\u002Fasset.jmir.pub\u002Fresources\u002Fimages\u002Fpartners\u002Foaspa.jpg\" alt=\"Open Access Scholarly Publishers Association\" \u002F\u003E\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli style=\"margin: 10px;\"\u003E\u003Ca href=\"https:\u002F\u002Fwww.trendmd.com\" target=\"_blank\" rel=\"noopener\"\u003E\u003Cimg src=\"https:\u002F\u002Fasset.jmir.pub\u002Fresources\u002Fimages\u002Fpartners\u002Ftrend-MD.jpg\" alt=\"TrendMD Member\" \u002F\u003E\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli style=\"margin: 10px;\"\u003E\u003Ca href=\"https:\u002F\u002Forcid.org\" target=\"_blank\" rel=\"noopener\"\u003E\u003Cimg src=\"https:\u002F\u002Fasset.jmir.pub\u002Fresources\u002Fimages\u002Fpartners\u002FORCID.jpg\" alt=\"ORCID Member\" \u002F\u003E\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli style=\"margin: 10px;\"\u003E\u003Ca href=\"https:\u002F\u002Fdoaj.org\u002Ftoc\u002F2368-7959\" target=\"_blank\" rel=\"noopener\"\u003E\u003Cimg src=\"https:\u002F\u002Fasset.jmir.pub\u002Fresources\u002Fimages\u002Fpartners\u002FDOAJ.jpg\" alt=\"Directory of Open Access Journals\" \u002F\u003E\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli style=\"margin: 10px;\"\u003E\u003Ca href=\"https:\u002F\u002Fdoaj.org\u002Ftoc\u002F2368-7959\" target=\"_blank\" rel=\"noopener\"\u003E\u003Cimg src=\"https:\u002F\u002Fasset.jmir.pub\u002Fresources\u002Fimages\u002Fpartners\u002Fdoaj_seal_logo_medium.png\" alt=\"DOAJ Seal\" \u002F\u003E\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003Cli style=\"margin: 10px;\"\u003E\u003Ca href=\"https:\u002F\u002Fwww.cabdirect.org\u002Fglobalhealth\" target=\"_blank\" rel=\"noopener\"\u003E\u003Cimg src=\"https:\u002F\u002Fasset.jmir.pub\u002Fresources\u002Fimages\u002Fpartners\u002FCABILogo.png\" alt=\"CABI\" \u002F\u003E\u003C\u002Fa\u003E\u003C\u002Fli\u003E\r\n\u003C\u002Ful\u003E\r\n\u003C\u002Fdiv\u003E",onlineIssn:"2368-7959",searchDescription:"Journal of Medical Internet Research - International Scientific Journal for Medical Research, Information and Communication on the Internet",searchKeywords:"Medical, Medicine, Internet, Research, Journal, ehealth, JMIR,open access publishing, medical research, mental health, addictions, behavior change, digital health",submissionChecklist:[{order:af,content:"\u003Cp\u003EThe submission has not been previously published nor is it before another journal for consideration; or an explanation has been provided in Comments to the Editor. Related\u002Foverlapping published or submitted work will be uploaded as supplementary files so reviewers and editors can determine the degree of overlap with previous\u002Fother papers under consideration. Salami slicing of research is discouraged.\u003C\u002Fp\u003E"},{order:az,content:"\u003Cp\u003EThe submission file is in Microsoft Word (.doc\u002F.docx) file format.\u003C\u002Fp\u003E"},{order:"3",content:"\u003Cp\u003EThe text meets this journal's formatting requirements, in particular those summarized in the \u003Ca href=\"http:\u002F\u002Fwww.jmir.org?Instructions_for_Authors:Instructions_for_Authors_of_JMIR#checklist\" target=\"_blank\"\u003EAuthor Checklist\u003C\u002Fa\u003E found in Instructions for Authors. The text employs \u003Cem\u003Eitalics\u003C\u002Fem\u003E, rather than \u003Cspan style=\"text-decoration: underline;\"\u003Eunderlining\u003C\u002Fspan\u003E or bold as emphasis; with figures and tables (portrait only, no landscape format) placed within the text, rather than at the end. Additional information has been put in separate files to be uploaded as Multimedia Appendix.\u003C\u002Fp\u003E"},{order:"5",content:"\u003Cp\u003EI have read and understood the \u003Ca href=\"..\u002F..\u002F\u002F?Instructions_for_Authors:Instructions_for_Authors_of_JMIR#Open_Access\" target=\"instr\"\u003Efee schedule\u003C\u002Fa\u003E. In particular, I understand and agree that unless my department\u002Forganization is a \u003Ca href=\"..\u002F..\u002Fsupport.htm\" target=\"member\"\u003Einstitutional member\u003C\u002Fa\u003E BEFORE submission (see dropdown-list in step 1 of the submission process), I\u002Fmy department will be billed for the article processing fee (see Instructions for authors) in case of acceptance. PLEASE MENTION IN THE COVER LETTER ON SUBMISSION THAT YOU 1) AGREE TO PAY THE APF, OR 2) IF YOU THINK THAT THE APF SHOULD BE WAIVED DUE TO MEMBERSHIP OR FOR ANY OTHER REASONS. Journal sections marked with * may be eligible for a fee waiver or reduction under certain circumstances (must be justified in the comments field for the editor on submission). APFs may not apply for article categories marked with * (check instructions for authors). ** Special fees (in particular a submission fee) apply for \u003Ca href=\"..\u002F..\u002F\u002F?Instructions_for_Authors:Protocol_review\"\u003Eresearch protocols and grant proposals\u003C\u002Fa\u003E. Note that the APF will also be billed if the author retracts the manuscript after acceptance, or if a case of scientific misconduct prevents us from publishing a manuscript after acceptance.&nbsp;\u003C\u002Fp\u003E\r\n\u003Cp\u003EPlease note the price increase for JMIR in July 2015.\u003C\u002Fp\u003E"},{order:"6",content:"\u003Cp\u003EAll cited webreferences (webpages, online available PDF reports) which are NOT journal articles or which do not have a DOI have been cached using WebCite (\u003Ca href=\"http:\u002F\u002Fwww.webcitation.org\"\u003Ewww.webcitation.org\u003C\u002Fa\u003E) . Instead of citing the \"live\" webpage\u002Fwebsite, the author should cite the WebCite archived webpage. No URLs in the body of the manuscript are allowed - all URLs are cited as references.\u003C\u002Fp\u003E"},{order:"8",content:"\u003Cp\u003E(please check this checkbox even if you do not wish to fast-track as an indication that you read this). I understand that if I wish to fast-track the paper, I will pay the Fast-Track-Fee immediately after submission (a payment link will be provided after submission) or at a later stage. The FTF guarantees an editorial decision within 15 working days (see website for further instructions)\u003C\u002Fp\u003E"},{order:"9",content:"\u003Cp\u003EI understand that all author names and their affiliations for the final publication will be taken from the database (metadata form), not the submitted manuscript, thus all author names must be entered in the metadata form during submission. Authors may remove author names from the manuscript if they prefer blind review. All coauthors have been\u002Fwill be entered in the metadata form, and all coauthors fulfill ICMJE criteria in that they made 1) substantial contributions to conception and design, or acquisition of data, or analysis and interpretation of data; 2) drafting the article or revising it critically for important intellectual content; and 3) final approval of the version to be published. Authors should meet conditions 1, 2, and 3.\u003C\u002Fp\u003E"},{order:"10",content:"\u003Cp\u003EP-values are reported in accordance with our \u003Ca href=\"..\u002F..\u002F\u002F?Instructions_for_Authors:Instructions_for_Authors_of_JMIR#p\" target=\"instr\"\u003Einstructions for authors\u003C\u002Fa\u003E.\u003C\u002Fp\u003E"},{order:aA,content:"\u003Cp\u003ESince 26 Oct 2006, we now require payment of a \u003Cstrong\u003EUS$ 90 submission fee\u003C\u002Fstrong\u003E for ALL articles submitted to the \u003Cem\u003EJ Med Internet Res\u003C\u002Fem\u003E&nbsp;(=this journal) EXCEPT letters or invited articles (there is no submission fee for sister journals - please change the journal in the drop down list above before proceeding). You can use Paypal or a credit card immediately after submission. Authors will not be able to complete the submission process without payment. This fee cannot be waived (only exception: invited articles), needs to be paid also by institutional members, and is non-refundable. This fee is in addition to other potential fees such as the optional fast-track fee (FTF) and the article processing fee (APF) for non-members. Authors should understand that the submission fee is non-refundable, even if the manuscript is promptly rejected without peer-review (we do send out the majority of papers for peer-review, but we reserve the right to reject papers without peer-review for any reason, including the topic not being deemed interesting enough, which is a subjective decision by the editor).\u003C\u002Fp\u003E"},{order:"12",content:"\u003Cp\u003EAuthors agree that the manuscript and peer-review reports may be transferred to a JMIR sister\u002Fpartner journal (e.g. \u003Ca href=\"http:\u002F\u002Fwww.i-jmr.org\" target=\"_new\"\u003Ei-JMR\u003C\u002Fa\u003E, \u003Ca href=\"http:\u002F\u002Fwww.researchprotocols.org\" target=\"_new\"\u003EJMIR Res Protoc\u003C\u002Fa\u003E, JMIR mHealth, JMIR Human Factors and others), if the paper is not found suitable for publication in JMIR, but is publishable in another journal. The submission fee for that partner journal (if any) will be waived, and transfer of the peer-review reports may mean that the paper does not have to be re-reviewed. Authors will receive a notification when the manuscript is transferred, and at that time can decide if they want to pursue publication in a sister\u002Fpartner journal. If authors do NOT wish an automatic transfer to an alternative journal after rejection for JMIR, this should be noted in the cover letter.\u003C\u002Fp\u003E"}],articlesWidget:{enabled:g,count:y,label:"Recent Articles"},openReviewWidget:{enabled:g,count:y,label:"\u003Ca href=\"https:\u002F\u002Fpreprints.jmir.org\"\u003EPreprints\u003C\u002Fa\u003E Open for Peer-Review"},searchWidget:{enabled:g},partnershipsWidget:{enabled:g},submitButton:{enabled:g,label:"Submit Article"},editorInChief:"\u003Cp style=\"display: inline-block;\"\u003EJohn Torous, MD, MBI, Harvard Medical School, USA\u003C\u002Fp\u003E"}}},journals:{data:[{journal_id:b,title:"Journal of Medical Internet Research",tag:"The leading peer-reviewed journal for digital medicine and health and health care in the internet age. June 2025 - Journal Impact Factor 6.0. Q1 journal in Health Care Science & Services and Medical Informatics categories. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:a,path:aB,slug:aB,seq:b,enabled:b,environment:d,url:"https:\u002F\u002Fwww.jmir.org",batch:b,year:1999,colour:l,impact:"6.0",order:b,published:10756,transfers:a,cite_score:"11.7"},{journal_id:i,title:"JMIR Research Protocols",tag:"Ongoing trials, grant proposals, formative research, methods, early results. June 2025 - Journal Impact Factor 1.5. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:"JMIR Res Protoc publishes research protocols, current and ongoing trials, and grant proposals in all areas of medicine (with an initial focus on ehealth\u002Fmhealth). Publish your work in this journal to let others know what you are working on, to facilitate collaboration and\u002For recruitment, to avoid duplication of efforts, to create a citable record of a research design idea, and to aid systematic reviewers in compiling evidence. Research protocols or grant proposals that are funded and have undergone peer-review will receive an expedited review if you upload peer-review reports as supplementary files.",path:"resprot",slug:"researchprotocols",seq:e,enabled:b,environment:d,url:"https:\u002F\u002Fwww.researchprotocols.org",batch:b,year:G,colour:"#837a7a",impact:"1.5",order:H,published:5264,transfers:a,cite_score:"2.4"},{journal_id:E,title:"JMIR Formative Research",tag:"Process evaluations, early results and feasibility\u002Fpilot studies of digital and non-digital interventions. June 2025 - Journal Impact Factor 2.1. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:c,path:aC,slug:aC,seq:I,enabled:b,environment:d,url:"https:\u002F\u002Fformative.jmir.org",batch:e,year:J,colour:as,impact:"2.1",order:K,published:4027,transfers:a,cite_score:"3.5"},{journal_id:L,title:"JMIR mHealth and uHealth",tag:"Internet interventions, technologies and digital innovations for mental health and behavior change. June 2025 - Journal Impact Factor 6.2. Q1 journal in Health Care Science & Services and Medical Informatics categories. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:"JMIR mhealth and uhealth is a new journal focussing on mobile and ubiquitous health technologies, including smartphones, augmented reality (Google Glasses), intelligent domestic devices, implantable devices, and other technologies designed to maintain health and improve life.",path:aD,slug:aD,seq:j,enabled:b,environment:d,url:"https:\u002F\u002Fmhealth.jmir.org",batch:e,year:M,colour:aE,impact:"6.2",order:j,published:2959,transfers:a,cite_score:"11.6"},{journal_id:N,title:"JMIR Public Health and Surveillance",tag:"A multidisciplinary journal that focuses on the intersection of public health and technology, public health informatics, mass media campaigns, surveillance, participatory epidemiology, and innovation in public health practice and research. June 2025 - Journal Impact Factor 3.9. Q1 journal in Public, Environmental & Occupational Health category. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:"Innovations in Public Health practice and research",path:aF,slug:aF,seq:u,enabled:b,environment:d,url:"https:\u002F\u002Fpublichealth.jmir.org",batch:b,year:r,colour:"#01538A",impact:"3.9",order:aG,published:1867,transfers:a,cite_score:"6.3"},{journal_id:45,title:"Online Journal of Public Health Informatics",tag:"A leading peer-reviewed, open access journal dedicated to the dissemination of high-quality research and innovation in the field of public health informatics. June 2025 - Journal Impact Factor 1.1.  (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:a,path:aH,slug:aH,seq:O,enabled:b,environment:d,url:"https:\u002F\u002Fojphi.jmir.org",batch:a,year:aI,colour:"#3399FF",impact:"1.1",order:P,published:1751,transfers:a,cite_score:a},{journal_id:p,title:"JMIR Medical Informatics",tag:"Clinical informatics, decision support for health professionals, electronic health records, and ehealth infrastructures. June 2025 - Journal Impact Factor 3.8. Q2 journal in Medical Informatics category. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:"Clinical informatics",path:aJ,slug:aJ,seq:i,enabled:b,environment:d,url:"https:\u002F\u002Fmedinform.jmir.org",batch:e,year:M,colour:"#82ABB9",impact:"3.8",order:N,published:1734,transfers:a,cite_score:"7.7"},{journal_id:f,title:au,tag:av,description:c,path:n,slug:n,seq:p,enabled:b,environment:d,url:aw,batch:b,year:x,colour:w,impact:F,order:o,published:ax,transfers:a,cite_score:ay},{journal_id:u,title:"JMIR Human Factors",tag:"Making health care interventions and technologies usable, safe, and effective. June 2025 - Journal Impact Factor 3.0. Q2 journal in Health Care Sciences & Services category. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:"Usability Studies and Ergonomics",path:aK,slug:aK,seq:aG,enabled:b,environment:d,url:"https:\u002F\u002Fhumanfactors.jmir.org",batch:e,year:x,colour:"#008C9E",impact:aL,order:t,published:1078,transfers:a,cite_score:aM},{journal_id:Q,title:"JMIR Serious Games",tag:"A multidisciplinary journal on gaming and gamification including simulation and immersive virtual reality for health education\u002Fpromotion, teaching and social change. June 2025 - Journal Impact Factor 4.1. Q1 journal in Health Care Science & Services category. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:"Serious games for health and social change",path:aN,slug:aN,seq:N,enabled:b,environment:d,url:"https:\u002F\u002Fgames.jmir.org",batch:b,year:M,colour:"#4A5A67",impact:"4.1",order:u,published:780,transfers:a,cite_score:"8.6"},{journal_id:H,title:"JMIR Medical Education",tag:"Technology, innovation and openess in medical education in the information age. June 2025 - Journal Impact Factor 12.5. June 2025 - Journal Impact Factor 2.2. Q1 journal in Education, Scientific Disciplines category. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:c,path:aO,slug:aO,seq:B,enabled:b,environment:d,url:"https:\u002F\u002Fmededu.jmir.org",batch:e,year:r,colour:"#6678A6",impact:"12.5",order:e,published:740,transfers:a,cite_score:aA},{journal_id:R,title:"JMIR Aging",tag:"Digital health technologies, apps, and informatics for patient education, medicine and nursing, preventative interventions, and clinical care \u002F home care for elderly populations. June 2025 - Journal Impact Factor 4.8. Q1 journal in Geriatrics & Gerontology and Gerontology categories. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:c,path:aP,slug:aP,seq:S,enabled:b,environment:d,url:"https:\u002F\u002Faging.jmir.org",batch:e,year:s,colour:"#979bc4",impact:aM,order:i,published:634,transfers:a,cite_score:"6.6"},{journal_id:T,title:"JMIRx Med",tag:aQ,description:a,path:aR,slug:aR,seq:z,enabled:b,environment:d,url:"https:\u002F\u002Fxmed.jmir.org",batch:a,year:U,colour:"#3187df",impact:c,order:I,published:575,transfers:a,cite_score:a},{journal_id:P,title:"JMIR Cancer",tag:"Patient-centered innovations, education and technology for cancer care, cancer survivorship, and cancer research. June 2025 - Journal Impact Factor 2.7. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:c,path:aS,slug:aS,seq:y,enabled:b,environment:d,url:"https:\u002F\u002Fcancer.jmir.org",batch:e,year:r,colour:"#584677",impact:"2.7",order:f,published:539,transfers:a,cite_score:"5.9"},{journal_id:S,title:"JMIR Pediatrics and Parenting",tag:"Improving pediatric and adolescent health outcomes and empowering and educating parents. June 2025 - Journal Impact Factor 2.3. Q2 journal in Pediatrics category. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:c,path:aT,slug:aT,seq:V,enabled:b,environment:d,url:"https:\u002F\u002Fpediatrics.jmir.org",batch:e,year:s,colour:"#d2a9ad",impact:aU,order:L,published:530,transfers:a,cite_score:"4.5"},{journal_id:j,title:"Interactive Journal of Medical Research",tag:"A new general medical journal for the 21st centrury, focusing on innovation in health and medical research. June 2025 - Journal Impact Factor 2.2. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:c,path:"ijmr",slug:"i-jmr",seq:o,enabled:b,environment:d,url:"https:\u002F\u002Fwww.i-jmr.org",batch:e,year:G,colour:"#22B2C1",impact:W,order:X,published:525,transfers:a,cite_score:a},{journal_id:o,title:"iProceedings",tag:"Electronic Proceedings, Presentations and Posters of Leading Conferences",description:c,path:aV,slug:aV,seq:L,enabled:b,environment:d,url:"https:\u002F\u002Fwww.iproc.org",batch:e,year:r,colour:"#6F7D80",impact:a,order:R,published:510,transfers:a,cite_score:a},{journal_id:V,title:"JMIR Dermatology",tag:"Technologies, devices, apps, and informatics applications for patient education in dermatology, including preventative interventions, and clinical care for dermatological populations",description:c,path:aW,slug:aW,seq:A,enabled:b,environment:d,url:"https:\u002F\u002Fderma.jmir.org",batch:e,year:s,colour:"#ecac7d",impact:a,order:A,published:361,transfers:a,cite_score:"1.8"},{journal_id:X,title:"JMIR Rehabilitation and Assistive Technologies",tag:"Development and Evaluation of Rehabilitation, Physiotherapy and Assistive Technologies, Robotics, Prosthetics and Implants, Mobility and Communication Tools, Home Automation and Telerehabilitation. June 2025 - Journal Impact Factor 3.0. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:c,path:aX,slug:aX,seq:aY,enabled:b,environment:d,url:"https:\u002F\u002Frehab.jmir.org",batch:e,year:x,colour:"#15638E",impact:aL,order:Q,published:347,transfers:a,cite_score:"5.7"},{journal_id:Y,title:"JMIR Diabetes",tag:"Emerging Technologies, Medical Devices, Apps, Sensors, and Informatics to Help People with Diabetes. June 2025 - Journal Impact Factor 2.6. Q2 journal in Health Care Sciences & Services category. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:c,path:aZ,slug:aZ,seq:Q,enabled:b,environment:d,url:"https:\u002F\u002Fdiabetes.jmir.org",batch:e,year:Z,colour:"#5c89c7",impact:a_,order:B,published:322,transfers:a,cite_score:"4.7"},{journal_id:A,title:"JMIR Cardio",tag:"Electronic, mobile, digital health approaches in cardiology and for cardiovascular health. June 2025 - Journal Impact Factor 2.2. Q2 journal in Cardiac & Cardiovascular Systems category. (Source: Journal Citation Reports™ 2025 from Clarivate™)  \r",description:c,path:a$,slug:a$,seq:P,enabled:b,environment:d,url:"https:\u002F\u002Fcardio.jmir.org",batch:e,year:J,colour:"#791f20",impact:W,order:aY,published:258,transfers:a,cite_score:"4.3"},{journal_id:ba,title:"JMIR AI",tag:"A new peer reviewed journal focused on research and applications for the health artificial intelligence (AI) community. June 2025 - Journal Impact Factor 2.0. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:"JMIR AI is a new journal that focuses on the applications of AI in health settings. This includes contemporary developments as well as historical examples, with an emphasis on sound methodological evaluations of AI techniques and authoritative analyses. It is intended to be the main source of reliable information for health informatics professionals to learn about how AI techniques can be applied and evaluated.",path:bb,slug:bb,seq:O,enabled:b,environment:d,url:"https:\u002F\u002Fai.jmir.org",batch:e,year:bc,colour:_,impact:"2.0",order:$,published:229,transfers:a,cite_score:"2.5"},{journal_id:38,title:"JMIR Infodemiology",tag:"Focusing on determinants and distribution of health information and misinformation on the internet, and its effect on public and individual health. June 2025 - Journal Impact Factor 2.3. Q2 journal in Health Care Sciences & Services and Public, Environmental & Occupational Health. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:"Focusing on determinants and distribution of health information and misinformation on the internet, and its effect on public and individual health.",path:bd,slug:bd,seq:37,enabled:b,environment:d,url:"https:\u002F\u002Finfodemiology.jmir.org",batch:e,year:2021,colour:"#32A852",impact:aU,order:y,published:at,transfers:a,cite_score:"6.5"},{journal_id:z,title:"JMIR Nursing",tag:"Virtualizing care from hospital to community: Mobile mealth, telehealth and digital patient care. June 2025 - Journal Impact Factor 4.0. Q1 journal in Nursing category. (Source: Journal Citation Reports™ 2025 from Clarivate™) ",description:a,path:be,slug:be,seq:aa,enabled:b,environment:d,url:"https:\u002F\u002Fnursing.jmir.org",batch:e,year:s,colour:"#429a99",impact:"4.0",order:p,published:163,transfers:a,cite_score:"5.1"},{journal_id:bf,title:"Journal of Participatory Medicine",tag:"The Journal of Participatory Medicine is a peer-reviewed, open access journal with the mission to advance the understanding and practice of participatory medicine among health care professionals and patients.\n\nIt is the Official Journal of the Society for Participatory Medicine.",description:c,path:bg,slug:bg,seq:Y,enabled:b,environment:d,url:"https:\u002F\u002Fjopm.jmir.org",batch:e,year:aI,colour:"#2ea3f2",impact:a,order:bh,published:148,transfers:a,cite_score:"3.1"},{journal_id:aa,title:"JMIR Perioperative Medicine",tag:"Technologies for pre- and post-operative education, preventative interventions and clinical care for surgery and anaesthesiology patients, as well as informatics applications in anesthesia, surgery, critical care and pain medicine",description:c,path:bi,slug:bi,seq:R,enabled:b,environment:d,url:"https:\u002F\u002Fperiop.jmir.org",batch:e,year:s,colour:"#187662",impact:a,order:V,published:135,transfers:a,cite_score:az},{journal_id:bj,title:"JMIR Biomedical Engineering",tag:"Engineering for health technologies, medical devices, and innovative medical treatments and procedures.",description:c,path:bk,slug:bk,seq:$,enabled:b,environment:d,url:"https:\u002F\u002Fbiomedeng.jmir.org",batch:e,year:Z,colour:bl,impact:a,order:E,published:106,transfers:a,cite_score:a},{journal_id:$,title:"JMIR Bioinformatics and Biotechnology",tag:"Methods, devices, web-based platforms, open data and open software tools for big data analytics, understanding biological\u002Fmedical data, and information retrieval in biology and medicine.",description:c,path:bm,slug:bm,seq:K,enabled:b,environment:d,url:"https:\u002F\u002Fbioinform.jmir.org",batch:e,year:U,colour:bl,impact:a,order:bf,published:72,transfers:a,cite_score:W},{journal_id:43,title:"Asian\u002FPacific Island Nursing Journal",tag:"The official journal of the Asian American \u002F Pacific Islander Nurses Association (AAPINA), devoted to the exchange of knowledge in relation to Asian and Pacific Islander health and nursing care. Created to fill the gap between nursing science and behavioral\u002Fsocial sciences, the journal offers a forum for empirical, theoretical and methodological issues related to Asian American \u002F Pacific Islander ethnic, cultural values and beliefs and biological and physiological phenomena that can affect nursing care.",description:"The official journal of the Asian American \u002F Pacific Islander Nurses Association, this is a peer-reviewed, open access journal for the exchange of knowledge in relation to Asian and Pacific Islander health and nursing care. It will serve as a voice for nursing and other health care providers for research, education, and practice.",path:bn,slug:bn,seq:ba,enabled:b,environment:d,url:"https:\u002F\u002Fapinj.jmir.org",batch:e,year:J,colour:bo,impact:c,order:bp,published:49,transfers:a,cite_score:a_},{journal_id:46,title:"JMIR XR and Spatial Computing (JMXR)",tag:"A new peer-reviewed journal for extended reality and spatial computing in health and health care. ",description:a,path:bq,slug:bq,seq:ab,enabled:b,environment:d,url:"https:\u002F\u002Fxr.jmir.org",batch:e,year:ae,colour:"#887ECB",impact:a,order:ab,published:ab,transfers:a,cite_score:a},{journal_id:35,title:"JMIRx Bio",tag:aQ,description:c,path:br,slug:br,seq:T,enabled:b,environment:d,url:"https:\u002F\u002Fxbio.jmir.org",batch:e,year:2023,colour:"#bf2433",impact:a,order:Y,published:O,transfers:a,cite_score:a},{journal_id:42,title:"JMIR Neurotechnology",tag:"Cross-disciplinary journal that connects the broad domains of clinical neuroscience and all related technologies. The journal provides a space for the publication of research exploring how technologies can be applied in clinical neuroscience (e.g., neurology, neurosurgery, neuroradiology) to prevent, diagnose, and treat neurological disorders.",description:"JMIR Neuro is an innovative new journal which aims to bridge clinical neurology & neurosurgery with advances in the web space and digital technologies",path:bs,slug:bs,seq:bp,enabled:b,environment:d,url:"https:\u002F\u002Fneuro.jmir.org",batch:e,year:bc,colour:bo,impact:a,order:bj,published:z,transfers:a,cite_score:a},{journal_id:e,title:"Medicine 2.0",tag:"Official proceedings publication of the Medicine 2.0 Congress",description:a,path:"med20",slug:"medicine20",seq:t,enabled:b,environment:d,url:"https:\u002F\u002Fwww.medicine20.com",batch:b,year:G,colour:aE,impact:a,order:aa,published:A,transfers:a,cite_score:a},{journal_id:bh,title:"JMIR Data",tag:"A muldisciplinary journal to publish open datasets for analysis and re-analysis",description:c,path:bt,slug:bt,seq:H,enabled:b,environment:d,url:"https:\u002F\u002Fdata.jmir.org",batch:e,year:U,colour:"#5A6672",impact:a,order:T,published:i,transfers:a,cite_score:a},{journal_id:I,title:"JMIR Challenges",tag:"JMIR Challenges is a new platform connecting \"solution-seekers\" (sponsors such as companies or other researchers) with \"solution-providers\" (entrants, such as innovators, researchers, or developers in the ehealth space)",description:c,path:bu,slug:bu,seq:X,enabled:b,environment:d,url:"https:\u002F\u002Fchallenges.jmir.org",batch:e,year:Z,colour:_,impact:a,order:z,published:e,transfers:a,cite_score:a},{journal_id:K,title:"JMIR Preprints",tag:"A preprint server for pre-publication\u002Fpre-peer-review preprints intended for community review as well as ahead-of-print (accepted) manuscripts",description:"Publish your paper for open peer-review.",path:bv,slug:bv,seq:f,enabled:b,environment:d,url:"https:\u002F\u002Fpreprints.jmir.org",batch:b,year:r,colour:_,impact:a,order:S,published:b,transfers:a,cite_score:a}]},license:{},page:{data:a},pages:{data:{}},preprint:{data:a},searchArticles:{data:{}},searchAuthors:{data:[],pagination:{}},searchHelp:{data:{},error:a},sections:{data:[],allSections:[],journalSections:[]},submission:{data:{id:a,files:{toc:[],figures:[],appendicies:[],other:[]}},file:a,affiliation:a,suggestedAffiliations:a,events:{extraction:[]},errors:{}},subscription:{},theme:{data:[]},themes:{random:a,data:[],sortType:"pubDate",sortOrder:"desc"}},serverRendered:g,routePath:ag,config:{environment:d,adsEnabled:g,adsDebug:m,_app:{basePath:"\u002F",assetsPath:"\u002F_nuxt\u002F",cdnURL:a}}}}(null,1,"","production",2,16,true,"Switzerland",5,3,0,"#247CB3",false,"mental",4,7,"Zurich",2015,2018,10,6,"University of Zurich","#45936C",2014,12,33,26,11,396389,"Basel",27,"5.8",2012,20,22,2017,18,13,2013,9,39,21,15,31,30,34,2020,29,"2.2",17,23,2016,"#666666",19,32,40,"2024-01-19T15:18:59.000Z",1433,2024,"1","\u002F2024\u002F1\u002Fe56569","The Role of Humanization and Robustness of Large Language Models in Conversational Artificial Intelligence for Individuals With Depression: A Critical Analysis","Andrea","Ferrario","Andrea Ferrario","PhD",396374,"41 044 634 40 81","Institute Biomedical Ethics and History of Medicine","Winterthurerstrasse, 30","8006",396386,"#605959",227,"JMIR Mental Health","Internet interventions, technologies and digital innovations for mental health and behavior change. June 2025 - Journal Impact Factor 5.8. Q1 journal in Psychiatry category. (Source: Journal Citation Reports™ 2025 from Clarivate™) ","https:\u002F\u002Fmental.jmir.org",1227,"10.2","2","11","jmir","formative","mhealth","#65AD8C","publichealth",8,"ojphi",2009,"medinform","humanfactors","3.0","4.8","games","mededu","aging","Overlay journal for preprints with post-review manuscript marketplace","xmed","cancer","pediatrics","2.3","iproc","derma","rehab",14,"diabetes","2.6","cardio",41,"ai",2022,"infodemiology","nursing",28,"jopm",25,"periop",24,"biomedeng","#474760","bioinform","apinj","#3399ff",36,"xr","xbio","neuro","data","challenges","preprints"));</script><script src="/_nuxt/9c7c1e4.js" defer></script><script src="/_nuxt/b70fdb7.js" defer></script><script src="/_nuxt/4916c14.js" defer></script><script src="/_nuxt/8043cc4.js" defer></script><script src="/_nuxt/797995a.js" defer></script><script src="/_nuxt/d965382.js" defer></script><script src="/_nuxt/4927325.js" defer></script><script src="/_nuxt/2bde5b8.js" defer></script><script src="/_nuxt/1326996.js" defer></script><script src="/_nuxt/09b1d65.js" defer></script><script src="/_nuxt/366ad09.js" defer></script><script src="/_nuxt/95fde3b.js" defer></script><script src="/_nuxt/d0c41c5.js" defer></script><script src="/_nuxt/e6dad64.js" defer></script><script src="/_nuxt/84066b5.js" defer></script><script src="/_nuxt/fc6cf93.js" defer></script><script src="/_nuxt/14f78e7.js" defer></script><script src="/_nuxt/aa08135.js" defer></script><script src="/_nuxt/75832c0.js" defer></script><script src="/_nuxt/4436098.js" defer></script><script src="/_nuxt/bcc9d63.js" defer></script><script src="/_nuxt/3d6a000.js" defer></script><script src="/_nuxt/98a1aa4.js" defer></script><script src="/_nuxt/89ba270.js" defer></script><script src="/_nuxt/bc9dad6.js" defer></script><script src="/_nuxt/fc087e0.js" defer></script><script src="/_nuxt/b643d0c.js" defer></script><script src="/_nuxt/68827e8.js" defer></script><script src="/_nuxt/421b4ad.js" defer></script><script src="/_nuxt/bbb2307.js" defer></script><script src="/_nuxt/d9f2686.js" defer></script><script src="/_nuxt/255fd1e.js" defer></script><script src="/_nuxt/0bceff3.js" defer></script><script src="/_nuxt/7b27d0b.js" defer></script><script src="/_nuxt/e8be31d.js" defer></script><script src="/_nuxt/70e9da6.js" defer></script><script src="/_nuxt/beec627.js" defer></script><script src="/_nuxt/f98275c.js" defer></script><script src="/_nuxt/4c795dc.js" defer></script><script src="/_nuxt/08b91c7.js" defer></script><script src="/_nuxt/3df9693.js" defer></script><script src="/_nuxt/9a1b312.js" defer></script><script src="/_nuxt/21899a6.js" defer></script><script src="/_nuxt/bf91a67.js" defer></script><script src="/_nuxt/e7d56e2.js" defer></script><script src="/_nuxt/9c711d7.js" defer></script><script src="/_nuxt/a116589.js" defer></script><script src="/_nuxt/e8da5fa.js" defer></script><script data-n-head="ssr" src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js" data-body="true" defer></script><script data-n-head="ssr" src="https://badge.dimensions.ai/badge.js" data-body="true" defer></script><script data-n-head="ssr" type="text/javascript" charset="utf-8" data-body="true">_linkedin_partner_id = "3149908"; window._linkedin_data_partner_ids = window._linkedin_data_partner_ids || []; window._linkedin_data_partner_ids.push(_linkedin_partner_id);</script><script data-n-head="ssr" type="text/javascript" charset="utf-8" data-body="true">(function(l) { if (!l){window.lintrk = function(a,b){window.lintrk.q.push([a,b])}; window.lintrk.q=[]} var s = document.getElementsByTagName("script")[0]; var b = document.createElement("script"); b.type = "text/javascript";b.async = true; b.src = "https://snap.licdn.com/li.lms-analytics/insight.min.js"; s.parentNode.insertBefore(b, s);})(window.lintrk);</script><script data-n-head="ssr" type="text/javascript" charset="utf-8" data-body="true">
                    (function(w, d) {
                                var s = d.createElement('script');
                                s.src = '//cdn.adpushup.com/48547/adpushup.js';
                                s.crossOrigin='anonymous'; 
                                s.type = 'text/javascript'; s.async = true;
                                (d.getElementsByTagName('head')[0] || d.getElementsByTagName('body')[0]).appendChild(s);
                                w.adpushup = w.adpushup || {que:[]};
                        })(window, document);
                    </script><script data-n-head="ssr" type="text/javascript" charset="utf-8" data-body="true">
(function(w, d) {
    var s = d.createElement('script');
    s.src = '//cdn.adpushup.com/48547/adpushup.js';
    s.crossOrigin='anonymous'; 
    s.type = 'text/javascript'; s.async = true;
    (d.getElementsByTagName('head')[0] || d.getElementsByTagName('body')[0]).appendChild(s);
    w.adpushup = w.adpushup || {que:[]};
})(window, document);

var adpushup = window.adpushup = window.adpushup || {};
adpushup.que = adpushup.que || [];

// Note: Individual ad triggering is now handled by each component
// when they mount and verify they should be displayed (desktop only)
</script></body></html>