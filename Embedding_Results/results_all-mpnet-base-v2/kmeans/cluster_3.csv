title,abstract,class,cluster,publication,year,url,keywords,llm,human n,interaction,long-term?,conclusion,remark
Experimental evidence on the productivity effects of generative artificial intelligence,"We examined the productivity effects of a generative artificial intelligence (AI) technology, the assistive chatbot ChatGPT, in the context of midlevel professional writing tasks. In a preregistered online experiment, we assigned occupation-specific, incentivized writing tasks to 453 college-educated professionals and randomly exposed half of them to ChatGPT. Our results show that ChatGPT substantially raised productivity: The average time taken decreased by 40% and output quality rose by 18%. Inequality between workers decreased, and concern and excitement about AI temporarily rose. Workers exposed to ChatGPT during the experiment were 2 times as likely to report using it in their real job 2 weeks after the experiment and 1.6 times as likely 2 months after the experiment.",3,3,Science,2023,https://www.science.org/doi/10.1126/science.adh2586,Productivity,GPT 3.5,453,Conversation,2 months,"ChatGPT substantially raised productivity: The average time taken decreased by 40% and output quality rose by 18%. Inequality between workers decreased, and concern and excitement about AI temporarily rose. Workers exposed to ChatGPT during the experiment were 2 times as likely to report using it in their real job 2 weeks after the experiment and 1.6 times as likely 2 months after the experiment.",
Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task,"This study explores the neural and behavioral consequences of LLM-assisted essay writing. Participants were divided into three groups: LLM, Search Engine, and Brain-only (no tools). Each completed three sessions under the same condition. In a fourth session, LLM users were reassigned to Brain-only group (LLM-to-Brain), and Brain-only users were reassigned to LLM condition (Brain-to-LLM). A total of 54 participants took part in Sessions 1-3, with 18 completing session 4. We used electroencephalography (EEG) to assess cognitive load during essay writing, and analyzed essays using NLP, as well as scoring essays with the help from human teachers and an AI judge. Across groups, NERs, n-gram patterns, and topic ontology showed within-group homogeneity. EEG revealed significant differences in brain connectivity: Brain-only participants exhibited the strongest, most distributed networks; Search Engine users showed moderate engagement; and LLM users displayed the weakest connectivity. Cognitive activity scaled down in relation to external tool use. In session 4, LLM-to-Brain participants showed reduced alpha and beta connectivity, indicating under-engagement. Brain-to-LLM users exhibited higher memory recall and activation of occipito-parietal and prefrontal areas, similar to Search Engine users. Self-reported ownership of essays was the lowest in the LLM group and the highest in the Brain-only group. LLM users also struggled to accurately quote their own work. While LLMs offer immediate convenience, our findings highlight potential cognitive costs. Over four months, LLM users consistently underperformed at neural, linguistic, and behavioral levels. These results raise concerns about the long-term educational implications of LLM reliance and underscore the need for deeper inquiry into AI's role in learning.",3,3,arXiv,2025,https://arxiv.org/abs/2506.08872,Creativity,GPT-4o,54,Conversation,4 months,"1. Using LLMs like ChatGPT for essay writing significantly reduces cognitive engagement and brain connectivity compared to writing unaided ('Brain-only') or using a search engine . This reduced cognitive load correlates with more homogeneous essays, impaired memory recall (evidenced by poor quoting ability), and a diminished sense of ownership over the written work . 2. Prior LLM use appears to create a 'cognitive debt', hindering brain engagement even when the tool is removed, suggesting potential long-term negative impacts on learning and critical thinking skills .",Neuroscience experiments
AI Suggestions Homogenize Writing Toward Western Styles and Diminish Cultural Nuances,"Large language models (LLMs) are being increasingly integrated into everyday products and services, such as coding tools and writing assistants. As these embedded AI applications are deployed globally, there is a growing concern that the AI models underlying these applications prioritize Western values. This paper investigates what happens when a Western-centric AI model provides writing suggestions to users from a different cultural background. We conducted a cross-cultural controlled experiment with 118 participants from India and the United States who completed culturally grounded writing tasks with and without AI suggestions. Our analysis reveals that AI provided greater efficiency gains for Americans compared to Indians. Moreover, AI suggestions led Indian participants to adopt Western writing styles, altering not just what is written but also how it is written. These findings show that Western-centric AI models homogenize writing toward Western norms, diminishing nuances that differentiate cultural expression.",2,3,arXiv,2025,https://arxiv.org/abs/2409.11360,Diversity (Writing),GPT-4o,118=60(Indian)+58(American),Conversation,F,"1. American participants experienced greater efficiency gains when writing with AI, as the AI is Western-centric.

2. When Indian participants collaborated on writing with AI, their style leaned toward Western writing styles, showing that AI can alter a human's original style.

3. AI diminishes cultural nuances. AI suggestions led Indian participants to write more like Americans, affecting both what was written and how it was written. The findings suggest that Western-centric AI models can lead to cultural imperialism and linguistic singularity.",
Generative AI without guardrails can harm learning: Evidence from high school mathematics,"Generative AI is poised to revolutionize how humans work, and has already demonstrated promise in significantly improving human productivity. A key question is how generative AI affects learning〞namely, how humans acquire new skills as they perform tasks. Learning is critical to long-term productivity, especially since generative AI is fallible and users must check its outputs. We study this question via a field experiment where we provide nearly a thousand high school math students with access to generative AI tutors. To understand the differential impact of tool design on learning, we deploy two generative AI tutors: one that mimics a standard ChatGPT interface (※GPT Base§) and one with prompts designed to safeguard learning (※GPT Tutor§). Consistent with prior work, our results show that having GPT-4 access while solving problems significantly improves performance (48% improvement in grades for GPT Base and 127% for GPT Tutor). However, we additionally find that when access is subsequently taken away, students actually perform worse than those who never had access (17% reduction in grades for GPT Base)〞i.e., unfettered access to GPT-4 can harm educational outcomes. These negative learning effects are largely mitigated by the safeguards in GPT Tutor. Without guardrails, students attempt to use GPT-4 as a ※crutch§ during practice problem sessions, and subsequently perform worse on their own. Thus, decision-makers must be cautious about design choices underlying generative AI deployments to preserve skill learning and long-term productivity.",3,3,PNAS,2025,https://www.pnas.org/doi/10.1073/pnas.2422633122,Learning,GPT-4,About 1000,Conversation,F,"1. AI-assisted tools can improve immediate performance.

2. The short-term improvement cannot be sustained in the subsequent unassisted exam. The GPT Base group performed significantly worse, worse than the control group. The GPT Tutor group was on par with the control group.

3. Students did not even feel this was harmful. The GPT Base group did not think they learned less, and the GPT Tutor group believed they learned significantly better.",
"Beware of metacognitive laziness: Effects of generative artificial intelligence on learning motivation, processes, and performance","Abstract
With the continuous development of technological and educational innovation, learners nowadays can obtain a variety of supports from agents such as teachers, peers, education technologies, and recently, generative artificial intelligence such as ChatGPT. In particular, there has been a surge of academic interest in human坼AI collaboration and hybrid intelligence in learning. The concept of hybrid intelligence is still at a nascent stage, and how learners can benefit from a symbiotic relationship with various agents such as AI, human experts and intelligent learning systems is still unknown. The emerging concept of hybrid intelligence also lacks deep insights and understanding of the mechanisms and consequences of hybrid human坼AI learning based on strong empirical research. In order to address this gap, we conducted a randomised experimental study and compared learners' motivations, self坼regulated learning processes and learning performances on a writing task among different groups who had support from different agents, that is, ChatGPT (also referred to as the AI group), chat with a human expert, writing analytics tools, and no extra tool. A total of 117 university students were recruited, and their multi坼channel learning, performance and motivation data were collected and analysed. The results revealed that: (1) learners who received different learning support showed no difference in post坼task intrinsic motivation; (2) there were significant differences in the frequency and sequences of the self坼regulated learning processes among groups; (3) ChatGPT group outperformed in the essay score improvement but their knowledge gain and transfer were not significantly different. Our research found that in the absence of differences in motivation, learners with different supports still exhibited different self坼regulated learning processes, ultimately leading to differentiated performance. What is particularly noteworthy is that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger ※metacognitive laziness§. In conclusion, understanding and leveraging the respective strengths and weaknesses of different agents in learning is critical in the field of future hybrid intelligence.
Practitioner notes
What is already known about this topic
Hybrid intelligence, combining human and machine intelligence, aims to augment human capabilities rather than replace them, creating opportunities for more effective lifelong learning and collaboration.
Generative AI, such as ChatGPT, has shown potential in enhancing learning by providing immediate feedback, overcoming language barriers and facilitating personalised educational experiences.
The effectiveness of AI in educational contexts varies, with some studies highlighting its benefits in improving academic performance and motivation, while others note limitations in its ability to replace human teachers entirely.
What this paper adds
We conducted a randomised experimental study in the lab setting and compared learners' motivations, self坼regulated learning processes and learning performances among different agent groups (AI, human expert and checklist tools).
We found that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger metacognitive ""laziness"", which can potentially hinder their ability to self坼regulate and engage deeply in learning.
We also found that ChatGPT can significantly improve short坼term task performance, but it may not boost intrinsic motivation and knowledge gain and transfer.
Implications for practice and/or policy
When using AI in learning, learners should focus on deepening their ＃",3,3,Britsh Journal of Educational Technology,2024,https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.13544,Learning,GPT-4,117,Conversation,F,"1. AI education does not improve people's learning interest.

2. AI triggers ""metacognitive laziness."" People rely on AI to offload tasks like evaluation and reflection, reducing their participation in key learning processes.

3. AI improves short-term performance but does not help long-term learning. AI education cannot achieve knowledge transfer, nor can it enhance the understanding of knowledge (knowledge gain).",
Whether and When Could Generative AI Improve College Student Learning Engagement?,"Generative AI (GenAI) technologies have been widely adopted by college students since the launch of ChatGPT in late 2022. While the debate about GenAI＊s role in higher education continues, there is a lack of empirical evidence regarding whether and when these technologies can improve the learning experience for college students. This study utilizes data from a survey of 72,615 undergraduate students across 25 universities and colleges in China to explore the relationships between GenAI use and student learning engagement in different learning environments. The findings reveal that over sixty percent of Chinese college students use GenAI technologies in Academic Year 2023每2024, with academic use exceeding daily use. GenAI use in academic tasks is related to more cognitive and emotional engagement, though it may also reduce active learning activities and learning motivation. Furthermore, this study highlights that the role of GenAI varies across learning environments. The positive associations of GenAI and student engagement are most prominent for students in ※high-challenge and high-support§ learning contexts, while GenAI use is mostly negatively associated with student engagement in ※low-challenge, high-support§ courses. These findings suggest that while GenAI plays a valuable role in the learning process for college students, its effectiveness is fundamentally conditioned by the instructional design of human teachers.",3,3,Behavioral Sciences,2025,https://www.mdpi.com/2076-328X/15/8/1011,Education,No experiments. Deepseak GPT,"72,615",Conversation,F,"1. GenAI has a high adoption rate (over 60%) among Chinese college students, but satisfaction with its academic utility is limited ﹝

2. A positive association was found with higher cognitive engagement (higher-order thinking) and aspects of emotional engagement, such as academic self-efficacy and resilience ﹝

3. A negative association was found with behavioral engagement (e.g., note-taking, reviewing) and, notably, with learning interest and learning motivation ﹝

4. The effect of GenAI is highly dependent on the ""learning environment"" ﹝he positive associations of GenAI are most prominent in ""high-challenge and high-support"" learning contexts ﹝GenAI use is mostly negatively associated with student engagement in ""high-support, low-challenge"" courses. The effectiveness of GenAI is ""fundamentally conditioned by the instructional design of human teachers"".",
Trusting the Algorithm: Emotional Engagement with ChatGPT in Higher Education.,"This study examines emotional engagement with ChatGPT among 121 university students from diverse academic disciplines, focusing on the relationships between trust in the AI, the emotional framing of prompts, and the explicit use of ChatGPT for emotional support. Results reveal a paradox: higher trust correlates with increased emotional self-awareness (r=. 386) and perceived emotional intelligence (r=. 508), while deliberate emotional framing is linked to lower perceived AI emotional intelligence (r=每. 412) and reduced emotional benefits (r=每. 259). Students who use ChatGPT for emotional support report diminished emotional awareness (r=每. 190) and less favourable emotional outcomes (r=每. 270), indicating an ※empathic expectation gap§ where emotional intent exposes the system＊s limitations. The findings highlight the need to integrate ChatGPT in digital pedagogy as a reflective tool rather than a substitute for human connection, with attention to ethical design, user education, and emotional literacy.",3,3,International Conference on Pedagogical Science and Digital Learning 2025,2025,https://doi.org/10.5281/ZENODO.17423731,Emotional Support Use,ChatGPT,121,Conversation,F,"Usage Patterns: While nearly half of students engage in emotional framing (M=1.45), only ~23% explicitly use ChatGPT for emotional support.

Basis of Trust: Trust is built on the AI being ""always available"" and ""non-judgmental,"" positioning it as a safe space for expression.

Emotional Outcomes: Students generally report neutral to moderately positive emotional results from these interactions (M=2.26).

Double-Edged Sword: While trust enables productive interaction, over-reliance on AI for regulation risks hindering personal emotional growth and diminishing human help-seeking behaviors.",
Optimizing academic engagement and mental health through AI: an experimental study on LLM integration in higher education,"Background
In alignment with UNESCO's Sustainable Development Goal 4 (SDG4), which advocates for inclusive and equitable quality education, the integration of Artificial Intelligence tools〞particularly Large Language Models (LLMs)〞presents promising opportunities for transforming higher education. Despite this potential, empirical research remains scarce regarding the effects of LLM use on students' academic performance, mental well-being, and engagement, especially across different modes of implementation.
Objective
This experimental study investigated whether a guided, pedagogically grounded use of LLMs enhances students' academic writing quality, perceived mental health, and academic engagement more effectively than either unguided use or no exposure to LLMs. The study contributes to UNESCO's ""Futures of Education"" vision by exploring how structured AI use may foster more inclusive and empowering learning environments.
Method
A total of 246 undergraduate students were randomly assigned to one of three conditions: guided LLM use, unguided LLM use, or a control group with no LLM access. Participants completed a critical writing task and standardized instruments measuring academic engagement and mental well-being. Prior academic achievement was controlled for, and writing quality was assessed using Grammarly for Education.
Results
Students in the guided LLM condition achieved significantly higher scores in writing quality and academic engagement compared to the control group, with large and moderate effect sizes, respectively. Modest improvements in mental health indicators were also observed. By contrast, unguided use yielded moderate gains in writing quality but did not produce significant effects on engagement or well-being.
Conclusion
The findings highlight the critical role of intentional instructional design in the educational integration of AI tools. Structured guidance not only optimizes academic outcomes but also supports students' well-being and inclusion. This study offers empirical evidence to inform ongoing debates on how digital innovation can contribute to reducing educational disparities and advancing equitable learning in the post-pandemic era.",3,3,Frontiers in Psychology,2025,https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2025.1641212/full,Education,ChatGPT,246,Conversation,F,"

1. Guided use of LLMs, with pedagogical grounding, leads to a significant improvement in students' academic writing quality compared to unguided use or no use of LLMs at all.

2. Structured (guided) integration of LLMs also promotes students' academic engagement and, to a certain extent, their mental health / perceived well-being, although the improvement in mental health is moderate (small-to-moderate effect size). 

3. In contrast, unguided use of LLMs, while resulting in a moderate improvement in writing quality, has little to no significant effect on engagement and mental health. ",
Impact of LLM Feedback on Learner Persistence in Programming,"Abstract
This study examines how Large Language Model (LLM) feedback generated for compiler errors impacts learners＊ persistence in programming tasks within a system for automated assessment of programming assignments. Persistence, the ability to maintain effort in the face of challenges, is crucial for academic success but can sometimes lead to unproductive"" wheel spinning"" when students struggle without progress. We investigated how additional LLM feedback based on the GPT-4 model, provided for compiler errors affects learners＊ persistence within a CS1 course. Specifically, we examined whether its impacts differ based on task difficulty, and if the effects persist after the feedback is removed. A randomized controlled trial involving 257 students across various programming tasks was conducted. Our findings reveal that LLM feedback improved some aspects of students＊ performance and persistence, such as increased scores, a higher likelihood of solving problems, and a lower tendency to demonstrate unproductive"" wheel spinning"" behavior. Notably, this positive impact was also observed in challenging tasks. However, its benefits did not sustain once the feedback was removed. The results highlight both the potential and limitations of LLM feedback, pointing out the need to promote long-term skill development and learning independent of immediate AI assistance.",3,3,ICCE,2025,https://learninganalytics.upenn.edu/ryanbaker/ICCE2025_paper_28.pdf,Education,GPT 4,257,Conversation,T,"1. LLM (GPT-4) generated feedback improves student persistence in programming courses 〞 enhancing their final submission quality, reducing unproductive ""wheel-spinning,"" and minimizing wasted time, abandonment, and interruptions. These improvements are evident across tasks of all difficulty levels.

2. However, when the LLM feedback is removed, these benefits do not persist, indicating that LLM serves more as a short-term or immediate scaffold, rather than a ""trainer"" that helps students develop long-term, independent problem-solving abilities.",
Effects of LLM Use and NoteTaking on Reading Comprehension and Memory: A Randomised Experiment in Secondary Schools,"The rapid uptake of Generative AI, particularly large language models (LLMs), by students raises urgent questions about their effects on learning. We compared the impact of LLM use to that of traditional note-taking, or a combination of both, on secondary school students' reading comprehension and retention. We conducted a pre-registered, randomised controlled experiment with within-and between-participant design elements in schools. 405 students aged 14-15 studied two text passages and completed comprehension and retention tests three days later. Quantitative results demonstrated that both note-taking alone and combined with the LLM had significant positive effects on retention and comprehension compared to the LLM alone. Yet, most students preferred using the LLM over note-taking, and perceived it as more helpful. Qualitative results revealed that many students valued LLMs for making complex material more accessible and reducing cognitive load, while they appreciated note-taking for promoting deeper engagement and aiding memory. Additionally, we identified ""archetypes"" of prompting behaviour, offering insights into the different ways students interacted with the LLM. Overall, our findings suggest that, while note-taking promotes cognitive engagement and long-term comprehension and retention, LLMs may facilitate initial understanding and student interest. The study reveals the continued importance of traditional learning approaches, the benefits of combining AI use with traditional learning over using AI alone, and the AI skills that students need to maximise those benefits.",3,3,Computers & Education,2025,https://www.sciencedirect.com/science/article/pii/S0360131525002829,Education,,344,Conversation,3 DAYS,"1. LLMs aid quick understanding and reduce cognitive load, but may not improve long-term memory or deep understanding.

2. Traditional skills like note-taking and active recall are still better for memory and comprehension than LLMs alone.

3. LLM effectiveness depends on how students use it 〞 simply allowing its use doesn＊t guarantee better learning outcomes.",
Exploring the Impact of Generative AI ChatGPT on Critical Thinking in Higher Education: Passive AI?Directed Use or Human每AI Supported Collaboration?,"Generative AI is weaving into the fabric of many human aspects through its transformative power to mimic human-generated content. It is not a mere technology; it functions as a generative virtual assistant, raising concerns about its impact on cognition and critical thinking. This mixed-methods study investigates how GenAI ChatGPT affects critical thinking across cognitive presence (CP) phases. Forty students from a four-year university in the southwestern United States completed a survey; six provided their ChatGPT scripts, and two engaged in semi-structured interviews. Students＊ self-reported survey responses suggested that GenAI ChatGPT improved triggering events (M = 3.60), exploration (M = 3.70), and integration (M = 3.60); however, responses remained neutral during the resolution stage. Two modes of interaction were revealed in the analysis of students＊ ChatGPT scripts: passive, AI-directed use and collaborative, AI-supported interaction. A resolution gap was identified; nonetheless, the interview results revealed that when GenAI ChatGPT was utilized with guidance, all four stages of cognitive presence were completed, leading to enhanced critical thinking and a reconceptualization of ChatGPT as a more knowledgeable other. This research suggests that the effective use of GenAI in education depends on the quality of human每AI interaction. Future directions must orient toward an integration of GenAI in education that positions human and machine intelligence not as a substitution but as co-participation, opening new epistemic horizons while reconfiguring assessment practices to ensure that human oversight, critical inquiry, and reflective thinking remain at the center of learning.",3,3,Educ. Sci.,2025,https://www.mdpi.com/2227-7102/15/9/1198,Education,CHATGPT,40,Conversation,F,"1. LLMs, like ChatGPT, have the potential to support critical thinking in higher education if used collaboratively and with guidance. They can help students engage in true critical thinking, not just quick answers or cognitive offloading.

2. However, a major risk exists: passive use of AI can weaken, rather than enhance, deep learning and critical thinking. The effectiveness of LLMs depends heavily on how they are used, the educational design, and the human-AI collaboration framework.

3. To effectively use ChatGPT in education, institutions, educators, and course designers must carefully structure AI use 〞 including when to use it, how to guide students, and ensure reflection and discussion 〞 rather than simply opening access to ChatGPT.",
Measuring the Impact of Large Language Models on Academic Success and Quality of Life Among Students with Visual Disability: An Assistive Technology Perspective,"In the rapid digital era, artificial intelligence (AI) tools have progressively arisen to shape the education environment. In this context, large language models (LLMs) (i.e., ChatGPT vs. 4.0 and Gemini vs. 2.5) have emerged as powerful applications for academic inclusion. This paper investigated how using and trusting LLMs can impact the academic success and quality of life (QoL) of visually impaired university students. Quantitative research was conducted, obtaining data from 385 visually impaired university students through a structured survey design. Partial Least Squares Structural Equation Modelling (PLS-SEM) was implemented to test the study hypotheses. The findings revealed that trust in LLMs can significantly predict LLM usage, which in turn can improve QoL. While LLM usage failed to directly support the academic success of disabled students, but its impact was mediated through QoL, suggesting that enhancements in well-being can contribute to higher academic success. The results highlighted the importance of promoting trust in AI applications, along with developing an accessible, inclusive, and student-centred digital environment. The study offers practical contributions for educators and policymakers, shedding light on the importance of LLM applications for both the QoL and academic success of visually impaired university students.",3,3,MDPI Bioengineering,2025,https://www.mdpi.com/2306-5354/12/10/1056,Education,GPT 4 & Gemini 2.5,385 visually impaired Students,Conversation,F,"1. LLM usage and quality of life: The use of LLMs is significantly positively correlated with students' reported quality of life, including life satisfaction and well-being. Using LLMs to assist in learning and accessing resources helps improve the quality of life and satisfaction for visually impaired students.

2. LLM usage, trust, and academic success: While LLM usage itself does not directly predict academic success, it has an indirect effect through its impact on quality of life. In other words, LLM usage improves students' well-being, and this improvement in well-being, in turn, contributes to better academic performance.",
The Impact of ChatGPT on English as a Foreign Language Learners' Writing Skills 每 An Experimental Study at Georgian Universities,"This study explores the impact of ChatGPT on English as a Foreign Language (EFL) students' writing skills. The integration of advanced AI tools like ChatGPT has transformed educational experiences, offering significant potential to enhance writing competence through personalized feedback and interactive writing practice. Conducted in a Georgian higher education context, the study involved 33 B2-level students divided into experimental and control groups over six weeks. The experimental group used ChatGPT for writing assistance, while the control group received traditional instruction. Results showed that ChatGPT significantly improved students' writing performance, highlighting its efficacy as an educational tool. However, concerns about ethical use and over-reliance on AI were noted, emphasizing the need for a balanced integration of technology in language learning.",3,3,ESI,2025,https://eujournal.org/index.php/esj/article/view/19269?utm_source=chatgpt.com,Education,ChatGPT,33,Conversation,6 Weeks,"This study provides preliminary empirical evidence that, in EFL (English as a Foreign Language) writing training, ChatGPT significantly improves students' writing performance in a short-term (6-week) period compared to traditional methods, indicating a positive impact of LLMs (ChatGPT) on students' writing abilities and learning outcomes.",
