title,abstract,class,cluster,publication,year,url,keywords,llm,human n,interaction,long-term?,conclusion,remark
An empirical investigation of the impact of ChatGPT on creativity,"This paper investigates the potential of ChatGPT for helping humans tackle problems that require creativity. Across five experiments, we asked participants to use ChatGPT (GPT-3.5) to generate creative ideas for various everyday and innovation-related problems, including choosing a creative gift for a teenager, making a toy, repurposing unused items and designing an innovative dining table. We found that using ChatGPT increased the creativity of the generated ideas compared with not using any technology or using a conventional Web search (Google). This effect remained robust regardless of whether the problem required consideration of many (versus few) constraints and whether it was viewed as requiring empathetic concern. Furthermore, ChatGPT was most effective at generating incrementally (versus radically) new ideas. Process evidence suggests that the positive influence of ChatGPT can be attributed to its capability to combine remotely related concepts into a cohesive form, leading to a more articulate presentation of ideas.",2,2,Nature Human Behavior,2024,https://www.nature.com/articles/s41562-024-01953-1,Creativity,GPT-3.5,233,Conversation,F,"1. ChatGPT Enhances Creativity: Using ChatGPT significantly improves the creativity (originality and appropriateness) of generated ideas compared to using no technology or traditional web search (Google). 
2. Type of Creativity: ChatGPT is particularly effective at generating incrementally new ideas (improving/combining existing concepts) rather than radically new ones, likely due to its reliance on existing data. 
3. Mechanism: Its strength lies in combining distantly related concepts into cohesive, articulate forms, acting as an 'idea exposition aid' that improves 'idea articulateness'.
4. Role of Human Modification: For lay participants, further modifying ChatGPT's raw output does not significantly enhance creativity ratings, suggesting potential for automated creativity generation, though expert input might differ.",
Creative scar without generative AI: Individual creativity fails to sustain while homogeneity keeps climbing,"Generative AI such as ChatGPT has been proven to enhance human creativity at the cost of content diversity. Yet, what occurs when individuals, who have developed a dependency on it, find ChatGPT inaccessible? In this study, we examine the impact of both the presence and absence of ChatGPT on sustained creative output and content homogeneity, leveraging two complementary methodologies: a natural experiment (Study 1) and a controlled laboratory experiment with extended follow-ups (Study 2). Study 1 analyzed 419,344 academic papers published before and after ChatGPT-3.5’s release across all subjects categorized by Web of Science (i.e., Physical Sciences, Life Sciences & Biomedicine, Technology, Social Sciences, Arts & Humanities). Study 2, a seven-day laboratory experiment with two follow-up surveys, collected 3593 original ideas and 427 solutions across 18 different creative tasks, with half of the participants using ChatGPT-4. We find that although generative AI helps scholars to publish more academic works in higher-ranked journals and enhances individuals' performance in creative tasks, such creativity drops remarkably upon withdrawal of AI assistance. Strikingly, the induced content homogeneity keeps climbing even months later. We resemble the latter as a creative scar inked in the temporal creativity trajectory. This research identifies a creativity illusion that although generative AI can augment creative performance, users do not truly acquire the ability to create but easily lost it once generative AI is no longer available.",2,2,Technology in Society,2026,https://www.sciencedirect.com/science/article/pii/S0160791X25002775,Creativity,GPT 3.5 / GPT4o,"419,344 article+61 students",Indirect,30 days/ 60 days,"1. The study identified a ""Creativity Illusion"": 
While the presence of Generative AI (like GPT) is associated with an increase in creative output, with the average number of papers published per scholar per year increasing by 0.9 and the likelihood of publishing in higher-ranking journals increasing by 6%, this performance boost comes at the cost of increased content homogeneity. Specifically, the similarity in language style increased by 79% annually, and content similarity increased by 7% (suggesting a convergence of research interests/hot topics). 

2. Upon the withdrawal of AI assistance, individual creativity significantly declines, but the homogeneity persists—a phenomenon the paper terms a ""Creative Scar.""",
Human Creativity in the Age of LLMs: Randomized Experiments on Divergent and Convergent Thinking,"Large language models are transforming the creative process by offering unprecedented capabilities to algorithmically generate ideas. While these tools can enhance human creativity when people co-create with them, it’s unclear how this will impact unassisted human creativity. We conducted two large pre-registered parallel experiments involving 1,100 participants attempting tasks targeting the two core components of creativity, divergent and convergent thinking. We compare the effects of two forms of large language model (LLM) assistance—a standard LLM providing direct answers and a coach-like LLM offering guidance—with a control group receiving no AI assistance, and focus particularly on how all groups perform in a final, unassisted stage. Our findings reveal that while LLM assistance can provide short-term boosts in creativity during assisted tasks, it may inadvertently hinder independent creative performance when users work without assistance, raising concerns about the long-term impact on human creativity and cognition.",2,2,CHI,2025,https://dl.acm.org/doi/10.1145/3706598.3714198,Creativity,GPT-4o,1100,Conversation(Coorperation/ Coach),F,"1. While LLM assistance can be good for creativity, it has a homogenization problem. Performance is good during collaboration, but independent performance worsens afterward.

2. The coach mode is not effective; its results are consistently the worst of all.",
Inspiration booster or creative fixation? The dual mechanisms of LLMs in shaping individual creativity in tasks of different complexity,"The emergence of large language models (LLMs) presents opportunities for stimulating unlimited creative potential. However, how LLMs influence individual creativity remains unclear. Therefore, this paper examines the dual-opposing mechanisms through which LLMs influence individual creativity. In Experiment 1, each participant collaborated with a human partner or a general, unconstrained LLM partner to complete creative tasks. The results showed that compared to collaborating with the human partner, collaborating with the LLM partner significantly improved individual creativity in simple tasks, attributable to inspiration stimulation. However, in complex tasks, collaborating with the LLM partner led to a decrease in creativity, attributable to creative fixation. To mitigate this impact, in Experiment 2, participants were instructed to collaborate with batch-responsive LLM or constrained-responsive LLM to complete creative tasks. We found that constraining the output of LLMs effectively mitigated the creative fixation they induce in complex tasks, thereby enhancing creative performance. However, this constraint may weaken the positive effects of inspiration stimulation in simple tasks. These findings provide insights for the differentiated application of LLMs in creative tasks.",2,2,Humanities and Social Sciences Communications,2025,https://www.nature.com/articles/s41599-025-05867-9,Creativity,ERNIE Bot,204,Conversation,F,"1. LLMs can improve the quality of creative output, but this creativity can become fixated, especially in complex tasks. 

2. Mechanism explanation: Creative fixation stems from cognitive load theory. LLMs provide ""a large amount of information,"" which occupies limited ""working memory"" resources, leading to ""cognitive overload."" At this point, the individual lacks sufficient cognitive resources for independent thought and can only unconsciously follow the LLM's logical framework, resulting in fixation. This is why the effect is not as good on complex problems.",
"Generative artificial intelligence, human creativity, and art","Recent artificial intelligence (AI) tools have demonstrated the ability to produce outputs traditionally considered creative. One such system is text-to-image generative AI (e.g. Midjourney, Stable Diffusion, DALL-E), which automates humans’ artistic execution to generate digital artworks. Utilizing a dataset of over 4 million artworks from more than 50,000 unique users, our research shows that over time, text-to-image AI significantly enhances human creative productivity by 25% and increases the value as measured by the likelihood of receiving a favorite per view by 50%. While peak artwork Content Novelty, defined as focal subject matter and relations, increases over time, average Content Novelty declines, suggesting an expanding but inefficient idea space. Additionally, there is a consistent reduction in both peak and average Visual Novelty, captured by pixel-level stylistic elements. Importantly, AI-assisted artists who can successfully explore more novel ideas, regardless of their prior originality, may produce artworks that their peers evaluate more favorably. Lastly, AI adoption decreased value capture (favorites earned) concentration among adopters. The results suggest that ideation and filtering are likely necessary skills in the text-to-image process, thus giving rise to “generative synesthesia”—the harmonious blending of human exploration and AI exploitation to discover new creative workflows.",2,2,PNAS Nexus,2024,https://academic.oup.com/pnasnexus/article/3/3/pgae052/7618478,Creativity (Art),Midjourney,>5800,Detect whether AI,6 months,"1. The performance of AI-generated art is very good. Six months after adoption, the value of artworks, measured as favorites per view, increased by 50%. Artist productivity increased by 50% in the month of adoption and subsequently doubled. AI can improve the efficiency of artists in executing their ideas. 

2. However, when AI is used for creation, novelty tends to decrease. Therefore, the process should be a fusion of AI and the artist : the artist provides the ideas (""ideation"") and AI executes them.",T2I
Generative AI enhances individual creativity but reduces the collective diversity of novel content,"Creativity is core to being human. Generative artificial intelligence (AI)—including powerful large language models (LLMs)—holds promise for humans to be more creative by offering new ideas, or less creative by anchoring on generative AI ideas. We study the causal impact of generative AI ideas on the production of short stories in an online experiment where some writers obtained story ideas from an LLM. We find that access to generative AI ideas causes stories to be evaluated as more creative, better written, and more enjoyable, especially among less creative writers. However, generative AI–enabled stories are more similar to each other than stories by humans alone. These results point to an increase in individual creativity at the risk of losing collective novelty. This dynamic resembles a social dilemma: With generative AI, writers are individually better off, but collectively a narrower scope of novel content is produced. Our results have implications for researchers, policy-makers, and practitioners interested in bolstering creativity.",2,2,Science,2024,https://www.science.org/doi/10.1126/sciadv.adn5290,Creativity,GPT-4,300,"AI generates ideas, and human writers complete the work.",F,"1. Stories written with AI assistance were evaluated as being better than those written by humans alone. This improvement was particularly significant for writers who were deemed less creative to begin with. 

2. However, the AI-assisted ideas suffer from severe homogenization. The stories produced by the AI-assisted groups were much more similar to each other than the stories produced by the human-only group.",
"The paradox of creativity in generative AI: high performance, human-like bias, and limited differential evaluation","Creativity plays a crucial role in helping individuals and organisations generate innovative solutions to arising challenges. To support this creative process, generative Artificial Intelligence (AI), such as ChatGPT is being used increasingly. However, whether such a generative AI model can truly enhance creativity or whether it exhibits similar creative biases to humans is unclear. This study, conducted in 2025, consisted of an experiment which involved ChatGPT-4o performing the egg task, a creativity task which measures fixation bias and original idea generation (expansion). The AI model's results were compared both to a sample of 47 human participants and to aggregated data from eight previous studies using the same procedure with the egg task. This dual comparison provides a comprehensive perspective on creative biases in both AI and humans at multiple levels. While ChatGPT demonstrated greater productivity than humans, it exhibited a comparable fixation bias, with most ideas falling within conventional categories. Furthermore, the model showed a limited capability to differentially evaluate originality, as it struggled to distinguish between original and conventional ideas, unlike humans who are typically able to make this distinction. In conclusion, although generative AI demonstrates impressive fluency by producing a large number of creative ideas, its inability to critically assess their originality and overcome the fixation bias highlights the necessity of human involvement, particularly for properly evaluating and filtering the ideas generated.",2,2,Frontiers in Psychology,2025,https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2025.1628486/full,Creativity,GPT-4o,47,Conversation,F,"1. AI demonstrated considerably higher fluency, producing a greater overall number of ideas than humans within the time limit.

2. AI exhibited a comparable fixation bias to humans, with the majority of its ideas falling within conventional categories.

3. AI showed a limited capability to differentially evaluate originality and struggled to distinguish between original and conventional ideas, unlike humans who typically can. This highlights the necessity of human involvement for proper evaluation and filtering.",
Mapping the increasing use of LLMs in scientific papers,"Scientific publishing lays the foundation of science by disseminating research findings, fostering collaboration, encouraging reproducibility, and ensuring that scientific knowledge is accessible, verifiable, and built upon over time. Recently, there has been immense speculation about how many people are using large language models (LLMs) like ChatGPT in their academic writing, and to what extent this tool might have an effect on global scientific practices. However, we lack a precise measure of the proportion of academic writing substantially modified or produced by LLMs. To address this gap, we conduct the first systematic, large-scale analysis across 950,965 papers published between January 2020 and February 2024 on the arXiv, bioRxiv, and Nature portfolio journals, using a population-level statistical framework to measure the prevalence of LLM-modified content over time. Our statistical estimation operates on the corpus level and is more robust than inference on individual instances. Our findings reveal a steady increase in LLM usage, with the largest and fastest growth observed in Computer Science papers (up to 17.5%). In comparison, Mathematics papers and the Nature portfolio showed the least LLM modification (up to 6.3%). Moreover, at an aggregate level, our analysis reveals that higher levels of LLM-modification are associated with papers whose first authors post preprints more frequently, papers in more crowded research areas, and papers of shorter lengths. Our findings suggests that LLMs are being broadly used in scientific writings.",2,2,arxiv,2024,https://arxiv.org/pdf/2404.01268,Creativity (Research),,"950,965 articles",Conversation,F,"1. A method based on word frequency shifts successfully detected the usage of ChatGPT. It was found that LLM modifications in Computer Science papers increased to 17.5% in the abstracts and significantly increased to 15.3% in the introductions. Mathematics papers and those published in Nature Portfolio showed the lowest level of modification, at a maximum of 6.3%.

2. The impact factors identified were: The first author published preprints more frequently. The papers belonged to more crowded research fields. The papers were shorter in length.",Only on writing
Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP Researchers,"Recent advancements in large language models (LLMs) have sparked optimism about their potential to accelerate scientific discovery, with a growing number of works proposing research agents that autonomously generate and validate new ideas. Despite this, no evaluations have shown that LLM systems can take the very first step of producing novel, expert-level ideas, let alone perform the entire research process. We address this by establishing an experimental design that evaluates research idea generation while controlling for confounders and performs the first head-to-head comparison between expert NLP researchers and an LLM ideation agent. By recruiting over 100 NLP researchers to write novel ideas and blind reviews of both LLM and human ideas, we obtain the first statistically significant conclusion on current LLM capabilities for research ideation: we find LLM-generated ideas are judged as more novel (p < 0.05) than human expert ideas while being judged slightly weaker on feasibility. Studying our agent baselines closely, we identify open problems in building and evaluating research agents, including failures of LLM self-evaluation and their lack of diversity in generation. Finally, we acknowledge that human judgements of novelty can be difficult, even by experts, and propose an end-to-end study design which recruits researchers to execute these ideas into full projects, enabling us to study whether these novelty and feasibility judgements result in meaningful differences in research outcome.",2,2,ICLR,2025,https://arxiv.org/pdf/2409.04109,Creativity (Research),Claude 3.5 Sonnet,49*3（human，LLM，Human+LLM）,Conversation,F,"Current powerful LLMs (combined with retrieval and simple agent frameworks) are already able to generate research ideas that are more “novel” than those of many human experts, but they remain immature in terms of feasibility, self-evaluation, and diversity, and are still some distance away from being truly reliable “AI scientists.”",Generate idea
